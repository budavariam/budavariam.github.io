[{"content":"As the new year approached, I wanted to write a Team Leader manifesto or a document to catch how it feels to be a team leader after one year. To summarize what I learned or to help new team leaders with what to expect.\nI found this Manager Readme format and wanted to try it out.\nYou can find the primary doc here at managerreadme.com.\nName M√°ty√°s Leader since 2021. September Company Starschema ltd. Title Senior Software Developer Team Lead Team size 5 Motivation for this document Why did I take the time to write this document? This document is my team lead manifesto as of 2022. I write it in the first person as a team lead, and I write it to You as if you\u0026rsquo;d join my team soon. It\u0026rsquo;s like a discussion, which is how I\u0026rsquo;d tell you if we met.\nI heard about this format in a Hungarian podcast called \u0026lsquo;Anonim Vezet≈ëk Klubja\u0026rsquo; ep s01e07. It seemed interesting enough to try it out.\nWhat was I aiming to get from others reading it? I wanted you to understand how I \u0026ldquo;work\u0026rdquo; and what working with me can feel like.\nAlso, I wanted to remind myself of all my bad and good quirks that I should mention to avoid surprises.\nMy role Besides my software development roles, my role as a team lead includes these areas:\nAdministration: Manage newcomers, leavers, changes, timesheets, accesses Knowledge Management: What you should know, what should I know Resource Management: What projects will you work on Performance Management: Provide feedback Career planning/Development plan: Discuss options and goals Recruitment: Choose the new candidates for my team What are the team\u0026rsquo;s KPIs? How are you being measured? We mainly work in consulting, so the clients pay for our time. Basically, the sooner you finish the tasks, the better you are based on this metric.\nIn this sense, it makes you more valuable if you can estimate how much time it\u0026rsquo;d take you to finish a task. It\u0026rsquo;s even better if you could estimate something that you haven\u0026rsquo;t done before, of course I know it\u0026rsquo;s a dream.\nIn a broader sense we have detailed carreer plan document that we go through regularly to be on the same page of what\u0026rsquo;s expected on certain levels.\nHow will I help my teammates get better at their jobs? I\u0026rsquo;ll be there for technical problem debugging and can refer to tutorials or pieces of training.\nI\u0026rsquo;m up to jumping in calls for challenging technical problems to debug them together. You can join me on my development tasks to work them through together to get a glimpse of how I work.\nWhat do I value most? I value attention to detail. So it\u0026rsquo;ll make me happy if you mention that you also thought about edge cases.\nI believe that we are humans, and sometimes we make mistakes, I value when people come forward with their mistakes before its undeniable.\nI value proactivity. I don\u0026rsquo;t want to nudge you to tell me how you\u0026rsquo;re doing. If we\u0026rsquo;re working on time-sensitive tasks, keep me posted.\nI value humility for the tasks and projects, and when people can argue on a technical level and does not take it personally when their ideas are not the ones that the team chooses to implement.\nI value ideas that make things better.\nWhat does helping me look like? You can help me by asking the right questions and coming up with new ideas we can implement together.\nI can help you by managing conflicts, giving you technical help via screen sharing, and mentoring you on software engineering topics I know more about.\nWhat is my process for handling conflicts? (and how you can do it yourself) Write me on Slack, and we\u0026rsquo;ll figure it out.\nI\u0026rsquo;ll most likely ask these questions:\nDoes the other party know about this issue? Did you listen to their point of view? How did you try to resolve it? What weaknesses of mine should the team know about, and how can they help me improve? I studied Computer Science at the university, I worked professionally in a developer role for seven years before I got a managing position.\nI\u0026rsquo;m still learning communication and management. So please be patient with me. I\u0026rsquo;m still learning.\nMy Expectations How should people set time with me? If you want me in a meeting, please tell me in advance at least 2 hours ahead. The best way is on Slack. I want to avoid meeting during my lunch break or after work hours. For ad-hoc help, ping me on Slack, and I\u0026rsquo;ll tell you when I\u0026rsquo;m available. My calendar is up to date with personal slots booked as well. You can book a time there with confidence. Please only book between 2 time slots that have at least 30 mins between them, or let me know in advance. If you send me a calendar invitation, please give me the context in a few sentences or make a descriptive title that I can remember if we discussed it earlier Please don\u0026rsquo;t set up a meeting where you tell 5+ people what we need to figure out on the spot. Let us prepare for larger discussions. When it comes to mistakes, what\u0026rsquo;s the best way for employees to come forward? Tell me on Slack about the problem and describe it in a short sentence. (So I won\u0026rsquo;t get a heart attack until the explanation). After that, we can jump on a call to figure out how to solve the issue.\nHow do I define \u0026ldquo;Done\u0026rdquo;? The happy path works flawlessly. The error paths let the user know what\u0026rsquo;s wrong. You demonstrate that you thought about edge cases even if they\u0026rsquo;re not implemented yet. It\u0026rsquo;s \u0026ldquo;demoable\u0026rdquo; to the user without shame. There\u0026rsquo;s some documentation or way to demonstrate it with example input to use. When should people be available and how? For cooperation, it\u0026rsquo;s best to be available during regular work hours in Europe. If you need to leave for at least 2 hours, please let me know so that I know that you\u0026rsquo;re away. I expect to communicate in a heavily async way so it does not matter when you answer. Suppose there\u0026rsquo;s something complex/urgent problem, then we jump on a call. On the other hand, I prefer detailed text messages.\nI will only bother you via telephone if there\u0026rsquo;s a special on-call agreement, it\u0026rsquo;s your shift, and something related is going on.\nEmail chains are the worst way to communicate with me.\n1:1s What are 1:1s? One-on-ones are a scheduled, formal way to have a friendly discussion.\nIt would be best if you didn\u0026rsquo;t wait for them to tell me anything. Ping me on Slack, and we can have a discussion whenever.\nWhen do I usually have 1:1s with my team? I like to have 1:1 sessions in the morning before starting development. If it\u0026rsquo;s up to me, I\u0026rsquo;ll schedule at most 3 of them in a row, close to each other, with 15-minute breaks.\nI like 1:1 sessions to last for at least 30 minutes, and I prefer to hold them once in 2 weeks.\nWe can postpone the original schedule but don\u0026rsquo;t cancel it (unless there\u0026rsquo;s an extended vacation or similar).\nWho should lead the 1:1? As you prefer, I\u0026rsquo;ll prepare for our meetings with a simple agenda if there\u0026rsquo;s anything that we ought to talk about.\nOtherwise, how much you\u0026rsquo;d like to share is up to you.\nThis meeting is about confidential talking and bonding.\nIf there\u0026rsquo;s anything I\u0026rsquo;d like to share with others I\u0026rsquo;ll ask it explicitly.\nWhat to expect on a 1:1? I\u0026rsquo;ll ask you how you feel and what you would like to talk about. Also, if there\u0026rsquo;s anything you\u0026rsquo;re proud of that you\u0026rsquo;d like to share, what is blocking you, and how can I support you.\nAlso, I usually prepare some topics beforehand as an agenda if it\u0026rsquo;s applicable.\nfeedback from others company-related or work-related things to discuss project-related things to discuss personal growth I like to take notes to expand my memory and mark down the action items we discuss. Taking notes makes me feel safer that I can come back with answers to you at most the next time.\nWhat should be the primary focus during that time? You.\nI don\u0026rsquo;t want to take a lead and bore you with my stories. I\u0026rsquo;m interested in how you feel, what you struggle with, and how I can help.\nPersonality quirks What are the individual quirks that anyone working with me should know about? I\u0026rsquo;m not too fond of cold starts. #TeamNoHello. If you believe in personality tests, I got blue and green in the DISC model. What it means for me is that I prefer to talk about technical stuff, and I want to support you. I don\u0026rsquo;t like to repeat myself. So if I ask you something to do, I\u0026rsquo;ll expect you to write it down to remember it. I\u0026rsquo;ll occasionally remind you of it in a friendly tone, but it\u0026rsquo;ll make our work together more seamless if you remember it, and you\u0026rsquo;ll grow in my eye. I\u0026rsquo;ll make sure that there are no elephants in the room. If we discuss something only half of the team does not know about, I\u0026rsquo;ll give them context in a few sentences. I\u0026rsquo;ll expect the same in return. Please keep me in the loop while I\u0026rsquo;m on vacation. Write me anything. It\u0026rsquo;ll make my catchup easier when I get back from it. I won\u0026rsquo;t read it while I\u0026rsquo;m away. I don\u0026rsquo;t like the firefighting mentality. I\u0026rsquo;ll try to be one step ahead of the team, and I prefer dealing with issues earlier than they become a burning issue I wouldn\u0026rsquo;t say I like micromanagement. I believe you\u0026rsquo;ll ask questions if you get stuck for at least an hour. I\u0026rsquo;m incredibly polite, so it might not be evident when I\u0026rsquo;m pissed off. If I raise my voice, you\u0026rsquo;ll know that I\u0026rsquo;m super mad. Where to focus on your first 90 days? What does effective onboarding look like on my team? We have a few-week-long onboarding program that dives you deep into our workdays into real projects. You can work with a single colleague for an extended period to bond and see what working on the projects together feels like.\nIt\u0026rsquo;s considered effective if you better understand who we are, what we do, and how we like to do it.\nHow can you tell if you\u0026rsquo;re doing a good job in your first 30 days? You ask many questions. You fit with the team personally, and you feel with most of them that you can work together effectively.\nDisclaimer This document is reflects my personal experience, these thoughts and ideas are my own.\nThis document captures how I feel currently. I aim to update it regularly when my team changes. I can remind myself of my values and reevaluate how I work.\nBeing a leader is a journey for me. I don\u0026rsquo;t know what the future holds.\nSelf-reflection is key. If you\u0026rsquo;re also a leader, I can recommend you to collect your thoughts on finding your answers to these topics.\nIf you have anything to add or discuss hit me up on Linkedin or via Email.\nHappy leading!\nCover Photo by Miguel √Å. Padri√±√°n from Pexels\n","permalink":"https://budavariam.github.io/posts/2023/01/03/manager-readme/","summary":"As the new year approached, I wanted to write a Team Leader manifesto or a document to catch how it feels to be a team leader after one year. To summarize what I learned or to help new team leaders with what to expect.\nI found this Manager Readme format and wanted to try it out.\n","title":"Manager Readme"},{"content":"The 6th OITM has just finished for me. OITM is an IT championship in Hungary, sponsored by large tech companies held in November for 7 rounds.\nThe current championship had 29 challenges across different fields. Every week there\u0026rsquo;s a new round. This year I participated in 17 categories.\nHow I felt I needed to put in way more time than what I expected.\nThis year I needed some weeks to get into it and at the end I felt bad about not taking it more seriously earlier.\nIt took me a while to get over my disappointment in last year\u0026rsquo;s award ceremony and push myself to learn something new in the categories.\nMy favorite categories were the Cloud BI, where I realized I know more about BI then what I thought.\nAnd React.js, because it made me feel good about how much I already know, while pointing out the new directions that I could learn in it.\n2 years ago my favourite category was Cybersecurity, this year that was the one I enjoyed the least, and even stopped participating. After looking at the categories I think I should have joined to IT Security, that would have been probably what I missed.\nI deliberately hadn\u0026rsquo;t participated in categories where I knew I would fail badly like Microsoft related categories, php or Effective Java.\nWhat Changed This year the organizers started to give out badges for point over the average, time below the average and flawless round. Also they gave out coupons for each category winners each week.\nI liked that there was a new category for Excel, and that now many categories stopped sending out 4 answer guess forms.\nResults I earned these badges, that are currently visible on my profile.\n1x Category champion (Cloud BI) 70/119 rounds I scored over the average point of all participants 61/119 rounds I finished earlier than the average of all participants 15/119 flawless rounds 1 Elite Club membership Here are what I know about my results as of now for this year ordered by Percentage:\nCategory name üíØ Percentage Exact Python in cloud 4Ô∏è‚É£ Top 25 ? / 313 Language-independent programming 11.16% 74 / 663 React 3Ô∏è‚É£ 11.58% 35 / 302 Data science in IT Security 13.49% 34 / 252 Embedded Systems (C) 13.82% 30 / 217 Artifical Intelligence 14.05% 44 / 313 DevOps 14.95% 70 / 468 Cloud BI 2Ô∏è‚É£ 16.93% 31 / 183 Cloud Engineering 17.36% 62 / 357 Excel 5Ô∏è‚É£ 18.35% 96 / 523 Design Patterns 19.12% 87 / 455 Node.js fullstack development 1Ô∏è‚É£ 19.32% 63 / 326 Web development with traditional methods 21.22% 146 / 688 NetworKING 22.71% 87 / 383 Test automation 23.46% 84 / 358 Accessible websites 28.90% 111 / 384 Linux System Development and Maintenance 47.50% 200 / 421 Nevertheless I am looking forward to it next year!\nHappy Coding!\n","permalink":"https://budavariam.github.io/posts/2022/11/29/oitm-2022/","summary":"The 6th OITM has just finished for me. OITM is an IT championship in Hungary, sponsored by large tech companies held in November for 7 rounds.\n","title":"OITM 2022"},{"content":"Luckily this year had another transferred working day, and the tradition continues: our company gifted us with an opportunity to work on some fun projects in this Saturday working day.\nThis time I decided to join an already existing idea and try to do my best over there. I was hoping that I can just contribute follow the dream, and it\u0026rsquo;ll be less stressful, thus I can enjoy the endless pile of pizza more.\nRough Start It was not that simple. The idea holder had a clear goal on what shall be done, and motivated a bunch of people with various skillsets to this team. Earlier I also convinced 2 of my direct teammates to join.\nFinally our team grew into 9 people. We not only faced difficulties with the technical challenges, we needed to manage upcoming problems and keep track of how each part of the application is doing.\nWe only had around 6 hours. The time was ticking.\nThe idea In our internal toolset there\u0026rsquo;s not a simple way to extract details from the only Hungarian Train company\u0026rsquo;s ticket format for our finance team. It has to be extracted manually:\npair the tickets with their invoices create a summary pass forward in the pipeline save the documents for a few years Our idea was to extend one of our internal portals with such functionality that everyone can just upload their tickets they\u0026rsquo;d like to add for travel reimbursement.\nThen the app would extract the necessary details by getting the text data from pdf, pair the ticket and invoice pdf files together. And in an admin page the finance team have a download option for the files and see the exact summaries.\nTeam split This is the first time I was in such a large technical team. We decided early on what each member will be working on, and split into 1-2 person areas.\nI took the admin page, and the 2 other web devs took the client UI and the portal API.\nThe others decided to create a data pipeline in AWS, written in python.\nThey split the pipeline into 2 teams:\nextract the uploaded files and parse the pdf invoice and ticket format for 2 different type of export sources join the pairs of the pdfs and send back the data in a single JSON matching the data How the hell rose In the beginning things went smooth, then AWS permission issues started to take more time than expected. Also the API did not want to start up due to recent version updates, and tricky coding bugs appeared as well.\nWe were able to contaminate these problems and every team knew their task, we also knew that we could only succeed if every team fills their part.\nThe tension grew.\nSome parts were ready sooner, some seemed to become unexpected bottlenecks.\nUIWise we were lucky, we knew how to start app the app and what to expect. We decided not to tie ourselves for the conventions of the original app, we decided to use whatever we are familiar with that gets the job done. We\u0026rsquo;re not making production ready code, we\u0026rsquo;re here for having fun and presenting an idea.\nWe dedicated a single person to pimp up the presentation, and prepared for a live demo at the end.\nSadly we could not connect every part of the application, although the UI was functioning perfectly with my local server\u0026rsquo;s mock data.\nHow we avoided communication problems We weren\u0026rsquo;t afraid to call for help if a problem persists for more than 20 minutes, more eyes can spot errors quicker Kept the communication flowing, get status updates in fixed periods of time Split up tasks for micro teams that could work on specific issues Everybody knew which team worked on what Sit close to each other Live chat channel for help requests and sharing snippets My key Hackathon takeaways Try to find the right balance between team size and tasks before signing up I should prepare for the most basic things to fail (misbehaviour from recent software updates, permission issues) It\u0026rsquo;s important to make sure that everyone can feel useful and learns something by the end of the day Always be thankful for my teammates, they joined for a reason and it\u0026rsquo;s a nice touch to thank them their efforts Remember to have some fun and don\u0026rsquo;t take it too seriously Try to avoid unknowns as much as possible if you\u0026rsquo;re in a hurry with your feature Spend more time creating engaging visuals for the presentation, not solving your application for the edge cases Presentation The idea holder had a speech about the end goal, and how our large team tried to make it possible in a single day. Then I took over with the demo and presented the short live demo with some technical details on what\u0026rsquo;s going on in the background.\nWe could hear the crowd drop their jaws when they realised how we extract the data and it\u0026rsquo;s benefit of saving the finance team from a bunch of headache.\nOther teams In total there were 12 teams, each team had around 8 minutes to present their ideas. There were technical experiments, hardware programming, engaging mobile apps for sports, data visualizations, data analytics projects.\nPresentation takeaways Upon looking at a bunch of presentations I saw patterns that we could take into our presentations and what should we avoid next time.\nAim for memorability: Pick a descriptive punny team name, so that at the voting people will know which is your project Expect that the audience might be far away from the projector Use large font size Choose good visible fonts Don\u0026rsquo;t assume that they can read your presentation as clear as in their computer Do not write huge walls of text, rather use images Use distinct colors in diagrams, multiple presentations stick with the defaults that had for example orange and red. They looked the same. Explain the process, tell the story, don\u0026rsquo;t expect the audience to understand a flowchart just by seeing it the first time No result is still result if you can present it well A working demo does wonders, if it has a clear goal on what you want to tell. Don\u0026rsquo;t just click around aimlessly, prepare with mock data. Further ideas at the end can be interesting. One team teased it like \u0026lsquo;if we had 30 more minutes we would implement this huge amount of tasks\u0026rsquo; One data analysis project team used Kahoot to make it a fun engaging presentation. They didn\u0026rsquo;t make it a test about their understanding, rather made it a fun guessing game Results We got 3rd place with this idea. üéâ\nSummary I really enjoyed this day, it was a nice way to connect with people from different divisions.\nI\u0026rsquo;m looking forward to the next one.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2022/10/15/starschema-hackathon-2022-again/","summary":"Luckily this year had another transferred working day, and the tradition continues: our company gifted us with an opportunity to work on some fun projects in this Saturday working day.\n","title":"Starschema Hackathon 2022 (again!)"},{"content":"I\u0026rsquo;ve moved my blog content build to hugo more than a year ago, but I still forget how to achieve some basic things in Hugo or where to find them in the docs. I\u0026rsquo;ve put together this cheatsheet to help me later on. I hope it\u0026rsquo;ll benefit you as well.\nGo Templating Basics Docs\nHugo Templating Basics Getting started guide\nAccess parameters with .Get\nCustom templates Create a new folder under content e.g: a Create a file for the list template under layout/section/a.html Create a folder under layout/a and put the files that you want to override from _default like single.html Embed Content Into Markdown Files ShortCodes Shortcodes Emojis emoji support emoji cheat sheet\nI suggest you not to enable emoji parsing globally, because it can mess up source codes. I\u0026rsquo;d prefer to use {{ emoji `:emojicode:` }} in markdown content.\n// Add this shortcode definition to e.g: `layouts/shortcodes/emoji.html` in order to use it {{ .Get 0 | emojify }} Figure Available properties of Figure\nalign alt attr attrlink caption class height link rel src target title width Create Custom Lists From Content Taxonomies are awesome to create custom lists of posts\nEasily Manipulate Data With Scratch Scratch\nIt\u0026rsquo;s good to create a static map of values.\n{{ $scratch := newScratch}} {{ $scratch.Add \u0026#34;email\u0026#34; \u0026#34;mailto:\u0026#34; }} {{ $scratch.Add \u0026#34;gmail\u0026#34; \u0026#34;mailto:\u0026#34; }} \u0026lt;a href=\u0026#34;{{ $scratch.Get \u0026#34;gmail\u0026#34; }}email@domain.com\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; Debugging Print Values printf\ndebug values: {{ printf \u0026quot;Count %#v \u0026quot; .Count }}\nCheck Whether Partials Load To debug partials whether they show up or not, you can add this simple hack to the first line of its html file. You\u0026rsquo;ll quickly notice if they\u0026rsquo;ve loaded even iff it does not show any visible content just from the background change.\n\u0026lt;style\u0026gt;body{background:red!important;}\u0026lt;/style\u0026gt; Handle Images Image Processing\n{{ with .Resources.GetMatch \u0026#34;img.png\u0026#34; }} \u0026lt;img src=\u0026#34;data:{{ .MediaType }};base64,{{ .Content | base64Encode }}\u0026#34;\u0026gt; {{ end }} {{- $images := .Resources.Match \u0026#34;*\u0026#34; -}} {{ printf \u0026#34;nr of images %#v \u0026#34; ( len $images ) }} Available Variables Some variables are available by default in different parts of the site.\nConfiguration Values In case you have parameterValue in config.yml like this:\nparams: parameterValue: 23 You can access it in your code throug Site Params in your partial templates.\n{{ .Site.Params.parameterValue }} Pages Page Variables\n\u0026lt;pre\u0026gt; {{ printf \u0026#34;File: %s\u0026#34; .File }} {{ printf \u0026#34;Content: %s\u0026#34; .Content }} {{ printf \u0026#34;Data: %s\u0026#34; .Data }} {{ printf \u0026#34;IsPage: %s\u0026#34; .IsPage }} {{ printf \u0026#34;Kind: %s\u0026#34; .Kind }} \u0026lt;/pre\u0026gt; Summary I hope you\u0026rsquo;ve found what you were looking for.\nCover Photo by Pixabay from Pexels\n","permalink":"https://budavariam.github.io/posts/2022/07/14/hugo-development-tips/","summary":"I\u0026rsquo;ve moved my blog content build to hugo more than a year ago, but I still forget how to achieve some basic things in Hugo or where to find them in the docs. I\u0026rsquo;ve put together this cheatsheet to help me later on. I hope it\u0026rsquo;ll benefit you as well.\n","title":"Hugo Development Tips"},{"content":"I like to write my projects in JavaScript. Since I don\u0026rsquo;t have time to juggle between all of them, it\u0026rsquo;s inevitable that they\u0026rsquo;re abandoned after a while and left as they were last touched for eternity. I bet this story feels familiar.\nThe node_modules Multiverse Currently I don\u0026rsquo;t have a way to let my machine know, that I won\u0026rsquo;t work on some of my projects for a while. It does not know, that it\u0026rsquo;s safe to get rid of the large unnecessary build artifacts and dependencies. I mostly use node that comes with npm package manager by default. Npm has a huge downside illustrated below.\nHeaviest objects in the universe (source: reddit)\nFor every project that you\u0026rsquo;re woking on, it\u0026rsquo;ll create a new separate node_modules folder, downloading all dependencies and pack it into a single tree structure. This node_modules folder can quickly grow to hundreds of megabytes even if you only use a small set of dependencies. That\u0026rsquo;s because your dependencies most likely depend on other projects, and so on\u0026hellip;\nOut of Space In the last couple of days I\u0026rsquo;ve been struggling with the amount of free space I have. I\u0026rsquo;ve cleaned up in the most obvious places aleady, but it was not enough.\nI decided to take a deepdive into my projects folder stucture.\nfind ~/project -iname \u0026#39;node_modules\u0026#39; -type d | grep -v \u0026#39;/node_modules/\u0026#39; I looked for leaf folders with the name node_modules. To my surprise I found around 50 sandboxes, playgrounds, current projects, recently abandoned projects and REALLY old ones.\nAt that point rage was my guiding star, so I went through them one by one, and removed the unused ones.\nNow I know that there are better ways to tackle this problem. One of which is npkill that promises to easily find and remove old and heavy node_modules folders.\nIn the end I managed to save up around 20GB of space\u0026hellip; I let it sink in. 20GB.\nHow to solve it At first I thought about moving to docker for all frontend related development. I could use development images, build the code there and move the problem away with one level of abstraction.\nI already have a preferred way to clean up dangling images, but I felt like there must be a better way to solve the space problem globally.\nReuse Modules with pnpm A few weeks ago I\u0026rsquo;ve heard about pnpm, but I did not feel the urge then to look into it. Now I felt it\u0026rsquo;s the perfect time to try something new.\nThe feature I like in it the most is that it uses a single loaction to download all modules throughout all the projects that you use with pnpm. During each install it even shows how many packages were reused from the store. It\u0026rsquo;s really pleasing.\nI also like that it can coexist with npm, if you have some special needs that it can not yet solve with pnpm.\nThe project has similar motivation than my needs, even it\u0026rsquo;s name stands for performant npm.\nüü¢Node.js Tip\nWhy store separate copies of packages if you can have a `single` referencable one?\nThat\u0026#39;s the idea behind PNPM which makes it a performant, space-efficient, and faster alternative to NPM/Yarn.\nTrust me, your hard disk will thank you for this weight loss exercise pic.twitter.com/mltti8CFAX\n\u0026mdash; Hem (@HemSays) September 6, 2021 Getting started with pnpm The official docs are a good source to have it up and running in a glance.\nInstallation The installation was pretty straightforward for me. I chose a feasible one from their listed ways and it worked flawlessly.\ncorepack enable corepack prepare pnpm@7.2.1 --activate How to add/remove modules The pnpm add PACKAGE command adds the PACKAGE dependency, and as an added bonus it makes sure that the new module is added to your package.json as well. So hopefully you won\u0026rsquo;t ever run into a problem, that your code depends on a package that you\u0026rsquo;ve installed, but your coworker can not run the app.\n# use is-number package as an example pnpm add is-number The pnpm remove PACKAGE removes it from package.json and the node_modules folder. I\u0026rsquo;d like to add that it won\u0026rsquo;t remove the package from the global store, so reinstalling a package is lightning fast.\n# use is-number package as an example pnpm remove is-number How to clean up after a project The pnpm store prune command removes unreferenced projects from the global store. The global store is not cleaning up itself, and contains multiple versions of the same pakages, as per the dependencies need it. Although when you update some packages in a project, some modules might only have been referenced by your old versions, thus they can be safely deleted.\nIt is advised to run this command once in a while, not too often though.\nAbandon a project on purpose When you no longer develop a project, you can just remove the node_modules folder as usual. The new thing to do is to run pnpm store prune and enjoy your regained free space.\n# abandon a project cd $(pnpm root)/.. rm -rf ./node_modules pnpm store prune Where is the global store You can find the store\u0026rsquo;s location with pnpm store path command.\npnpm store path My current challenge is different node versions I use n for managing node versions. I did not find any documentation of how these can coexist. Although I must add that it\u0026rsquo;s not the best searchable name.\nI have some old projects that only work with older node versions, and I might need to switch between them occasionally in the future.\npnpm env can hopefully help me with that.\npnpm env use --global lts pnpm env use --global 14.17.0 Note: --global flag is mandatory for this command as per v7.x\nIt\u0026rsquo;s said that it works with nvm, I might try that in a next iteration.\nClosing Words I\u0026rsquo;m glad that I found pnpm, I know my hard drive will thank me later. I already like how much module it reuses in the few projects I utilized it in. It already helped me catch bad imports, it\u0026rsquo;s a good start.\nI just need to learn to write pnpm instead of npm from now on.\nI\u0026rsquo;m not affiliated in any way with this project or its authors. This post represents my opinion and limited experience with this tool.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2022/06/15/save-disk-space-with-pnpm/","summary":"I like to write my projects in JavaScript. Since I don\u0026rsquo;t have time to juggle between all of them, it\u0026rsquo;s inevitable that they\u0026rsquo;re abandoned after a while and left as they were last touched for eternity. I bet this story feels familiar.\n","title":"Save Disk Space with pnpm"},{"content":"Nowadays it\u0026rsquo;s pretty common to have the Table Of Contents on the side, that follows the user\u0026rsquo;s scrolling. I\u0026rsquo;ve decided to see what it takes to add it to my Hugo blog.\nAt first I\u0026rsquo;ve looked around in the web, whether Hugo already supports it. It seemed to me that it\u0026rsquo;s not yet available by default, while some themes might support it due to their underlying framework that they use. For example Bootstrap has ScrollSpy.\nInspiration I\u0026rsquo;ve found this great article on CSS-tricks by Chris Coyier that gave me a headstart on how it can be simply implemented.\nSee the Pen Smooth Scrolling Sticky ScrollSpy Navigation by M√°ty√°s Budav√°ri (@budavariam) on CodePen. My Tricky Part For my hugo site I use a modified version of the PaperMod theme. Nowadays I do not follow it\u0026rsquo;s updates while I have many of my own customizations in it.\nSections For sticky headers it\u0026rsquo;s essential to know which item is currently visible in the browser. I hadn\u0026rsquo;t yet had that info. In markdown I can just embed many headers, and it\u0026rsquo;s content won\u0026rsquo;t have any knowledge in the DOM of where it is\u0026hellip;\nMy layout looked like this:\n\u0026lt;h1\u0026gt;Title\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Paragraph\u0026lt;/p\u0026gt; \u0026lt;h2\u0026gt;Sub Title\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Another Paragraph\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Yet another Paragraph\u0026lt;/p\u0026gt; \u0026lt;h2\u0026gt;Another Title\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Another Paragraph: Tokyo Drift\u0026lt;/p\u0026gt; Instead of something like this:\n\u0026lt;section\u0026gt; \u0026lt;h1\u0026gt;Title\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Paragraph\u0026lt;/p\u0026gt; \u0026lt;section\u0026gt; \u0026lt;h2\u0026gt;Sub Title\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Another Paragraph\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Yet another Paragraph\u0026lt;/p\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section\u0026gt; \u0026lt;h2\u0026gt;Another Title\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Another Paragraph: Tokyo Drift\u0026lt;/p\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/section\u0026gt; I wrapped all my headings into sections as it shall be done in the example above with a well/placed regular expression, after the markdown parse has already happened.\nIt\u0026rsquo;s usually a bad idea to replace content in HTML with regular expressions. But since I have a generated code it has enough constraints, that I can trust enough to hope that it\u0026rsquo;s a solid solution.\nI added \u0026lt;section\u0026gt; in the beginning, \u0026lt;/section\u0026gt; at the end and replaced \u0026lt;h\\ds by prefixing \u0026lt;/section\u0026gt;\u0026lt;section\u0026gt; this way the number of starting and closing tags will always match, and I don\u0026rsquo;t have to write a more complicated parser, neeither do I have to come up with an algorithm that tries to keeps track of the state of scrolling with limited information.\nTable Of Contents The theme had a toc.html file with complicated logic. In the docs I\u0026rsquo;ve found, that hugo does it for me already\u0026hellip; and lets me use a rather simple {{ .TableOfContents }} variable in the template.\nI just needded to style it.\nHide On Smaller Screens I\u0026rsquo;m not completely proud of my current solution. I id not want to erwrite the whole layout. At first an absoulute positioned parent seemed feasible, but a good ol\u0026rsquo; float: right works exactly I expect it.\nSince it\u0026rsquo;s just a convenience feature I hide it if the sceen is smaller than where this TOC would fit already.\nSummary It was a great practice to get to know hugo better, while creating something fancy.\nHappy coding!\nCover Photo by ENESFILM from Pexels\n","permalink":"https://budavariam.github.io/posts/2022/06/10/sticky-table-of-contents-navigation-in-hugo/","summary":"Nowadays it\u0026rsquo;s pretty common to have the Table Of Contents on the side, that follows the user\u0026rsquo;s scrolling. I\u0026rsquo;ve decided to see what it takes to add it to my Hugo blog.\n","title":"Sticky Table Of Contents Navigation in Hugo"},{"content":"I just started to get to know how ads work, I\u0026rsquo;m going to experiment with the different capabilities of Google AdSense and how it can be connected with Google Analytics.\nI fired up AdSense and started to learn more about Google Analytics v4. I\u0026rsquo;ve used Google Analytics v3 (Universal Analytics) before, but it\u0026rsquo;s going to be deprecated next year.\nLibs I Use for my Site I build my blog using Hugo,one of the static site generation tool I\u0026rsquo;ve used. I customized my theme based on the PaperMod theme of adityatelange. This theme is based on the minimalistic Paper theme.\nTools that Seems Promising I\u0026rsquo;d like to gain some experience in the analytics part of the applications. I mostly develop internal tools in closed networks, so I lack the proper experience of this from my ususal day-to-day life.\nLet\u0026rsquo;s see how can I analyze my site.\nPerformance Analysis The first rule is that the site has to be performant to keep its users.\nBut what is considered good? I have to measure it sommehow.\nGoogle has some web developer tools that comme in handy.\nLighthouse test is available in Chrome (open in DevTools). Earlier it had a separate extension now it\u0026rsquo;s convenient to reach.\nYou can analyze and optimize your website with PageSpeed tools. Here are the links that analyze my site:\nPageSpeed mobile PageSpeed desktop Google Analytics Google Analytics is the most popular analytics tool available. It\u0026rsquo;s free to use.\nYou can find more info at the Analytics Docs.\nIn case you don\u0026rsquo;t have enough data you can enable some demo accounts where you can explore its possibilities.\nNowadays it\u0026rsquo;s called GA4. GA3 was called Universal analytics, it\u0026rsquo;s going to be deprecated in 2023.x\nGoogle Analytics 4 Tutorial for Beginners This video below helped me get started with GA4.\nGoogle AdSense AdSense is a platform where you can set how your advertisements will show up.\nAdSense acts as an ad network, providing you access to demand from advertisers and helping you set up your ad inventory. AdSense is best for publishers who want more automation for their ad solutions, and have a small dedicated ad management team.\nOkay, then what\u0026rsquo;s the difference between Ad Manager, AdSense, and AdMob? See this post for details.\nGoogle Tag Manager In Google Analytics 4 collects events instead of sessions. Google Tag Manager helps you define events in a graphical interface without any coding necessary. You can propagate changes in your analytics without having to redeploy your site with new data.\nFor complex usecases you can use gtag.js alongside the Tag Manager.\nUpon developing your components Tag Assistant helps you preview your different tags.\nWorking with Google Analytics alongside Tag Manager Google Analytics4 collects many events by default. In case you want to add custom events they have recommended naming conventions that can be found at Recommended events page.\nThese events can have parameters. The names under Enhanced measurement events are already usable in your custom events. However, if you want to use other parameters, you have to add them at Google Analytics \u0026gt; Configure \u0026gt; custom Definitions. Otherwise the new parameters won\u0026rsquo;t be saved although might show up in DebugView.\nYou can start a preview mode in Tag Assistant, and if you turn on Debug signal you can check the events in Google Analytics \u0026gt; Configure \u0026gt; DebugView as well.\nGoogle Tag Manager Tutorial for Beginners This video below helped me get started with Google Tag Manager.\nGoogle Search Console In case you\u0026rsquo;re more into SEO aka search engine optimization, you can look how oother people find your site through google at the Google Search Console.\nSearch Console Insights show quickly digestible information about how your site performs currently.\nWhoever have access can see my site data, and its Search Console Insights.\nSummary I see that there\u0026rsquo;s a lot to learn in this area, and I\u0026rsquo;m starting to dive deeper into it.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2022/06/09/adsense-experiments/","summary":"I just started to get to know how ads work, I\u0026rsquo;m going to experiment with the different capabilities of Google AdSense and how it can be connected with Google Analytics.\n","title":"AdSense Experiments"},{"content":"A picture is worth a thousand words. It\u0026rsquo;s easier to explain the architecture and data flows with diagrams, than with lengthy paragraps.\nDevelopers like to stick to their text editors. Mermaid lets them create flowcharts, sequence diagrams, pie charts and many more diagrams in a declarative way.\nPreviously I created my diagrams in external editors, it was not the best experience to load and export data compared to writing down what I want to show up in the image and have it instantly.\nMermaid can export the generated images as .png, .svg or even .pdf.\nGithub announced first level support for mermaid diagrams this february. It was the first time I heard about this library, I\u0026rsquo;ve been wanting to try it eeveer since. Now I finally got a chance to draw some flowcharts.\nFlowchart Mermaid docs defines the basic syntax with simple examples.\nBasic flowchart example %% single line comment flowchart LR A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{Decision} subgraph grph[Decision graph] C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] end Let\u0026rsquo;s see what we got here:\nflowchart followed by orientation TB / TD - top to bottom BT - bottom to top RL - right to left LR - left to right Any single word by itself is a new node The nodes can be connected together by edges The text on nodes and edges can be customized Single line comments start with %% Styling The docs has more info on styling.\nBasic styling example flowchart LR classDef className fill:#f9f,stroke:#333,stroke-width:4px; node1[name1]:::className---|textOnArrow|node2[name2] CLI Mermaid has a command-line interface available on github.\n# Convert Mermaid mmd Diagram File To SVG mmdc -i input.mmd -o output.svg # Create A PNG With A Dark Theme And Transparent Background mmdc -i input.mmd -o output.png -t dark -b transparent Summary Mermaid has powerful syntax. If you host your code on github, your mermaid diagrams can appear without any further configuration. Otherwise you still have thee option to generate the images with a CLI tool.\nHappy coding!\nCover Photo by C1superstar from Pexels\n","permalink":"https://budavariam.github.io/posts/2022/05/16/mermaid-diagrams/","summary":"A picture is worth a thousand words. It\u0026rsquo;s easier to explain the architecture and data flows with diagrams, than with lengthy paragraps.\nDevelopers like to stick to their text editors. Mermaid lets them create flowcharts, sequence diagrams, pie charts and many more diagrams in a declarative way.\n","title":"Mermaid Diagrams"},{"content":"I often need to present myself differently in git per project. When I work on a client\u0026rsquo;s own github, and they provide me an email address, it\u0026rsquo;s more professional, and most of the time a requirement, to use it to identify myself. Git, by default lets me specify configuration globally, or per repository. However, with a little trick I can set it on any abstraction level I need.\nThe situation Take the simplest example, that I need to change my email address across different git repositories. Imagine I have a folder structure:\nPersonal sandbox: where I\u0026rsquo;d like to use my personal address Company level internal development: where I\u0026rsquo;d like to use my company address One folder per each clients: where I\u0026rsquo;d like to use my vendor addresses Each of these folders can contain many repositories, and the git config depends on the top level folder.\nThe problem is that I really don\u0026rsquo;t want to set up different email addresses per new repositories.\nLet\u0026rsquo;s see what we can do about this.\nWe\u0026rsquo;ll dive in git config a bit.\n# You can set up the single global email address git config --global user.email \u0026#34;company_email@example.com\u0026#34; # You can modify the configs per repository as well git config user.email \u0026#34;name@company.com\u0026#34; Git Include to the rescue Git Includes give you a way to extend your git configurations by loading other files into them.\nYou can even do this conditionally with the includeIf directive.\nYou need to do 2 things:\nDefine the gitconfig snippet with your favourite editor / command in the desired location.\necho \u0026#34;\u0026#34;\u0026#34;[user]\\n email = personal_address@example.com\u0026#34;\u0026#34;\u0026#34; \u0026gt;\u0026gt; ~/project_dir/personal/.gitconfig Extend your git config conditionally\n[includeIf \u0026#34;gitdir:~/project_dir/personal/\u0026#34;] path = ~/project_dir/personal/.gitconfig After this, every git repository anywhere under ~/project_dir/personal/ will see your email address as personal_address@example.com, based on ~/project_dir/personal/.gitconfig.\nSee what\u0026rsquo;s happening You need to add an includeIf directive to your global git config file.\nIt needs to have a single parameter, to define for which git repositories should it add the snippet.\nThe parameter can start with a gitdir: keyword that tells git to test the location of the current repository, whether if matches the defined glob pattern. If it matches, then the snippet defined in the path param of the includeIf directive will be included.\nYou can have relative paths, but it will be relative to the current repo, NOT the global config file.\nWhat if I use dotfiles If you share your dotfiles in a public repository, I highly advise you NOT to share your different email addresses with the whole world.\nHere\u0026rsquo;s where .gitignore and include can come in handy.\nIgnore You can define a pattern for sensitive data in your gitignore file e.g. ignore all files that start with the sensitive prefix.\nYou need to remember to add these files when you set up a new machine.\nInclude And in your global gitconfig you can safely include your additional configs, where you define the extensions via includeIf directives.\n[include] path = ~/dotfiles/git/sensitive-gitconfig File locations It\u0026rsquo;s up to you where you put the snippets. I prefer to keep them in the dotfiles repository. It\u0026rsquo;s also good to keep them near the repositories.\nSee what works for you the best.\nSummary I hope it will prevent you many headaches.\nHappy coding!\nCover Photo by Ibolya Toldi from Pexels\n","permalink":"https://budavariam.github.io/posts/2022/04/04/organization-specific-git-config/","summary":"I often need to present myself differently in git per project. When I work on a client\u0026rsquo;s own github, and they provide me an email address, it\u0026rsquo;s more professional, and most of the time a requirement, to use it to identify myself. Git, by default lets me specify configuration globally, or per repository. However, with a little trick I can set it on any abstraction level I need.\n","title":"Organization Specific Git Config"},{"content":"New Year, new transferred working day. Luckily we had the opportunity to do something fun in a Saturday instead of just extending our work week. So we had another Hackathon! üéâ\nOur Idea Now that the weather starts to be better, people tend to go back to the office. Since there could be weeks since they\u0026rsquo;ve been there the last time, their usual sweet seats might have been taken by someone else.\nWhat if we could book seats just like meeting rooms in advance?\nTeam We have an internal portal with many fun addons, we decided to extend it with a functionality smilar to Officely, but with even more granuality.\nWe wanted to let the workers mark that they\u0026rsquo;ll show up in the office AND book their preferred seats in advance at once.\nOur team of 5 was split into 3 parts:\nbackend + db: to store the requests visuals: create the pixel perfect image mapping frontend: create the logic to show the boxes and communicate with the DB (that\u0026rsquo;s me) Result We did not have time to connect all the dots together, but luckily we reached a point to have a demoable state of the frontend with some magic numbers.\nI\u0026rsquo;ve created a small github repo to catch the essence of the work.\nIn our internal portal it looks much fancier.\nWe got the most votes from the other contestants, and took 1st place (out of 7 teams). üéâ\nImage map creation During the day we had to improvise how to come up with data. For the proper data matching we needed to map each locations with the DB. It was a bit slow to get each seat\u0026rsquo;s ID and location properly manually.\nLater I figured that Inkscape has a Calligraphic Brush Stroke Pen, that I can use to create small circles, and collect their x,y coordinates later.\nBash is my friend, all I needed to do to extract the sizes is to look for these circle-s, and get their properties. I made an assumption that the order is cx, cy and r, and I only needed the first 2. In VSCode I could easily paste the result to the constants.\ngrep \u0026#39;circle\u0026#39; /tmp/floorplan.svg \\ | sed -E \u0026#34;s/[\u0026lt;\u0026gt;=a-zA-Z\\\u0026#34;/]//g\u0026#34; \\ | awk \u0026#39;{printf(\u0026#34;[%d, %d]\\n\u0026#34;, int($1), int($2))}\u0026#39; \\ | pbcopy Further development I\u0026rsquo;m pretty sure that we\u0026rsquo;ll finish this up, and put it into the portal.\nDuring development we already had some ideas:\nShow who booked the seats Cancel booking Mark as dedicated seat Summary We had much fun, I really liked how everyone was into our idea, and we were able to present a seemingly working solution.\nI\u0026rsquo;m looking forward to the next Hackathon.\nHappy coding!\nCover Photo by Kelly L from Pexels\n","permalink":"https://budavariam.github.io/posts/2022/03/26/starschema-hackathon-2022/","summary":"New Year, new transferred working day. Luckily we had the opportunity to do something fun in a Saturday instead of just extending our work week. So we had another Hackathon! üéâ\n","title":"Starschema Hackathon 2022"},{"content":"I came across CSS Battle last year. I tried code golfs before, but this is a whole new level.\nIt reminds me of suicide chess. You have the same building blocks, as the original but you have to think in reverse, in a completely different way.\nWhat makes your code beautiful and readable are a burden in this game.\nWhat is CSS Battle The objective of the game is to write HTML/CSS to replicate the given target image in the least code possible.\nIt sounds simple, isn\u0026rsquo;t it. They restrict using JavaScript, SVG-s, images, canvas, or anything that would make it simple to draw shapes. You need to rely on basics CSS and HTML to make your playground get a 100% pixel perfect match with their given image.\nIt sounds horrible, what is good in it? Some say you need to break things to get to know them better.\nYou can learn more about different shorthand syntaxes and makes you dive deeper into the inner mechanics of how CSS and HTML really works.\nYou have to know the rules so that you can break them.\nTips I found useful Since you need to write the shortest code possible, it will be inevitably ugly and mostly unreadable.\nSome reminders and tips that I read, or figured out myself that made my solutions shorter:\nYou need to remove all whitespaces, because they\u0026rsquo;re counted as well.\nYou don\u0026rsquo;t need to write valid xHTML, it just need to render. e.g: the \u0026lt;p\u0026gt; tags are working fine without closing tags\nYou have a fixed sized layout, you can use magic numbers\nShorthand syntax is your friend:\nThe inset can be a shorthand for top/right/bottom/left. For directional items 1 repeats for all, 2 stands for (y,x) axis from top to bottom, left to right You can use background shorthand instead of background-color. (Stands for these in order: background-color, background-image, background-repeat, background-attachment, background-position) padding can be used for size instead of: height/width\nmargin/inset can be used for positioning instead of: top/right/bottom/left\nYou can omit units in css, the default is px\nYou can omit quotes in HTML\nYou can omit values of HTML boolean properties, if the name is present it\u0026rsquo;s true\nYou can omit the last ; from CSS rules\nYou don\u0026rsquo;t always have to use closing tags in HTML\nYou don\u0026rsquo;t need to write class-es:\n\u0026lt;a b\u0026gt; can be matched with a[b]{} \u0026lt;a id=b\u0026gt; can be matched with #b{} \u0026lt;body bgcolor=111111\u0026gt; is shorter than body { background-color: \u0026quot;#111111\u0026quot;; }\nYou can target all items with *\nFor top level positioning fixed is shorter than absolute\nYou can use box-shadow to \u0026ldquo;copy\u0026rdquo; items, it gets currentcolor as its default color.\nfilter: drop-shadow(...); can copy single borders radial-gradient is good for repeating patterns\nIf you need to set background-color multiple times (5+), you can set it to currentcolor once, and use color: in the next occurrances.\np{background:currentcolor} /* `background:currentcolor`: constant 23char */ p[a]{color:red} /* color: 5char */ p[b]{color:fff} ... p[z]{color:0} vs. p[a]{background:red} /* background: 10char */ p[b]{background:fff} ... p[z]{background:0} ::before/::after and border are good building blocks\nIn case you need to transform: rotate you might face into different bugs in separate browsers. Here are some separate ideas how to tackle them: will-change: transform; -webkit-backface-visibility: hidden; outline: 1px solid transparent; box-shadow: 0 0 1px rgba(255,255,255,0); You can create a starter code to help you over time with your favourite patterns e.g:\n\u0026lt;body bgcolor=0\u0026gt;\u0026lt;p\u0026gt; \u0026lt;style\u0026gt; body{padding: 60 50} p{position:fixed; background:red; padding:10 30; margin:10 20 } You might find more useful tips at css-battle page.\nShowcase Application My code is not golfy enough yet. Also I don\u0026rsquo;t have many people to race against, so I decided to put up my solutions to github.\nI decided to create a showcase site for it. I took this opportunity to get started with next.js static-site-generator and tailwind.css css utility library.\nIt shows the original image, renders my solution and prints it with syntax highlight.js.\nI might add some thoughts on the different tasks, with some details on how I approached the problems. The code contains MDX renderer, so I can add my thoughts without having to write HTML. I like the dark/light mode integration with the code highlghter, and tailwind\u0026rsquo;s support with CSS custom properties.\nYou can reach the DEMO site here.\nOr browse my solutions over here on Github.\nResources web.dev: learn CSS. An awesome and detailed css course. MDN CSS docs. The best webdev reources. CSS Specification as of 2021. The source of thruth. HTML Standard Closing notes When I first found this game I thought of creating a tool to minify my code. I don\u0026rsquo;t know if I\u0026rsquo;m going to get better at this game first or make the tool happen.\nI enjoyed creating the next.js site. Tailwind is simpler than I first imagined. I\u0026rsquo;d like to thank ChangoMan for the starter code, that contained what I imagined to get started with next.js.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2022/03/14/css-battle-showcase/","summary":"I came across CSS Battle last year. I tried code golfs before, but this is a whole new level.\n","title":"CSS Battle Showcase"},{"content":"Have you ever been in a situation where you work for a few repositories over a prolonged time, and all of a sudden, you\u0026rsquo;re notified that you\u0026rsquo;ll no longer have access to these repos in a few weeks?\nContribution history is not a good metric Nowadays, it\u0026rsquo;s trendy to assume how active a developer is by looking at their contribution history.\nEven though it\u0026rsquo;s not a good metric for many reasons:\nNot all developers use GitHub Contributions can be spread across many repository hosting services, even on-prem private ones The number of commits does not say anything about their quality Anyways, it bothers me a bit when this happens. When all those nice lil\u0026rsquo; green boxes go away.\nHow to mitigate There are a few options.\nI must mention that you should NOT save the repo privately. If they took away your access, chances are high that you should get rid of the confidential codebase.\nStar the private repo I found this thread, that talks about this exact issue.\n\u0026ldquo;We recommend starring any repositories you contribute to. That way, your commits to those repositories will remain in your contributions graph even if you leave the organization that owns the repository or delete your fork of the repository\u0026rdquo; from Support-Protips\nThis comment might save the day.\nSave the commit metadata to a separate repo If you do not trust the starring method above, and you only care about commit contributions, you can:\nCreate a single private repo for lost contributions Filter the given repo with only your commits Recreate the commits in the new repo without any sensitive data Set up GitHub to show private contributions in the activity history Enjoy You have to make sure that the commits conform to the rules to be counted.\nIt might sound like cheating, but it keeps your contributions safe even if the organization gets deleted or they remove the repository.\nAccept it and move on There are more severe matters nowadays that you can worry about. Why bother?\nMy approach I created a python script that follows the steps described above.\nYou only need to modify the code inside the main function to personalize. It needs a list with the project names and locations and the target repo.\nDuring development, I created a single repo for all different repos and used the project name as a branch and the commit\u0026rsquo;s message. When I merge them back to the main branch, the commits will only show up in my contribution graph.\nHow the process_repo code works:\nget_email_addresses: Lists all found email addresses of the contributors Waits for you to select yours as a space-separated list get_filtered_commit_history: Goes through all of the commits and filters yours based on the email selection prepare_repo: Tries to git init the target repo, switches to the new branch called similarly as the given project name. create_commits: Creates new commits into the target repo\u0026rsquo;s target branch by modifying a single file with the commit\u0026rsquo;s date Summary Writing this code gave me some hope that I could have some control over my contribution graph. It was a great exercise, but I might not use it for real at all.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2022/03/13/keep-your-github-contribution-history/","summary":"Have you ever been in a situation where you work for a few repositories over a prolonged time, and all of a sudden, you\u0026rsquo;re notified that you\u0026rsquo;ll no longer have access to these repos in a few weeks?\n","title":"Keep Your Github Contribution History"},{"content":"I came across situations in the past where I needed to modify a pipe just slightly. I immediately knew how to do it imperatively but could not develop a feasible chain of *nix utilities in a reasonable time.\nHere\u0026rsquo;s where my knowledge of a scripting language comes in handy.\nUNIX Philosophy One of the main points of UNIX philosophy is to write simple code.\nPeter H. Salus summarized it well:\nWrite programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams because that is a universal interface. Take this chain, for example.\nseq 1 10 | shuf | tail -5 | sort -n It removes 5 random items from the list 1-10. First, it generates the 10 numbers, then shuffles the list, takes the last five items, and sorts the list back.\nToolbox If you\u0026rsquo;re a command-line magician, the chances are high that you can chain together the built-in utilities to achieve what you need in most situations. If you\u0026rsquo;re familiar with sed or awk, it increases your chances.\nOtherwise, one option would be to save the current stdout to a file and write a script in a language that you\u0026rsquo;re familiar with to process that file. Then continue the pipe from its stdout.\nAnd another option is to process the input Stream.\nThe power of the method I\u0026rsquo;m writing about shows up when you need to do some tricky calculations.\nPipe example For illustration, I created a pipe that writes 20 random numbers into the stdout every second. And the task I came up with for now is to multiply each number by five, pass them forward immediately on stdout, and print the summary at the end.\nThe initpipe function creates this chain into a named pipe called mypipe.\nfunction initpipe { # init 20 random numbers between 1-100 (inclusive) rm -f mypipe mkfifo mypipe seq 1 20 | \\ awk \\ -v min=1 \\ -v max=100 \\ -v seed=${1:-42} \\ \u0026#39;BEGIN{srand(seed);} {print int(min+rand()*(max-min+1)); system(\u0026#34;sleep 1\u0026#34;)}\u0026#39; \\ \u0026gt; mypipe \u0026amp; } I know it\u0026rsquo;s SOOO easy with awk, but let\u0026rsquo;s move on, and see how we can do it in Python and JavaScript.\ninitpipe \u0026#34;$RANDOM\u0026#34;; tee /dev/tty \u0026lt; mypipe | awk \u0026#39;BEGIN {res=0;} {curr=int($1) * 5; res += curr; print(curr); } END { print(res) }\u0026#39; I\u0026rsquo;ll use tee /dev/tty to show the current line to process. It might not be available on every OS. It\u0026rsquo;s not even necessary. It\u0026rsquo;s there for visualization.\nJavaScript If you plan to run JavaScript code in the command line, you need to pick an interpreter and see how it connects to the standard input. I usually choose node.js for this purpose. It uses a readable Stream to access stdin. Then on data event, it spits out a Buffer.\nThe code below loads the processes the stream line by line:\nconst stdin = process.stdin; let result = 0; stdin.on(\u0026#34;data\u0026#34;, (buf) =\u0026gt; { const curr = parseInt(buf.toString().trim()) * 5; process.stdout.write(curr); result += curr; }); stdin.on(\u0026#34;end\u0026#34;, () =\u0026gt; { process.stdout.write(result); }); Save it as, e.g. multiplybyfive.js and call it as:\ninitpipe \u0026#34;$RANDOM\u0026#34;; tee /dev/tty \u0026lt; mypipe | node multiplybyfive.js There can be other solutions by using npm packages, but I aimed for a solution without additional packages.\nNode one-liner If you\u0026rsquo;re into ugly solutions, you can call it without saving it into its separate file:\ninitpipe \u0026#34;$RANDOM\u0026#34;; tee /dev/tty \u0026lt; mypipe | node -e \u0026#39;let i=process.stdin,r=0,o=process.stdout;i.on(\u0026#34;data\u0026#34;,(c)=\u0026gt;{const c=parseInt(c.toString()) * 5;res+=c;);i.on(\u0026#34;end\u0026#34;,()=\u0026gt;{o.write(r)});\u0026#39; Python In python, the sys package lets you access the standard input, and you need to read it line by line.\nimport sys import os result = 0 for line in iter(sys.stdin.readline, \u0026#39;\u0026#39;): curr = int(line) * 5 result += curr sys.stdout.write(str(curr) + os.linesep) sys.stdout.write(str(result) + os.linesep) Python Oneliner The above code would look even uglier than the javascript version, but if you only need the final result, you can use a simplified version:\ninitpipe \u0026#34;$RANDOM\u0026#34;; tee /dev/tty \u0026lt; mypipe | python3 -c \u0026#34;import sys;print(sum([int(line) * 5 for line in iter(sys.stdin.readline, \u0026#39;\u0026#39;)]))\u0026#34; Summary I hope it will help you as much as it will help me.\nHappy coding!\nCover Photo by Rifqi Ramadhan from Pexels\n","permalink":"https://budavariam.github.io/posts/2022/01/02/process-nix-pipe-with-a-script/","summary":"I came across situations in the past where I needed to modify a pipe just slightly. I immediately knew how to do it imperatively but could not develop a feasible chain of *nix utilities in a reasonable time.\nHere\u0026rsquo;s where my knowledge of a scripting language comes in handy.\n","title":"Process *nix pipe with a script"},{"content":"Another year has passed, and the 5th OITM has finished. OITM is an IT championship in Hungary, sponsored by large tech companies.\nThe current championship had 25 challenges across different fields. Every week there\u0026rsquo;s a new round. This year I participated in 13 categories.\nI enjoyed the competition, and I\u0026rsquo;m happy with my results. My favorite categories were the Accessible websites, where we learned about the diverse users of the web, and Python backend development, where most of the questions were about the latest features of Python. I needed to be up to date.\nI learned about the nuances of many fields. The questions helped me refresh my knowledge on topics I don\u0026rsquo;t use in my day-to-day work. And my results reflect the categories that I do work with regularly. I joined the Windows Server category just for fun, and it shows.\nThere were a few 1-hour challenges in the competition that I was unsure about but submitted ahead of time. After submission, I wanted to figure out the result and got it before my clock would have run out. It was an excellent lesson for next time to fight till the end.\nResults This year, first time ever, I got into the TOP 25 in two categories! üéâ\nHere are my results for this year ordered by Percentage:\nCategory name Percentage Exact DevOps 2.97% 12 / 404 React.JS 3.58% 11 / 307 Linux System Development 7.49% 31 / 414 Angular frontend development 13.58% 47 / 346 Containerization (Kubernetes) 13.67% 35 / 256 Accessible websites 15.95% 63 / 395 Language-independent programming and Databases 18.18% 132 / 726 Embedded Systems (C) 20.66% 56 / 271 Python backend development 22.02% 74 / 336 Problem-analysis in Enterprise Systems 22.40% 56 / 250 Cyber Security 23.53% 108 / 459 Industrial Networks 23.98% 53 / 221 Windows Server Operations 43.17% 155 / 359 I am looking forward to it next year!\nHappy Coding!\n","permalink":"https://budavariam.github.io/posts/2021/12/15/oitm-2021/","summary":"Another year has passed, and the 5th OITM has finished. OITM is an IT championship in Hungary, sponsored by large tech companies.\n","title":"OITM 2021"},{"content":"Unless you were under a rock for the past couple of days, I assume you\u0026rsquo;ve heard about log4shell. The RCE exploit of the popular Java logging module log4j, that caused havoc all over the internet. I haven\u0026rsquo;t worked with Java for years, but I\u0026rsquo;m curious if my projects are vulnerable to this exploit. Let\u0026rsquo;s find out.\nIf you prefer, you can call it CVE-2021-44228.\nThe Main problem I found a great tool log4j-detector to check my source codes for nested embedded log4j versions. My problem with it is that it\u0026rsquo;s written in Java, and I didn\u0026rsquo;t want to spend time installing it into my machine.\nI like to work with docker, so I decided to run in it. After a few minutes of search I did not find any suitable image, so I decided to create one instead.\nI put my code on my github repo.\nLuckily it did not find any vulnerable version :) hooray.\nI know that it does not mean that everything is in perfect condition. But it\u0026rsquo;s as good as the tool gets. I will look deeper into this issue to know how to defend against it.\nConclusion I\u0026rsquo;m sure things will move pretty fast, and there will be uprising tools to look for these issues and fix them. Hopefully, we can get over it soon.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/12/14/log4shell-check/","summary":"Unless you were under a rock for the past couple of days, I assume you\u0026rsquo;ve heard about log4shell. The RCE exploit of the popular Java logging module log4j, that caused havoc all over the internet. I haven\u0026rsquo;t worked with Java for years, but I\u0026rsquo;m curious if my projects are vulnerable to this exploit. Let\u0026rsquo;s find out.\n","title":"Log4Shell Check"},{"content":"In Hungary, around the end of the year, we usually have some mandatory transferred workdays, when we have to work on Saturdays instead of the days around holidays. It\u0026rsquo;s not unusual for companies to let their workers spend their time in a more fun way, that\u0026rsquo;s what we did with an optional hackathon.\nRough start When we formed our team before the event, we decided to create a Slack bot to speed up our administration processes. Our team was split up between 2 cities.\nOn the morning of the competition, I started to look into the necessary REST APIs, searched through the internet for more detailed docs. After a few hours, we reached the point where our plan seemed feasible.\nGetting into Slack bot development I had some experience with the now disregarded slack webhooks. Therefore I jumped out of this field to look into how shall we enable interactivity and slash commands, to make our processes more powerful and user-friendly. I searched through docs and tutorials, switched between Python and JavaScript until I stumbled upon a github repo, that promised what I was looking for in the simplest possible way. I fired it up and started to put together the UI in the block kit builder.\nA big surprise Soon after the others dug even deeper into the systems we needed to connect, they realized it\u0026rsquo;s not a simple task, that we would be able to finish in the remaining 4 hours.\nSooooo a change of plans! We found another problem that affects many people, and we can solve it quickly with the tools we already have.\nWhen someone joins the company, it\u0026rsquo;s hard for them to instantly know everyone by name. It\u0026rsquo;s better, if they can associate a face with the names. We already have a site for that, but it would be so much better if we could get that information right in Slack instead of loading the website up. We live in Slack anyways. So we started to make it happen.\nAnd by we, I mean I.\nUnfortunately, I had everything in my machine, and we needed to act fast and make changes in a single file. We could have set up a git repo or VSCode Live Share, but we were in a hurry, and I\u0026rsquo;m used to pair-programming through screen share.\nIt was fun to delegate out Slack admin configurations, UI design and templating for the others while I made sure everything ran smoothly on my machine.\nResult The app is fairly simple. After the proper connection it just waits for POST messages from Slack, validates the messages and sends back the search results.\nWe were able to put together a working POC for the demo. We presented it first without significant glitches in the Slack part.\nI don\u0026rsquo;t want to put out the final result in the wild, with the exact fields and URLs. But I stripped out its essence for a showcase and future reference. It\u0026rsquo;s on github.\nI know that there are better options to accomplish this task, and this base repo is now 2 years old, with deprecated modules. I felt confident to move fast, and I sticked with a working solution instead of wasting time trying to spin up shiny new components.\nUseful docs At the end of the day, I learned how slack slash commands work, and was able to put together a nice-looking slack message from the building blocks. These pages helped me along the way:\nSlack Slash commands Block Kit Block Kit docs Block Kit Reference Slack apps Slack docs Slack API node.js tutorials Summary I felt amazing at the end. Finally, we had accomplished something helpful in such a short timeframe. I hope I can participate in similar events in the future.\nCover Photo by Tima Miroshnichenko from Pexels\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/12/12/starschema-hackathon-2021/","summary":"In Hungary, around the end of the year, we usually have some mandatory transferred workdays, when we have to work on Saturdays instead of the days around holidays. It\u0026rsquo;s not unusual for companies to let their workers spend their time in a more fun way, that\u0026rsquo;s what we did with an optional hackathon.\n","title":"Starschema Hackathon 2021"},{"content":"As I wrote in my last post, I\u0026rsquo;ve been working closely with Microsoft SQL server for a while now. Since then I\u0026rsquo;ve found some more tricks that made my life easier.\nI\u0026rsquo;ve come to realize in the past 2 months that the documentation is pretty thorough. So in this post I\u0026rsquo;ll include them in the relevant parts. I don\u0026rsquo;t plan on explaining these parts in depth, the docs do it better than I would. I\u0026rsquo;d rather share some more code that made my work simpler.\nValidate data before running a costly query In the folowing snipped I run a validation code and print a meaningful message, if it fails.\ndeclare id int = 42; if exists(select * from str_table where try_convert(float, Cost) is null and Cost is not null) begin raiserror( N\u0026#39;Failed to convert a Cost to number for ID: %d (for more details run: select * from huge_str_table where try_convert(decimal(18, 4), DetailLineAmt) is null and DetailLineAmt is not null)\u0026#39; -- Message text ,16 -- Severity ,1 -- State ,@id -- Message Parameters ); end Here I used the raiserror statements. In the it\u0026rsquo;s stated, that new applications should use throw instead of it. I used raiserror because throw does not support custom messages, but the variables that I set up with formatmessage show up as empty messages in my database query tool during development.\nThe N'' prefix at the start of the message indicates that it\u0026rsquo;s an nvarchar, so it can contain unicode characters.\nThe exists statement checks whether a given statement has any results.\nThe if statement can run a block of code that starts with begin and ends with end. It can only have a single else statment. If you need more elif branches you have to nest if-else constucts in the proper branches.\nYou can set a severity for your messages with raiserror, throw will set it automatically to 16, except if you re-throw an exception in a catch statement.\nThe State is useful if the same user-defined error is raised at multiple locations. It can be between 1-255. It can help find which section of code is raising the errors.\nThe error codes under 50000 are reserved for system errors. Throw can not send these system messages, while raiserror can.\nReusing code During this few months I\u0026rsquo;ve been investigating many questions about the data, its validity, and extracted information to business-related questions. Since we were in a hurry I often found myself running the same queries all over again. When I needed to type the same joins for at least 5 times, and they got lost in my console I stopped and tried to automate them, because I was fairly confident that they will come up again later.\nThese constructs were really helpful, their concepts were not new to me. I just want to keep their syntax over here for a quick reference and what point out what makes them different.\nWhen I created these views, functions, and procedures SSMS set me these values. I\u0026rsquo;ll exclude them from my examples, but I used them.\nSET ANSI_NULLS ON GO SET QUOTED_IDENTIFIER ON GO Views When I did not need any dynamism views were my go-to choice. You can think of views as saved sql statements.\ncreate or alter view ActiveCustomers AS select * from dbo.Customers where isDeleted \u0026lt;\u0026gt; 0 ; GO -- select * from ActiveCustomers; The or alter part helped me during development, because I did not need to drop and recreate the views every time.\nFunctions User defined functions (UDF) are similar to views, but they have 2 main differences that were relevant for me.\nthey can receive parameters they can return scalar values instead of tabular data create or alter function fnCheckBalanceAbove ( @lowerBound float ) returns @table table ( CalcTime datetime2(7) ,CompanyID int ) as begin insert into @table ( CalcTime ,CompanyID ) select getutcdate() [CalcTime] CompanyID from Company where Balance \u0026gt;= @lowerBound ; return; end ; go -- select * from fnCheckBalanceAbove(50000) The function can return inline valued table by just wrapping the select into the return statement, but I find it valuable to define the columns that are going to be returned for better readability.\nYou can use multiple queries to fill the defined result table.\nDo not forget that the function must end with a return statment.\nThe huge benefit of funtions, is that their results can be joined to other queries, thus potentially simplify and shorten their code significantly.\nStored procedures When you need to run many operations, you can use stored procedures.\nYou can use parameters just like for functions, but you can do even more things:\nuse a larger set of constructs like try-catch blocks call other stored procedures return multiple resultsets You can not use them inside queries, you need to call them with exec statement.\ncreate or alter proc GetTopNCustomers ( @limit int ) as begin select top(@limit) c.ID ,c.Balance from Customer c order by Balance desc ; end ; GO -- exec GetTopNCustomers @limit = 15; I advise agains returning multiple result sets if you\u0026rsquo;d like to store the results somewhere and not just debugging data, because it\u0026rsquo;s a bit tricky to store the results from a stored procedure call with insert into. You need to have a table that you query the data into.\nSee this code for example from:\nCREATE TABLE #sp_who2 (SPID INT,Status VARCHAR(255), Login VARCHAR(255),HostName VARCHAR(255), BlkBy VARCHAR(255),DBName VARCHAR(255), Command VARCHAR(255),CPUTime INT, DiskIO INT,LastBatch VARCHAR(255), ProgramName VARCHAR(255),SPID2 INT, REQUESTID INT) INSERT INTO #sp_who2 EXEC sp_who2 SELECT * FROM #sp_who2 -- Add any filtering of the results here : WHERE 1=1 and DBName \u0026lt;\u0026gt; \u0026#39;master\u0026#39; and HostName like \u0026#39;%\u0026#39; -- Add any sorting of the results here : ORDER BY DBName ASC DROP TABLE #sp_who2 Summary I hope you found this collection as useful as I did.\nHappy coding!\nCover Photo by Manuel Geissinger from Pexels\n","permalink":"https://budavariam.github.io/posts/2021/11/20/mssql-server-adventures/","summary":"As I wrote in my last post, I\u0026rsquo;ve been working closely with Microsoft SQL server for a while now. Since then I\u0026rsquo;ve found some more tricks that made my life easier.\n","title":"MSSQL Server Adventures"},{"content":"In the past couple of weeks I\u0026rsquo;ve started to work with Microsoft SQL Server. I have a pretty good founation of SQL from high school, but I\u0026rsquo;ve only used PostgreSQL so far in my carreer. I collect the snippets I found to be the most useful ones that helped me getting started.\nI\u0026rsquo;ve learned SQL the same way as I did HTML, with uppercase letters. Nowadays if I write it like that it feels like I\u0026rsquo;m screaming, so I choose to stick with lowercase keywords for it.\nI needed to get to know a system that uses MSSQL Server, so in this post I\u0026rsquo;m going to focus on getting metadata out and not on the CRUD part.\nMicrosoft SQL Server Management Studio (SSMS) Every time I looked for a bit more advanced thing to ask from the server I found that the SSMS is supposed to be able to do it. Currently I do not have a windows environment for development, so I did not go chose this path.\nI prefer writing queries than clicking on UI, to get more easily reproducible evidence of what I got for further reference.\nIt seems to be the go-to tool to use with MSSQL Server, so I\u0026rsquo;d recommend you to check it out.\nRun MSSQL Server Localy Microsoft maintains an official docker image for mssql server, that\u0026rsquo;s the simplest way to get started.\n# set password, NOTE: if you prepend with a space it won\u0026#39;t show up in history in many shells PASSWORD=\u0026#39;MyStrong!Password\u0026#39; # Run in Docker docker run \\ -d \\ --name \u0026#39;mssql_server\u0026#39; \\ -e \u0026#39;ACCEPT_EULA=Y\u0026#39; \\ -e \u0026#34;SA_PASSWORD=$PASSWORD\u0026#34; \\ -p 1433:1433 \\ mcr.microsoft.com/mssql/server:2019-latest # Connect to the server with sqlcmd docker exec -it \u0026#39;mssql_server\u0026#39; /opt/mssql-tools/bin/sqlcmd \\ -S localhost \\ -U sa \\ -P \u0026#34;$PASSWORD\u0026#34; Common tasks List Tables of a Database information_schema.tables stores the table information.\nselect * from [MyDatabase].[information_schema].[tables] order by 2,3; Second column is schema. Third Column is table_name.\nTOP I\u0026rsquo;m used to writing the top statement to limit the query esults at the end of the query. In MSSQL it\u0026rsquo;s right at the start of the select statement.\nselect top 1000 * from [MyDatabase].[dbo].[Log] order by createDate desc; Get Indices I needed to get indexes, and found a simple article to help me query them.\nselect i.[name] as index_name ,substring(column_names, 1, len(column_names)-1) as [columns] ,schema_name(t.schema_id) + \u0026#39;.\u0026#39; + t.[name] as table_view ,case when i.[type] = 1 then \u0026#39;Clustered index\u0026#39; when i.[type] = 2 then \u0026#39;Nonclustered unique index\u0026#39; when i.[type] = 3 then \u0026#39;XML index\u0026#39; when i.[type] = 4 then \u0026#39;Spatial index\u0026#39; when i.[type] = 5 then \u0026#39;Clustered columnstore index\u0026#39; when i.[type] = 6 then \u0026#39;Nonclustered columnstore index\u0026#39; when i.[type] = 7 then \u0026#39;Nonclustered hash index\u0026#39; end as index_type ,case when i.is_unique = 1 then \u0026#39;Unique\u0026#39; else \u0026#39;Not unique\u0026#39; end as [unique] ,case when t.[type] = \u0026#39;U\u0026#39; then \u0026#39;Table\u0026#39; when t.[type] = \u0026#39;V\u0026#39; then \u0026#39;View\u0026#39; end as [object_type] from sys.objects t inner join sys.indexes i on t.object_id = i.object_id cross apply ( select col.[name] + \u0026#39;, \u0026#39; from sys.index_columns ic inner join sys.columns col on 1=1 and ic.object_id = col.object_id and ic.column_id = col.column_id where 1=1 and ic.object_id = t.object_id and ic.index_id = i.index_id order by key_ordinal for xml path (\u0026#39;\u0026#39;) ) D (column_names) where t.is_ms_shipped \u0026lt;\u0026gt; 1 and index_id \u0026gt; 0 order by i.[name] List foreign keys I found a simple article to query all foreign keys in the database.\nselect schema_name(fk_tab.schema_id) + \u0026#39;.\u0026#39; + fk_tab.name as foreign_table, \u0026#39;\u0026gt;-\u0026#39; as rel, schema_name(pk_tab.schema_id) + \u0026#39;.\u0026#39; + pk_tab.name as primary_table, substring(column_names, 1, len(column_names)-1) as [fk_columns], fk.name as fk_constraint_name from sys.foreign_keys fk inner join sys.tables fk_tab on fk_tab.object_id = fk.parent_object_id inner join sys.tables pk_tab on pk_tab.object_id = fk.referenced_object_id cross apply ( select col.[name] + \u0026#39;, \u0026#39; from sys.foreign_key_columns fk_c inner join sys.columns col on 1=1 and fk_c.parent_object_id = col.object_id and fk_c.parent_column_id = col.column_id where 1=1 and fk_c.parent_object_id = fk_tab.object_id and fk_c.constraint_object_id = fk.object_id order by col.column_id for xml path (\u0026#39;\u0026#39;) ) D (column_names) order by schema_name(fk_tab.schema_id) + \u0026#39;.\u0026#39; + fk_tab.name, schema_name(pk_tab.schema_id) + \u0026#39;.\u0026#39; + pk_tab.name List columns sp_columns is a stored proceure that lists column information of the specified objecct.\nexec sp_columns [MyTable]; Use Variables Sometimes it helps to get data from variables into the queries.\ndrop table if exists #temptable; declare @uuid varchar(100); set @uuid = \u0026#39;123e4567-e89b-12d3-a456-426652340000\u0026#39;; select uuid = @uuid into #temptable; select * from #temptable; GO In this example you can also see the handy select into statement, that inserts the result into a table if the table does not already exists.\nGet values from freshly modified lines The Output clause can show values for you in the console or store them into variables.\ncreate table dbo.employees ( id int identity primary key, employee varchar(32)); go insert into dbo.employees output INSERTED.* -- output to console values (\u0026#39;Fred\u0026#39;) ,(\u0026#39;Tom\u0026#39;) ,(\u0026#39;Sally\u0026#39;) ,(\u0026#39;Alice\u0026#39;); go declare @deletedLinesTableVar table ( id int, employee VARCHAR(32) ); print \u0026#39;employees before deletion\u0026#39;; select * from dbo.employees; delete from dbo.employees output DELETED.* into @deletedLinesTableVar -- output into table variable where id = 4 or id = 2; print \u0026#39;employees, after deletion\u0026#39;; select * from dbo.employees; print \u0026#39;@deletedLinesTableVar, after deletion\u0026#39;; select * from @deletedLinesTableVar; drop table dbo.employees; The print statement prints values into the console.\nStored Procedures Stored procedures are reusable blocks of SQL code that you can run.\nGet All Defined Stored Procedure Codes You can query the code of the available procedures.\nselect [definition] from sys.sql_modules where object_id = (OBJECT_ID(N\u0026#39;dbo.myStoredProcedureName\u0026#39;)); select [definition] from sys.sql_modules; Create and Run a Stored Procedure use MyDatabase; go; create or alter proc [dbo].[myStoredProcedureName] ( @message varchar(100) ,@debug bit = 0 ) as set nocount on; declare @sql nvarchar(max) set @sql = concat( \u0026#39;select \u0026#39; ,@message ); if (@debug = 1) print @sql; else exec sp_executesql @sql; ; go Call it with parameters.\nexec dbo.myStoredProcedureName @message = \u0026#39;world\u0026#39;, @debug = 1; Show Last Few Queries Out of this handy MSSQL Server SQL collection I found a useful query to see the last few successful queries.\nselect deqs.last_execution_time as [Time], dest.text as [Query], dest.* from sys.dm_exec_query_stats as deqs cross apply sys.dm_exec_sql_text(deqs.sql_handle) as dest --where dest.dbid = DB_ID(\u0026#39;msdb\u0026#39;) order by deqs.last_execution_time desc; Show Connections And Queries sp_who provides information about current users, sessions, and processes in an instance of the Microsoft SQL Server Database Engine.\nexec sp_who exec sp_who2 sp_who2 is undocumented and disregarded though used widely, and it provides extra columns and more compact display.\nIf the status shows SUSPENDED, then the query might be blocked by a lock.\nShow locks sp_lock shoows information about current locks. It\u0026rsquo;s recommended to use sys.dm_tran_locks for new development.\nexec sp_lock; -- sys.dm_tran_locks select resource_type, resource_associated_entity_id, request_status, request_mode,request_session_id, resource_description from sys.dm_tran_locks CLI SQLCmd is a command line tool that can be used to connect to MSSQL server, to run scripts from local filesystem.\nsqlcmd -S \u0026#34;devdb.company.com,1433\u0026#34; \\ -d \u0026#39;MyDatabase\u0026#39; \\ -U \u0026#39;user\u0026#39; \\ -P \u0026#34;$PASSWORD\u0026#34; \\ -i \u0026#39;./my-migration.sql\u0026#39;; In case you run the docker version, make sure you add your file as a volume.\nGO Command GO command signals the end of a batch of Transact-SQL statements to the SQL Server utilities.\nSummary I hope this collection will be useful for you, and will help me later if I ever need to work with MSSQL again.\nHappy coding!\nCover Photo by Manuel Geissinger from Pexels\n","permalink":"https://budavariam.github.io/posts/2021/09/29/mssql-server-basics/","summary":"In the past couple of weeks I\u0026rsquo;ve started to work with Microsoft SQL Server. I have a pretty good founation of SQL from high school, but I\u0026rsquo;ve only used PostgreSQL so far in my carreer. I collect the snippets I found to be the most useful ones that helped me getting started.\n","title":"MSSQL Server Basics"},{"content":"I have access to a Google Calendar, that contains the absence of all my colleagues as full day events. I work with a mostly remote team, and sometimes it\u0026rsquo;s useful to know when will my teammates leave for vacation, even if they don\u0026rsquo;t tell me many days in advance.\nI wrote a simple script, to look through the events every monday and filter the ones I\u0026rsquo;m interested in, then send me an email report.\nHow it works It is avaliable on github. It needs to be configured for your needs before you run it.\nThe script runs in Google Apps Script. It fetches the events of a given external calendar that contains the abscence information. It queries the calendar for a given timeframe, and looks through the events in them, matching each of them with a predefined list of colleagues. In my case it runs every monday morning for the week.\nOn the second stage it puts the found users into an HTML table for each separate teams. One user per row, one day per column. The available times will be shown as green, the absence days will appear as yellow with a dot in them. The tables only show up for teams that have absences. If there are no absences a short message indicates, that we operate on full load.\nFinally an email is sent to all recipients separately who wanted access for this report. If there are no absences an email is still going to be sent, to show that the service works.\nWhat\u0026rsquo;s Google Apps Script Google Apps Script is a developer SaaS tool, that can be used to automate simple tasks. You can extend your Google Apps with simple scripts. It can use the API-s of Google services like calendar or gmail.\nYou can run the scripts as many times you\u0026rsquo;d like. You can step through code with a debugger. You can automate your tasks with time based triggers, or even on calendar modifications. Usage Limits You can find more details on the quotas at Google Developers site.\nCurrently it\u0026rsquo;s a free to use, if a script reaches a quota or limitation, it throws an exception with a message that gives more detailed information of the problem.\nService Status In case you face an error that really should not happen, there\u0026rsquo;s a chance that the service has some temporary issues. You can check the outage logs for detailed information on incidents.\nMy former experience This is my second project in this platform. I struggled with finding a solution to keep multiple google calendars in sync, I\u0026rsquo;ve decided to keep it closer to the fire and use Apps Scripts for it. I\u0026rsquo;ve a solution that had the basis of what I needed so I tweaked to fit my use-case exactly. My fork is available on github.\nI loved its simplicity and clear interface, so I decided to use it for this project as well.\nGetting Started Subscribe to the calendar that has the Absence information in Google Calendar.\nOpen Google Apps Scripts home page.\nClick on New project on the top left corner\nUpdate the contents of Code.gs from the git repo.\nIn the Project Settings menu, tick in Show \u0026quot;appsscript.json\u0026quot; manifest file in editor and update its contents from the repository\nSet up the config values with proper data:\nSOURCE_CALENDARS: the Absence report PEOPLE: the people you\u0026rsquo;d like to track, the names MUST match with the names used in the calendar NOTIFICATION_MAIL_ADDRESSES: the people you\u0026rsquo;d like to notify const SOURCE_CALENDARS = { \u0026#34;[Absence]\u0026#34;: \u0026#34;starwarsteam.calendarid@group.calendar.google.com\u0026#34;, }; // Team members whose abscence we want to get notified of const PEOPLE = [ { name: \u0026#34;Budav√°ri M√°ty√°s\u0026#34;, nick: \u0026#34;Matyi\u0026#34;, team: \u0026#34;Earth\u0026#34; }, { name: \u0026#34;Luke Skywalker\u0026#34;, nick: \u0026#34;Luke\u0026#34;, team: \u0026#34;Jedi\u0026#34; }, { name: \u0026#34;Anakin Skywalker\u0026#34;, nick: \u0026#34;Darth Vader\u0026#34;, team: \u0026#34;Sith\u0026#34; }, { name: \u0026#34;R2-D2\u0026#34;, nick: \u0026#34;Artu\u0026#34;, team: \u0026#34;Droid\u0026#34; }, { name: \u0026#34;C3PO\u0026#34;, nick: \u0026#34;Golden Guy\u0026#34;, team: \u0026#34;Droid\u0026#34; }, ]; // Who should get these emails const NOTIFICATION_MAIL_ADDRESSES = [\u0026#34;budavariam@gmail.com\u0026#34;]; In the Code view select the SendAbsenceReport function, and click the Play button, to run the script, and make it ask for the proper authentication\nClick on Triggers menu, and on the bottom right corner click: Add Trigger\nfunction: SendAbsenceReport deployment: HEAD event source: Time driven time based trigger: Week timer day of the week: Every Monday time of the day: 7am to 8am failure notification: weekly Enjoy your weekly report.\nFurther Development Ideas Look into if it\u0026rsquo;s possible to send a single email and use bcc for the same reports Set up different reports for different people Send notification if a new event appears during the week Disclaimer I\u0026rsquo;m not affiliated with Google in any way, I just wanted to share my custom solution on their cool platform.\nCover Photo by Julius Silver from Pexels\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/09/25/calendar-based-absence-reporting/","summary":"I have access to a Google Calendar, that contains the absence of all my colleagues as full day events. I work with a mostly remote team, and sometimes it\u0026rsquo;s useful to know when will my teammates leave for vacation, even if they don\u0026rsquo;t tell me many days in advance.\nI wrote a simple script, to look through the events every monday and filter the ones I\u0026rsquo;m interested in, then send me an email report.\n","title":"Calendar Based Absence Reporting"},{"content":"In the past few days I\u0026rsquo;ve been working with a code where I needed to see whether the service successfully sends mails through SMTP. I did not want to use or set up an actual mail server locally. As is turns out Python has a oneliner to solve this situation.\nPython oneliner Python by default has a module called smtpd, that you can use to event implement SMTP servers. Though it\u0026rsquo;s deprecated in favor of aiosmtpd, it\u0026rsquo;s still useful for my purposes, namely to intercept outgoing messages.\npython -m smtpd -n -c DebuggingServer localhost:2500 It\u0026rsquo;s as simple as this.\nTest it out For testing out that it really works, I used telnet.\ntelnet localhost 2500 # The lines below should be typed into telnet, WITHOUT the starting `\u0026gt;` \u0026gt; helo localhost \u0026gt; mail from: sender@example.com \u0026gt; rcpt to: receiver@example.com \u0026gt; data Subject: Integration test email #1 This template is used by integration tests only. \u0026gt; . \u0026gt; quit And the message will appear in stdout of the DebuggingServer.\n---------- MESSAGE FOLLOWS ---------- Subject: Integration test email #1 X-Peer: 127.0.0.1 This template is used by integration tests only. ------------ END MESSAGE ------------ Happy coding!\nCover Photo by Ylanite Koppens from Pexels\n","permalink":"https://budavariam.github.io/posts/2021/08/04/quickly-test-mail-sending-through-smtp/","summary":"In the past few days I\u0026rsquo;ve been working with a code where I needed to see whether the service successfully sends mails through SMTP. I did not want to use or set up an actual mail server locally. As is turns out Python has a oneliner to solve this situation.\n","title":"Quickly test mail sending through SMTP"},{"content":"Recently I tried Github actions to deploy some of my static sites, and I\u0026rsquo;ve been quite happy with its capabilities. Let me share my configs for different kinds of setups.\nWhat is Github Actions Github Actions is an embedded CI/CD pipeline of Github. You need to define the workflow files in yml files under .github folder in the repository root folder, and you can unleash its true power.\nIts main benefit is that it\u0026rsquo;s a Github service embedded in, and you can use it for free until (at the time of writing) 2000 build minutes per month. More info about pricing here.\nCreate React App on Github Pages Create React App is a popular starter project for react.js applications.\nExample repo\nThe tricky part is that if you use your Github pages site without a domain, it will serve your site in a subpath, BUT by default, Create-React-App assumes you serve it from the root.\nIn package.json, you need to set the \u0026quot;homepage\u0026quot; property to the name of the repository, starting with a forward slash.\nFor example, in my asciiart-text site, I needed to add:\n{ \u0026#34;homepage\u0026#34;: \u0026#34;/asciiart-text\u0026#34; } Hugo site on Github Pages Hugo claims to be the fastest static site generator, and I can not agree more.\nExample repo\nI publish my blog to Github pages built with Hugo.\nGatsby Static site on Github Pages Gatsby is an incredible static site generator based on react.\nExample repo\nThere are different predefined workflows for many static site generators, and I found one for gatsby. It worked fine, but I could not make it publish from a subdirectory, though it said in the docs. I spent a little time investigating, only to figure that the owner did not release the last version, so I forked it and fixed it for me.\nDisclaimer I have no affiliation with Github, and I just wanted to share my experience and collect my configs for future reference.\n","permalink":"https://budavariam.github.io/posts/2021/05/17/deploy-with-github-actions/","summary":"Recently I tried Github actions to deploy some of my static sites, and I\u0026rsquo;ve been quite happy with its capabilities. Let me share my configs for different kinds of setups.\n","title":"Deploy With Github Actions"},{"content":"I started to run on a weekly basis in last August, I\u0026rsquo;m fascinated with the data I can collect from each run. I\u0026rsquo;ve been using Strava ever since. While I was preparing for my previous post about plotly-dash, I decided to dust off my knowledge by creating a simple app to visualize my heartrate data in different activities.\nWhen I started out with plotly-dash development the most confusing part for me was that I already knew plotly as a js chart lib, not as python code.\nWith dash you can basically write your component interactions in python. For simple usecases you would not need to write any javascript at all. Under the hood it serves a React app and renders the same js plotly lib I was familiar with.\nNow let\u0026rsquo;s see the interesting parts from this github repository. Live site is available here.\nAuthentication In dash applications all the necessary elements have to be rendered on startup. I have a simple and straightforward layout, one div for authenticated and one for unauthenticated items.\nA single callback manages the login flow with the help of stravalib.\nThe auth flow was hugely inspired by AartGoossens/strava-dash-boilerplate. The difference is that they switch rendered items, but I can not live with such dash warnings and errors during development.\nStatic files and Clientside callbacks Dash looks for files automagically from the assets folder. In order to serve images I could simply reference them from this assets folder, but I wanted to see if I can have more control over it.\nI added a simple clientside callback just for showcase, it could be done in python side.\nSimple way You can use /assets/ prefix for your asset paths by default.\napp = dash.Dash(__name__) app.layout = html.Div([ html.Img(src=\u0026#39;/assets/image.png\u0026#39;) ]) Flask Routes You can use custom path with @app.server.route.\nfrom flask import send_from_directory app = dash.Dash(__name__) @app.server.route(\u0026#39;/static/\u0026lt;path\u0026gt;\u0026#39;) def serve_static(path): return send_from_directory(\u0026#39;assets\u0026#39;, path) Custom Component I added the custom component to the same repository for simplicity. It could live on its own.\nI like that I can develop components in React.\nDemo React page The demo page is tweakable and it can showcase different usecases, similar to storybook. It\u0026rsquo;s a separate app.\n{ \u0026#34;scripts\u0026#34;: { \u0026#34;build:demo\u0026#34;: \u0026#34;webpack --mode production --config ./webpack.serve.config.js\u0026#34; } } I added a simple github actions script to deploy to github-pages. You can see it live here.\njobs: deploy: runs-on: ubuntu-latest strategy: matrix: node-version: [14.x] steps: - uses: actions/checkout@v1 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v1 with: node-version: ${{ matrix.node-version }} - name: Install Packages run: cd ./activity_selector \u0026amp;\u0026amp; npm install - name: Build page run: cd ./activity_selector \u0026amp;\u0026amp; npm run build:demo - name: Deploy to gh-pages uses: peaceiris/actions-gh-pages@v3 with: publish_dir: ./activity_selector/dist github_token: ${{ secrets.GITHUB_TOKEN }} Deploy new version The base cookiecutter scripts do not provide good packaging script by default I usually roll my own solutions for it.\n{ \u0026#34;scripts\u0026#34;: { \u0026#34;presdist\u0026#34;: \u0026#34;npm run build\u0026#34;, \u0026#34;sdist\u0026#34;: \u0026#34;rm -r ./dist/; python setup.py sdist\u0026#34;, \u0026#34;postsdist\u0026#34;: \u0026#34;(. venv/bin/activate || venv\\\\scripts\\\\activate \u0026amp;\u0026amp; bash ./script_postsdist.sh)\u0026#34;, \u0026#34;sdist:version:activated\u0026#34;: \u0026#34;(. venv/bin/activate || venv\\\\scripts\\\\activate \u0026amp;\u0026amp; npm version patch \u0026amp;\u0026amp; npm run sdist)\u0026#34;, \u0026#34;sdist:activated\u0026#34;: \u0026#34;(. venv/bin/activate || venv\\\\scripts\\\\activate \u0026amp;\u0026amp; npm run sdist)\u0026#34; } } #!/bin/bash ## script_postsdist.sh # assume that the virtual env has been activated and pwd is the project root directory pushd .. rm ./activity_selector-*.tar.gz mv ./activity_selector/dist/activity_selector-* . NEW_FILE=$(find . -name \u0026#39;activity_selector*\u0026#39; -maxdepth 1 | head -1 | xargs basename) sed -i.bak \u0026#34;s/activity_selector-\\S*/$NEW_FILE/\u0026#34; ./requirements.txt rm ./*.bak pip install \u0026#34;./$NEW_FILE\u0026#34; popd || exit 1 With a simple cd activity_selector \u0026amp;\u0026amp; npm run sdist:version:activated command (after dependency installs), I can update the package in my app, it rewires the dependencies as well.\nDockerize environment In order to see how it looks in the deploy environment in an easily reproducible way I decided to dockerize the app.\nMultistage build keeps my image small, the base image and requirements.txt keeps my dependencies the same between installs. Gunicorn provides a production grade server to deploy the app.\nFROM python:3.6.13 as base FROM base as builder RUN mkdir /install WORKDIR /install COPY requirements.txt /requirements.txt COPY ./*.tar.gz . RUN pip install --no-cache-dir --prefix=/install --no-warn-script-location -r /requirements.txt FROM base COPY --from=builder /install /usr/local WORKDIR /app RUN mkdir -p logs COPY ./src ./src COPY ./assets ./assets COPY ./logconfig.conf ./logconfig.conf EXPOSE 5000 CMD gunicorn --bind 0.0.0.0:5000 --chdir ./src --log-config /app/logconfig.conf app:server Development experience I debugged my code from VSCode. Kept my config variables in a .env file in the project root folder.\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Start Dev Server\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceRoot}/src/app.py\u0026#34;, \u0026#34;console\u0026#34;: \u0026#34;integratedTerminal\u0026#34;, \u0026#34;env\u0026#34;: { \u0026#34;DEBUG\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;PYTHONPATH\u0026#34;: \u0026#34;${workspaceRoot}/src\u0026#34; }, \u0026#34;envFile\u0026#34;: \u0026#34;${workspaceRoot}/.env\u0026#34;, \u0026#34;python\u0026#34;: \u0026#34;${workspaceRoot}/src/venv/bin/python\u0026#34;, \u0026#34;justMyCode\u0026#34;: true } ] } I used 3 separate terminals:\ncd activity_selector \u0026amp;\u0026amp; npm start to continously build the custom component. See changes live at http://0.0.0.0:55554. One console to run VSCode debugger at One open console to update the component in the root app with: pip install -e ./activity_selector I had much fun creating these configs for the project.\nHappy Coding!\n","permalink":"https://budavariam.github.io/posts/2021/04/08/strava-activities-with-plotly/","summary":"I started to run on a weekly basis in last August, I\u0026rsquo;m fascinated with the data I can collect from each run. I\u0026rsquo;ve been using Strava ever since. While I was preparing for my previous post about plotly-dash, I decided to dust off my knowledge by creating a simple app to visualize my heartrate data in different activities.\n","title":"Strava Activities With Plotly"},{"content":"Last year I was working on some dash-plotly applications/dashboards. It was confusing at first, I learned a lot during that time, I\u0026rsquo;d like to share my gathered experience. The docs already contain useful information, I do not wish to repeat them. There are many example pages in github, my goal is to collect my most visited pages here, so it\u0026rsquo;ll be easier to start out with development.\nUseful links for getting started dash.plotly.com/layout dash tutorials and concepts, great starting point dash.plotly.com/basic-callbacks Info on callbacks dash.plotly.com/callback-gotchas. Note the rules of callbacks. They\u0026rsquo;re important, so I copy them here: Callbacks require their Inputs, States, and Output to be present in the layout Callbacks require all Inputs and States to be rendered on the page A component/property pair can only be the Output of one callback All callbacks must be defined before the server starts All Dash Core Components in a layout should be registered with a callback. legacy rule Callback Definitions Don\u0026rsquo;t Need To Be In Lists I prefer lists, since it\u0026rsquo;s easy to forget to add it to all return values when switching around plotly.com/python a lot of plotly examples plotly.com/python/reference very useful reference docs on the available properties github.com/plotly/plotly.js plotly.js git repo: issues and source code are gold github.com/plotly/dash-recipes recipes for advanced usecases github.com/ucg8j/awesome-dash curated list of further reading material, libs, talks and more tutorial to clear up confusion about customdata hovertemplate optional: dash-bootstrap-components 3rd party responsive components pandas cheatsheet Dash clientside callbacks https://dash.plotly.com/clientside-callbacks\nNote: All examples use a single output, but we can pass an array as return value\nSome examples can be found here (test_clientside.py)\nIf you do not want to update a value return window.dash_clientside.no_update If you do not want to update at all in that callback throw window.dash_clientside.PreventUpdate as an exception Access plotly events in dash Note: the events can only be accessed from clientside.\nThis document shows what you can do with plotly events.\nIf you define a callback that is called after the figure has been created/updated, you can subscribe to the plot events\n// works if the plot\u0026#39;s id is main-plot let plotlyGraph = document.querySelector(\u0026#34;#main-plot .js-plotly-plot\u0026#34;); plotlyGraph.on(\u0026#34;plotly_animatingframe\u0026#34;, (anim) =\u0026gt; console.log( \u0026#34;Frame: %s, frameData: %o, animationSettings: %o\u0026#34;, anim.name, anim.frame, anim.animation ) ); Note: if you register an eventlistener multiple times it will call its callback multiple times (as you told them to)\nNote: you can only subscribe to events if the plot has appeared in the DOM\nUnsubscribe from events Plotly.js uses a NodeJS style EventEmitter API\nSource code\ngraphDiv.removeListener(\u0026#34;plotly_click\u0026#34;, handler); graphDiv.removeAllListeners(\u0026#34;plotly_click\u0026#34;); All possible events Here\u0026rsquo;s the list of all available events extracted from the source code:\n\u0026#34;plotly_afterexport\u0026#34;; \u0026#34;plotly_afterplot\u0026#34;; \u0026#34;plotly_animated\u0026#34;; \u0026#34;plotly_animating\u0026#34;; \u0026#34;plotly_animatingframe\u0026#34;; \u0026#34;plotly_animationinterrupted\u0026#34;; \u0026#34;plotly_autosize\u0026#34;; \u0026#34;plotly_beforeexport\u0026#34;; \u0026#34;plotly_buttonclicked\u0026#34;; \u0026#34;plotly_click\u0026#34;; \u0026#34;plotly_clickannotation\u0026#34;; \u0026#34;plotly_deselect\u0026#34;; \u0026#34;plotly_doubleclick\u0026#34;; \u0026#34;plotly_framework\u0026#34;; \u0026#34;plotly_hover\u0026#34;; \u0026#34;plotly_react\u0026#34;; \u0026#34;plotly_redraw\u0026#34;; \u0026#34;plotly_relayout\u0026#34;; \u0026#34;plotly_relayouting\u0026#34;; \u0026#34;plotly_restyle\u0026#34;; \u0026#34;plotly_selected\u0026#34;; \u0026#34;plotly_selecting\u0026#34;; \u0026#34;plotly_sliderchange\u0026#34;; \u0026#34;plotly_sliderend\u0026#34;; \u0026#34;plotly_sliderstart\u0026#34;; \u0026#34;plotly_transitioned\u0026#34;; \u0026#34;plotly_transitioning\u0026#34;; \u0026#34;plotly_transitioninterrupted\u0026#34;; \u0026#34;plotly_unhover\u0026#34;; \u0026#34;plotly_update\u0026#34;; \u0026#34;plotly_webglcontextlost\u0026#34;; My extraction method I cloned the plotly.js git repo. Then run a search for all unique occurances of the plotly events that were sent with emit by using ag, the silver seracher.\ngit clone git@github.com:plotly/plotly.js.git cd plotly.js ag --noheading --nogroup -o --nonumbers --nofile \u0026#34;gd.emit\\(\u0026#39;plotly_[^\u0026#39;]+\u0026#39;\u0026#34; | sort -u Dynamic update Docs: live-updates\nIn dash in order to change the value of a prop in a callback, you can only respond to other callbacks, and only with one value for one callback. If you periodically need to update a value, you need to have something, that continuously triggers an event (change a prop, that is used as callback input), that you can respond to.\nYou can use a ticker to call a callback periodically, you can use it\u0026rsquo;s value both in clientside and serverside callbacks\nimport dash_core_components as dcc dcc.Interval(id=\u0026#39;my-interval\u0026#39;, interval=100) app.clientside_callback( ClientsideFunction(\u0026#39;clientside\u0026#39;, \u0026#39;my-updater-function\u0026#39;), [Output(\u0026#34;change\u0026#34;, \u0026#34;change-this-prop\u0026#34;)], [Input(\u0026#34;my-interval\u0026#34;, \u0026#34;n_intervals\u0026#34;)] ) Reference: https://dash.plotly.com/dash-core-components/interval\nNote: If you set the attributes of a DOM item from arbitrary js code, e.g. event handlers, it won\u0026rsquo;t trigger a callback.\nYou can only respond to callback with one value, here\u0026rsquo;s where this component shines, it lets you periodically call a callback, and set any other value.\nDownside of interval The ticker will communicate with the server in the given interval, if you need a fast dashboard this might not be the best idea, to sync the state with the dash server. It will most likely degrade performance with more and more users.\nIf you have the option to pass down all the necessary data, with clientside callbacks and global variables in javascript code, you can create lightning fast dashboards.\nAnimations Docs: animations\nconst plotlyGraph = document.querySelector(\u0026#34;#main-plot .js-plotly-plot\u0026#34;); plotlyGraph.on(\u0026#34;plotly_animated\u0026#34;, (a) =\u0026gt; console.log(\u0026#34;animation has finished plotly_animated event\u0026#34;, a) ); plotlyGraph.on(\u0026#34;plotly_animating\u0026#34;, (a) =\u0026gt; console.log(\u0026#34;animation has started plotly_animating event\u0026#34;, a) ); plotlyGraph.on(\u0026#34;plotly_animatingframe\u0026#34;, (a) =\u0026gt; console.log(\u0026#34;call on each frame plotly_animatingframe event\u0026#34;, a) ); plotlyGraph.on(\u0026#34;plotly_animationinterrupted\u0026#34;, (a) =\u0026gt; console.log(\u0026#34;pause btn clicked plotly_animationinterrupted event\u0026#34;, a) ); State vs Input Docs: forum post\nThe @app.callback decorator can have 3 parameters, Inputs, Outputs, and States. Input triggers a refresh on change, State does not, only use the latest version of the value, that is available when the callback runs.\nWhen you load the page for the first time, all callbacks will be called with the initial value. If you calculate default values in the beginning, and you want to use them in an other callback, then if you add them as an Input, it will wait for that data, BUT if you add it as a State it won\u0026rsquo;t wait for it, it will use the data that has been calculated until that point that your callback has been called.\n@app.callback( output=[ # the result of the callback will set the given prop on the given element Output(\u0026#39;my-link\u0026#39;, \u0026#39;href\u0026#39;), ], inputs=[ # if it changes it triggers a callback call Input(\u0026#39;url\u0026#39;, \u0026#39;search\u0026#39;), ], state=[ # if it changes it does not trigger a callback call # but the value is available as a prameter State(\u0026#39;strava-auth\u0026#39;, \u0026#39;data\u0026#39;), ] ) def login_verdict(url, auth_data): print(url, auth_data) return [\u0026#34;https://dash.plotly.com\u0026#34;] Prevent update of outputs In case you do not need to refresh all values in a callback, you can tell plotly that it should keep the previous value, and thus it will not trigger other callback that depend on that value.\nOtherwise if you\u0026rsquo;d set the same value as before, then dash would think, that a new value have arrived, and calls the next callbacks in the chain.\nThere are 2 types of preventions:\nprevent any kind of update in the callback. It is called PreventUpdate, it should be raised as an exception do not update a single value it is called no_update, it should be returned as a value Clientside callback In javascript:\nreturn window.dash_clientside.no_update throw window.dash_clientside.PreventUpdate Serverside callbacks In python:\nfrom dash.exceptions import PreventUpdate import dash @app.callback(...) def callback_prevent_all(): raise PreventUpdate @app.callback(...) def callback_prevent_some(): return [any_value, dash.no_update, any_other_value] Store simple runtime data We should not use global variables in plotly python code, since it will be changed for all users.\nWe can use global variables in javascript, since it will be only used for that client, but only for that one browser tab.\nIn case we want to share arbitrary data between the clientside and serverside, we can create a hidden div, and set it\u0026rsquo;s data attributes. It can be accessed in Input, Output and State of callbacks.\nReference https://dash.plotly.com/dash-html-components/div\ndata-* (string; optional): A wildcard data attribute\nimport dash_html_components as html html.Div(id=\u0026#34;hidden-data-value\u0026#34;, style=dict(display=\u0026#34;none\u0026#34;), **{ \u0026#34;data-value-1\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;data-value-2\u0026#34;: \u0026#34;false\u0026#34; }), Note: the values stored in data-attributes are strings.\nOne simple usecase is if you have a quickly changing data, you can store it in JS global variable, and have a clientside callback that stores it in a data prop of a div every 100ms, and then you can react to its changes in these fixed sampled times even from python code.\ndcc.Store Docs: Store\nA better way to handle shared data is dash_core_components.Store.\nIt can store data in:\nmemory storage_type='memory' (default) localstorage storage_type='local' sessionstorage storage_type='session' Empty value is None, I prefer to store dict in this type, can not store list since it is not JSON enumerable, but it can be embedded in a dict.\nHandle URL Some basic examples, and concepts: urls\nReference for Location element\nCallback context Docs: Callback context\nIf an input triggers a callback to run, by default you won\u0026rsquo;t have an idea of which component triggered it. Luckily now callback contexts are available, and you can split your logic across that information as well.\n# inside a callback ctx = dash.callback_context if not ctx.triggered: trigger_id = \u0026#39;-\u0026#39; else: trigger_id = ctx.triggered[0][\u0026#39;prop_id\u0026#39;].split(\u0026#39;.\u0026#39;)[0] ctx_msg = json.dumps({ \u0026#39;states\u0026#39;: ctx.states, \u0026#39;triggered\u0026#39;: ctx.triggered, \u0026#39;inputs\u0026#39;: ctx.inputs }, indent=2) Custom components If you need custom behavior and you\u0026rsquo;re not afraid of react, I strongly advise you to create custom components. Basically write only React.js code.\nDefined props can be updated with the usual callbacks, it can tell dash, that it\u0026rsquo;s input data has changed, and trigger other callbacks that depend on that data.\nBenefits I think in general it\u0026rsquo;s a good idea to keep the callback graph clean and small, custom components can dramatically decrease graph size.\nIt will be easier to comprehend the application flow and you can encapsulate complex logic.\nIt will speed up development, people can develop the custom components separately, and test them in a sandbox environment.\nDownside The downside of custom components is that you need to define the components\u0026rsquo; DOM structure yourself, style them consistently, even if there\u0026rsquo;s an existing dash component that does the exact same thing that you\u0026rsquo;d need.\nIt\u0026rsquo;s tricky to keep it consistent with the development environment, if you use bootstrap or enterprise dash-design-kit.\nGetting started Getting started\nCreate custom component boilerplate:\npip install cookiecutter \u0026amp;\u0026amp; cookiecutter https://github.com/plotly/dash-component-boilerplate.git Loading state Docs: loading\nDash renderer lets your custom component know if it is in a loading state, you can get that info with these properties.\n/** * Object that holds the loading state object coming from dash-renderer */ loading_state: PropTypes.shape({ /** * Determines if the component is loading or not */ is_loading: PropTypes.bool, /** * Holds which property is loading */ prop_name: PropTypes.string, /** * Holds the name of the component that is loading */ component_name: PropTypes.string, }), How to use loading component If you wrap your component(s) inside dash_core_components.Loading, then there will be a common loading indicator around them if any children is waiting for a callback response.\nfrom dash_core_components import Loading layout = Loading(children=[MyComponent(id=\u0026#34;my-comp\u0026#34;)]) Update callback In case your custom component makes changes that should trigger a dash callback, you can use setProps callback with the updated props.\n/** * Dash-assigned callback that should be called to report property changes * to Dash, to make them available for callbacks. */ setProps: PropTypes.func; For example:\n\u0026lt;input value={myProperty} onChange={ /* * Send the new value to the parent component. * setProps is a prop that is automatically supplied * by dash\u0026#39;s front-end (\u0026#34;dash-renderer\u0026#34;). * In a Dash app, this will update the component\u0026#39;s * props and send the data back to the Python Dash * app server if a callback uses the modified prop as * Input or State. */ (e) =\u0026gt; setProps({ myProperty: e.target.value }) } /\u0026gt; Note: In dash callbacks you can not use a prop in two callbacks as an Output, but this is somewhat an exception. You can update any input parameters of your component, even if other components use it as an Output.\nBuild \u0026amp; deploy Run python setup.py sdist to build the app into a bundle, you can add the dist into requirements.txt even as a tar.gz file. But it\u0026rsquo;s better to publish it into your preferred pip artifactory.\nYou do not need to edit ANY python files yourself, all documentation and property validation are generated from the definition and comments of propTypes in your react component.\nNote that it comes with different dependencies and a separate virtual env, you need to install:\nfrontend dependencies with npm install python dependencies with pip install Note, that if you have a dash app, that already uses your component, and you make changes, it\u0026rsquo;s not enough to build a new package, you need to increment the version number in package.json e.g with npm version patch\nDevelopment You can run tests (separate dependencies, python3 tests/test_usage.py), create a mini dash app (usage.py)\nnpm start is a really useful command to fire up a live reload webpack dev server to develop your react code in isolation.\nNote that the styles are probably going to be different then where it\u0026rsquo;s going to run, since you might use dash-design-kit or bootstrap-components. But you can customize the demo index.js to look similar to the environment that you depend on, it won\u0026rsquo;t be added to the final deployment.\nDev tools Docs: Dash devtools\nIt can significantly improve developer experience to turn on the developer tools.\nLivereload, error messages in the dashboard, callback graph with proper information about the current run, and many more.\nserver = app.server if __name__ == \u0026#34;__main__\u0026#34;: debug_mode = True if os.getenv(\u0026#34;DEBUG\u0026#34;, \u0026#34;false\u0026#34;) == \u0026#34;true\u0026#34; else False if debug_mode is True: print(f\u0026#34;Initiating server. Debug mode enabled.\u0026#34;) else: ## Use enable_dev_tools when you want to turn on certain features when deploying your application with gunicorn. # app.enable_dev_tools( # dev_tools_ui=True, # dev_tools_serve_dev_bundles=True, # ) print(f\u0026#34;Initiating server.\u0026#34;) app.run_server( debug=debug_mode, host=\u0026#34;0.0.0.0\u0026#34;, port=5000 ) Annoying errors Exception has occurred: SyntaxError expression cannot contain assignment, perhaps you meant \u0026quot;==\u0026quot;?, you most probably missed a comma at the end of a line duing editing the the layout. Exception has occured: SystemExit. You can ignore this. In VSCode livereload triggers this error. Metadata/Docs At first I started to develop using a very old dash version, and migration was not an option. I looked for solutions to common problems online, but many times they were not suited for my stack.\nIt helped me a lot to get to know the components in github source. You can see the installed python packages as well. They follow the same format, and are self-documented. It\u0026rsquo;s easy to see which properties were available on the installed versions.\nUsed versions There might be better ways since I wrote this developer summary, The versions I used at the time of writing:\nPlotly version: 1.58.4 Dash version: 1.19.0 dash-core-components: 1.15.0 dash-html-components: 1.1.2 Disclaimer I was not asked for this post, I\u0026rsquo;m not affiliated with plotly in any way.\nMoving forward Did you find what you were looking for?\nIn the top of the page there are many useful links I wrote about a demo plotly-dash app with an example on github If it\u0026rsquo;s still not enough, feel free to leave a comment below or reach out via email.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/04/05/plotly-dash-development-tips/","summary":"Last year I was working on some dash-plotly applications/dashboards. It was confusing at first, I learned a lot during that time, I\u0026rsquo;d like to share my gathered experience. The docs already contain useful information, I do not wish to repeat them. There are many example pages in github, my goal is to collect my most visited pages here, so it\u0026rsquo;ll be easier to start out with development.\n","title":"Plotly Dash Development Tips"},{"content":"My first memory with vim is in early 2010s, I was just learning git, and I messed up my repo badly, a colleague came to help, he told me seemingly random sequence of characters to type, and suddenly everything went back to normal. Git\u0026rsquo;s default editor was vim and I think we did an interactive rebase. We might have just fixed it in an other way, but still it felt powerful. Later on I saw vim books at the operators\u0026rsquo; desks, and I got really curious of what it is and how can it help my daily work.\nGetting started Vim is a modal text editor, that is available by default in most Linux distributions\nKeys mean different commands in different modes, there are a few key points to know for basic usage:\nvim starts in NORMAL mode in NORMAL mode : enters COMMAND mode, type :wq save file and quit or :q! to quit without saving q: opens the command line, close it with ctrl-c in NORMAL mode press i to change to INSERT mode, navigation keys and backspace characters work as expected go back to NORMAL mode with ESC in NORMAL mode type / to start a search, press n for the next match, and press N for the previous match in NORMAL mode press u to undo the changes made, ctrl-r to redo the reverted changes vim modes aantipov\nThe catch When you open a file with vim, you can not see what are your options, what key combinations can you use.\nYou have to understand many things all at once, an there\u0026rsquo;s no onboarding in the application. When you open it up, and start to type, some characters might not show up, and the cursor navigates away. It\u0026rsquo;s not even clear how to exit this hellhole.\nYou have to read throgh the manual, find some getting started guides or cheatsheets.\nAfter you fight yourself through the initial difficulties, you can unleash its true power.\nWhy I love it It gives me a no config editor, that I can just install anywhere. Most of the time it\u0026rsquo;s already installed and I\u0026rsquo;m ready to be productive in no time.\nI like touch typing, and I can benefit from it, since I can keep my hands in the home row. I can use the characters for actions, without relying on key chords.\nIts keybindings are supported by many tools and sites. It can be used even in bash command line with set -o vi.\nHow I learned it When I was working with servers most of my time I felt the need to edit files on them more effectively. Editing files locally then moving them back and forth was not convenient.\nI got to know simpler editors like nano, but later on I desperately wanted to learn vim.\nBeginnings When I started out, I searched for some good materials over the internet. This image perfectly depicts my experence.\nvim learning wall pascalprecht\nAt first I started using vimtutor. It\u0026rsquo;s a command line utility that opens vim with an onboarding text as a sandbox, it\u0026rsquo;s installed alongside vim by default. I went through it once per day for 2 weeks, it felt hard in the beginning, but got less painful later on.\n=============================================================================== = W e l c o m e t o t h e V I M T u t o r - Version 1.7 = =============================================================================== Vim is a very powerful editor that has many commands, too many to explain in a tutor such as this. This tutor is designed to describe enough of the commands that you will be able to easily use Vim as an all-purpose editor. The approximate time required to complete the tutor is 30 minutes, depending upon how much time is spent with experimentation. Over the basics I disabled arrow keys to force myself learn to navigate with h, j, k, l keys. I can tell you force is not the best way to learn, but I was determined, and wanted to try to out.\nI mapped my capslock key to escape, because my wrist got tired of the twisting moves. I read, that they chose escape because on early keyboards it was located closer to the home row.\nADM3A key mapping wikipedia\nThese made me pick up the good habit of entering INSERT mode only when I really needed it.\nGood influence I was happy with this level, used it once or twice for simple things over the next year, but not too much.\nThe next phase started when I started to work at another company and one developer used vim as his IDE.\nI was determined to dust off my knowledge, and start to learn it again. And I really mean again, sadly my muscle memory faded almost completely. It\u0026rsquo;s a skill that you need to practice constantly.\nPractice I found the amazing rtorr cheatsheet. And decided to write out my favourite combos into github. While I was looking for productivity tips, fandom wikia vim tips page was really helpful.\nI even created a small python scipt to practice them as flash cards, but I guess I\u0026rsquo;ll be the only one ever who plays with it.\nWhen I changed my blog I found fuse.js, a fuzzy finder library. As a practice I created a mini site for my cheatsheet.\nI know people who use VIM keybindings in VSCode, but it don\u0026rsquo;t really like it, because it messes up my beloved multi-cursor editing, and makes me less productive. What I love in VSCode is that it evolves month by month without my supervision, but third-party tools/configsets usually do not keep up quickly.\nSide effects There are some patterns I spotted over the years on the servers, that made me suggest that those were edited by people who only occasionally use vim.\nhjkl keys in random locations, sometimes even causing typos in variables no identation in blocks, although it\u0026rsquo;s fairly simple with vim too much whitespace at the end of the lines Editor wars From time to time there are huge debates between whether vim or emacs is the ultimate superior editor. I think it comes down to preference and experience with these tools.\nI invested time and energy to learn vim because I saw potential in it after the first try. I don\u0026rsquo;t say that other editors are worse, it\u0026rsquo;s just happend to be a great fit to my usecases.\nI learned many emacs key combos over the years, since they work by default in the terminal. But I did not yet took the time to get to know it more.\nIf you like modern tools, vim has a hyper extensible version called neovim.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/03/13/vim/","summary":"My first memory with vim is in early 2010s, I was just learning git, and I messed up my repo badly, a colleague came to help, he told me seemingly random sequence of characters to type, and suddenly everything went back to normal. Git\u0026rsquo;s default editor was vim and I think we did an interactive rebase. We might have just fixed it in an other way, but still it felt powerful. Later on I saw vim books at the operators\u0026rsquo; desks, and I got really curious of what it is and how can it help my daily work.\n","title":"Vim"},{"content":"A few years ago I switched between a few machines on a daily basis, and tweaked my environments constantly. It was a tedious task to update each of them one by one, every time I changed configs or aliases in any of them. I figured this has got to be easier somehow, and found the hidden world of dotfiles.\nYesterday I told a friend to set up a small zsh plugin to make his life easier, but somehow he managed to remove some essential lines from his config. It took some time to guess what it was, and he may never know what else did he remove. That\u0026rsquo;s when I realized, it feels good to have a safety net around my configs I collected over the years, and I like that I don\u0026rsquo;t have to deal with these kind of problems anymore. I want to spread the word about its benefits.\nDotfiles In *nix systems user configuration files are usually stored in folders and files with a name that starts with a dot. These files are added upon install, and can be modified later.\nTo keep your configurations safe you can put them under Version Control Systems. That way you can easily roll back to a previously working config, and sync the current configs to multiple machines easily.\nMany applications modify config files after their install, for example add some scripts to the rc files of the users\u0026rsquo; shells. With version control you can keep track of these modifications.\nMany people on github has a public repository called something like dotfiles that shows their approach. You can learn from their approaches, and even share your way with the community.\nHow to get started There are different ways to create the dotfiles backups:\nRoll your own scripts from scratch See others\u0026rsquo; approach, and tweak it to your needs That\u0026rsquo;s my preferred way Use a tool like Dotbot to do the heavylifting There are many more general-purpose solutions Put your whole home folder into git Make sure you ignore the folders that you want to exclude I think it\u0026rsquo;s an overkill, also not all necessary configs are stored in that directory You can find more information with repositories, tips and tricks and other tools at https://dotfiles.github.io.\nBut what about secrets It\u0026rsquo;s not advised to store passwords and crucial keys in VCS like git.\nYou can store it in a safe vault elsewhere and reference them as regular files. You can also store them in the same folder but add them to .gitignore.\nI\u0026rsquo;d make sure that my configs work without those files. Also I wouldn\u0026rsquo;t use names that store any additional info about its whereabouts, or its contents.\nIf you accidentally pushed some keys to the git repository, it\u0026rsquo;s not enough to revert those changes, and commit again, since it\u0026rsquo;s part of the history now. You can follow this guide to remove it completely from the repository.\nMy way I keep the public part of my configs at https://github.com/budavariam/dotfiles.\nI wanted to get my hands dirty, and didn\u0026rsquo;t want to use any external tools for this purpose. I took inspiration from other dotfiles repos and customized the shell scripts enough to fit my needs.\nI need to run the install script once, and it\u0026rsquo;s ready to go. The files are symlinked to their proper locations, so if I change anything in an other machine all I have to do is call git pull in my dotfiles repository.\nIt\u0026rsquo;s not prepared for all usecases, and not suited for reruns. I don\u0026rsquo;t often add new things to the repo, and the scripts are not too large to run some of its parts manually if needded.\nI advise you to find the method that fits you the best, and keep your configs safe.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/03/06/keep-your-configs-safe/","summary":"A few years ago I switched between a few machines on a daily basis, and tweaked my environments constantly. It was a tedious task to update each of them one by one, every time I changed configs or aliases in any of them. I figured this has got to be easier somehow, and found the hidden world of dotfiles.\n","title":"Keep Your Configs Safe"},{"content":"A few weeks ago I came across a post about recommended static site generators. I decided to reevaluate my previous choice for a blog engine. I\u0026rsquo;ve used Jekyll and Gatsby.js before, now I wanted something new.\nI used Jekyll for my first theme only because at that time (without github actions), it was the simplest way to push content into github pages from a repo without buildng it on my machine.\nHugo PaperMod Many people recommended Hugo.go, I decided to give it a try. After browsing for a while in the themes Papermod caught my eye. It has a similar minimalistic vibe, as my previous site, but also has many embedded features out of the box. üéâ\nI forked it and started to tweak it, to keep the features I liked in my previous page.\nMy first impression is that hugo is really blazing fast.\nTemplating It took me some time to figure out the logic behind the templating. I spent the most time with the social icons, to keep the feature, that I only need to specify the username, and it uses the proper icon AND the proper URL. Later on I got so confident in this strange syntax, I even implemented inverse logarithmic scale coloring for tag numbers, so small differences stand out more than with a simple linear scale.\nSVG icons I had some extra logic to be able to modify svg icons separate from the code, I just needed to replace a few lines of code, to make it work.\nI hopped on the chance to add svgo to the mix, to generate optimized svg-s to the site, no matter what I save in my folder.\nDeployment For deployment Jekyll has first level support from github. Github actions has templates for hugo deployment, it works just fine.\nIt kept me thinking what I did wrong when I got a 404 in the first deploy. peaceiris/actions-gh-pages@v3 by default pushes to a separate gh-pages branch, and I needded to adjust my repo settings, to load github pages from that location.\nNew features I dedicate this chapter to the new features I love in PaperMod, that I did not have before.\nsexier typography, nice looking components cover images scroll to top button quick search autodetect or switch between dark mode/lightmode read time for posts emoij parser paginated view for all posts post archive tags / show posts by tags embed shortcodes (components) into markdown I hope you like the new look and feel as much as I do.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/03/02/new-blog-engine/","summary":"A few weeks ago I came across a post about recommended static site generators. I decided to reevaluate my previous choice for a blog engine. I\u0026rsquo;ve used Jekyll and Gatsby.js before, now I wanted something new.\n","title":"New Blog Engine"},{"content":"In the past few days I\u0026rsquo;ve been working in manual mode on multiple linux boxes simultaneously. I have to follow logs, modify configurations and kill/start applications all at once. I got confused pretty fast of what server am I connected to in a certain console pane, and where are my operations. On top of that my ISP had a huge traffic hit these days, and my VPN connection dropped constantly. I dusted off my knowledge about some tools that boosted my productivity.\nI usually don\u0026rsquo;t like to repeat myself, and supposedly I\u0026rsquo;ll have to do these modifications for many more machines. So as I see something is working, I take a note of the solution and create a script as I go. I have to see that it works manually, in order to automatize it.\nSSH SSH provides secure shell connection to a remote machine. You can work in it just like your local machine. There are multiple authentication methods, I found ssh public key auth feasible in my use case.\nput ssh keys into authorized-keys of the remote user simply, if you already have access to the server ssh-copy-id \u0026lt;connection\u0026gt; sshpass make it easy to use ssh-copy-id in a script sshpass -p $secretpass ssh-copy-id \u0026lt;connection\u0026gt; remember the passphrases of the ssh keys ssh-add -K ${key_location} ssh port forward ssh -N -L LOCAL_PORT:localhost:REMOTE_PORT \u0026lt;connection\u0026gt; copy keys to the server scp ~/.ssh/my_keyprefix_* '\u0026lt;connection\u0026gt;:~/.ssh/' start ssh service sudo systemctl start ssh.service attach to the already existing byobu session (see below): ssh -t byobu Where \u0026lt;connection\u0026gt; is the data necessary to establish the ssh connection. Most likely an identity file and the server address: -i ~/.ssh/my_keyprefix.pem user@192.168.1.101. I think it\u0026rsquo;s better to use SSH Config. If you specify Host myserver in the config, you can use case myserver for the \u0026lt;connection\u0026gt; part.\nSSH Permissions SSH is picky with the permission settings.\nThe home folder that contains .ssh folder can not have group write permission. .ssh folder should have 700 octal permission .ssh/authorized_keys and public keys should have 644 octal permission .ssh/config should have 600 octal permission private keys under .ssh/ should have 600 octal permission Permission basics Octal permissions in linux specify the permissions of the owner, group and others as the numbers respectively.\nThe permissions can be any combination of: read (4), write (2) and execute (1).\nWith that in mind: 644 permission means read permission for everyone, and an extra write permission for the owner.\nPermissions can be set with chmod command like: chmod $octal_permission filelist.\nSSH Config I think it\u0026rsquo;s amazing that you can collect ssh configurations under a custom name, and you can use that name to connect to the specified server.\nYou need to set the necessary data into:~/.ssh/config.\nHost server-1 User customuser HostName 192.168.42.123 IdentityFile /var/opt/customdata/.ssh/id_ed25519 I used rsync to keep some code up to date in my systems, and it made the code significantly easier and less error prone to reference the ssh config already set, instead of typing it out.\nRsync does not proide automatic resync out of the box, but a little bash magic can do wonders.\nprojectpath=\u0026#34;~/projects/thisproject\u0026#34; machine=\u0026#34;server-1\u0026#34; # this is the Host in .ssh/config run_rsync() { rsync -azuv --no-o --no-g \\ --exclude \u0026#34;logs\u0026#34; \\ --exclude \u0026#34;.git\u0026#34; \\ \u0026#34;${projectpath}\u0026#34; \\ \u0026#34;$machine\u0026#34;:/opt } run_rsync; fswatch -o \u0026#34;${projectpath}\u0026#34; | \\ while read f; do run_rsync; done Debug SSH connection problems You can debug ssh issues with the verbose flag on the client side, e.g: ssh -vvv server-1.\nIf you need to debug your issues on the server side, you can set the ssh service to print debug logs by setting LogLevel DEBUG in /etc/ssh/sshd_config. You need to restart the sshd service to apply this modification. systemctl restart sshd\nView the logs with e.g: journalctl -f -u sshd.\nIn my case I needed to access a user that had his home folder outside /home AND had his password locked. On top of that their home folder had group write permissions by default. Such a thrill.\nLocked password The locked password made it harder to put out the ssh key, there are 2 simple solutions to choose from\nOne would be to set a password manually with: passwd customuser as a root user, then use ssh=copy-id as usual, and finally lock the password again with passwd --lock customuser.\nThe other solution is to append the public key manually to ~customuser/.ssh/authorized_keys.\nHome folder outside /home In my case selinux did not know that this folder can be used as an ssh_home folder. These few lines permanently fixed it.\nsudo semanage fcontext -a -t ssh_home_t ~customuser/.ssh/authorized_keys sudo semanage fcontext -a -t ssh_home_t ~customuser/.ssh sudo restorecon -R -v ~customuser/.ssh/ chmod g-w ~customuser Welcome message When I log in to a box, I found it beneficial to print a huge unique identifier of where I logged in exactly. It made it easier to keep track of what\u0026rsquo;s happening.\nI found a great tool called FIGlet, that can generate ASCII art like text from ordinary text. As a small practice project, in my free time I put together a simple webapp to showcase an already existing JS renderer.\n____ _____ ____ __ __ _____ ____ _ / ___| | ____|| _ \\\\ \\ / /| ____|| _ \\ / | \\___ \\ | _| | |_) |\\ \\ / / | _| | |_) | _____ | | ___) || |___ | _ \u0026lt; \\ V / | |___ | _ \u0026lt; |_____| | | |____/ |_____||_| \\_\\ \\_/ |_____||_| \\_\\ |_| But of course I could have just used cowsay.\n________________________________ \u0026lt; Welcome to St. James Ballroom! \u0026gt; -------------------------------- \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || || Set SSH banner SSH banner prints a message when an ssh session connects, before the used logs in.\nI aimed for a simple banner, centos have a wiki page that explains the simple steps to achieve it, but since it\u0026rsquo;s ssh config it should work similarly in other distributions.\nCreate a /etc/issue.net file and fill it with the desired plaintext context Edit /etc/ssh/sshd_config, to have this line: Banner /etc/issue.net Restart sshd: systemctl restart sshd In linux you can specify welcome messages, when you log in, it\u0026rsquo;s called Message Of The Day or MOTD for short. That opens up after the user has logged in, and before the shell started up. It can be cpntrolled usually in /etc/motd.\nTerminal multiplexers Terminal multiplexers make it easy to manage long running processes in remote machines. They\u0026rsquo;re especially useful if you have an unreliable network connection, you can start up a session in the remote machine, and when you log in to the machine the next time, you can connect to the same session.\nThey let you create multiple windows/panes, thus provide a better experience than forward/background jobs.\nYou can have multiple sessions in a machine at a given time, multiple users can log in to them.\nYou can use it in your local machine as well, and log in to it from multiple shell emulators if that\u0026rsquo;s what you need.\nScreen and tmux GNU screen is there since 1987, widely available.\nscreen -S sessionName # create session with a name screen -r sessionName # reconnect to named session screen -ls # list current sessions screen -XS sessionName quit # terminate session screen -r -d # reconnect to the last session screen -xr # share screen tmux is newer, created in 2007, has a huge community around it. They operate with key chords, both have a meta character that marks the actions for the multiplexer.\ntmux new -s session_name # create session with a name tmux attach-session -t session_name # reconnect to named session tmux ls # list current sessions tmux kill-session -t session_name # terminate session tmux new -As0 # attach to default session if exists Byobu My favourite is byobu, it\u0026rsquo;s a config layer over the other two above. It provides a simple interface for their functionalities. Byobu maps its functionality to the F1-F12 keys.\nYou can use the key chords that you\u0026rsquo;re used to, even select the underlying backend on start.\nbyobu byobu-screen # any tmux options can be given byobu-tmux # any screen options can be given Basic Keybinding comparison Byobu Tmux Screen Description CTRL+b CTRL-a default meta shift+F1 meta ? meta ? help F6 meta d meta d detach from session F2 meta c meta CTRL-C create new tab meta w meta \u0026quot; choose tab from a list F3 meta n meta CTRL-N next tab F4 meta p meta CTRL-P prev tab meta 0 meta CTRL-0 switch to tab (0 can be any number) shift+F2 meta \u0026quot; meta SHIFT-s split horizontally CTRL+F2 meta % meta | split vertically meta o meta TAB switch to pane meta x meta SHIFT-x close the pane that has focus F8 meta , meta SHIFT-a rename tab F7 meta [ meta ESC start scroll mode meta q show pane numbers if you press a number the cursor will jump to it meta ; toggle between prev/current pane meta SPACE toggle between layouts meta z toggle zoom to pane Note that Byobu can use the underlying backend\u0026rsquo;s keybindings as well.\nHappy coding!\nCover Photo by Kevin Ku from Pexels\n","permalink":"https://budavariam.github.io/posts/2021/02/27/think-outside-the-box/","summary":"In the past few days I\u0026rsquo;ve been working in manual mode on multiple linux boxes simultaneously. I have to follow logs, modify configurations and kill/start applications all at once. I got confused pretty fast of what server am I connected to in a certain console pane, and where are my operations. On top of that my ISP had a huge traffic hit these days, and my VPN connection dropped constantly. I dusted off my knowledge about some tools that boosted my productivity.\n","title":"Think Outside The Box"},{"content":"I usually work with *nix systems, and I process text all the time. This consists of CLI tool output, config file modifications and log files scanning. These utilities make it easy to search and manipulate plaintext data. I think they\u0026rsquo;re an essential part of any developer\u0026rsquo;s toolbox.\nThese commands can read either from the standard input, a single file or multiple files.\nGrep Grep\u0026rsquo;s name comes from the ed command g/re/p, which roughly means, globally look for a regular expression and print. Perfect for simple regex matches of single lines.\ngrep [flags] [pattern] [filenames]\nNotable grep flags -E extended regexp -q exit code marks the result (success is 0) -v lines that do not match -n matched line and line number -l only the names of files that contain a match -c count of the matching lines (not the number of matches) -i case insensitive match -o print only matching part (interesting with regex) -e define multiple patterns --color use colors always/never/auto Grep examples example=\u0026#34;\\ For instance, on the planet Earth, man had always assumed that he was more intelligent than dolphins because he had achieved so much ‚Äî the wheel, New York, wars and so on ‚Äî whilst all the dolphins had ever done was muck about in the water having a good time. But conversely, the dolphins had always believed that they were far more intelligent than man ‚Äî for precisely the same reasons.\u0026#34; # Match exact text echo \u0026#34;$example\u0026#34; | grep \u0026#39;man\u0026#39; # Match exactly \u0026#39;the\u0026#39;, \u0026#39;than\u0026#39; or \u0026#39;for\u0026#39; words # case insensitive (\\b is word boundary) echo \u0026#34;$example\u0026#34; | grep -iE \u0026#39;\\b(the|than|for)\\b\u0026#39; # Print only the matching part of the string # (can not print part of it, like groups) echo \u0026#34;$example\u0026#34; | grep -Eo \u0026#39;dolphins \\w+\u0026#39; # Do not print lines that contain \u0026#34;the\u0026#34; echo \u0026#34;$example\u0026#34; | grep -Ev \u0026#39;\\bthe\\b\u0026#39; # Count the lines that contain \u0026#34;good\u0026#34; echo \u0026#34;$example\u0026#34; | grep -c \u0026#39;good\u0026#39; # Filter lines that contain a # punctuation mark OR start with a lowercase letter echo \u0026#34;$example\u0026#34; | grep --color=never -E -e \u0026#39;[.,-]\u0026#39; -e \u0026#39;^[a-z]\u0026#39; Similar utilities egrep - extended regex pattern, like grep -E fgrep - faster, but works only for fixed patterns zgrep/zegrep/zfgrep - for compressed files pgrep - search processes and print the PID of matching ones ack-grep has the functionality of grep, but optimized for developers silver seracher is similar to ack, but faster Sed Sed is a powerful stream editor. For a more comprehensive guide check out this awesome post.\nI\u0026rsquo;ll show some commands that you can be productive with in no time.\nsed [flags] [pattern] [filenames]\nNotable sed flags -E extended regexp -n show ony those lines, that we explicitly print -e chain multiple commands -i edit files in place Basic commands print: p delete: d substitute: s/regexp pattern/replace to this string/modifiers fence characters after substitutiion that defines the fields can be any character, choose one that does not appear in your patterns. It has to be a single character. in replace string you can matching regular expression: \u0026amp; to reference the whole pattern \\1-\\9 to reference the groups by number modifiers can be: g: global flag, match all occurrances in each line p: print result NUMBER: the NUMBERth match in the line Addresses You can optionally specify addresses before the command in which the command acts upon:\nline number line range separated by comma, where the last line can be referenced with $ a regular expression to define which lines do you want to run the script to fenced by forward slashes Addresses can be negated if you put a ! between the address and the command.\nSed Examples example=\u0026#34;\\ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ut ut enim quis nisl ultrices molestie eu in nibh. In sit amet odio et tellus sagittis semper sed at urna. Pellentesque feugiat ipsum eget dignissim mattis. Donec accumsan nibh sit amet mi ornare, a faucibus diam euismod. \u0026#34; # Print 2nd line echo \u0026#34;$example\u0026#34; | sed -n \u0026#39;2 p\u0026#39; echo \u0026#34;$example\u0026#34; | sed \u0026#39;2! d\u0026#39; # Print 2-5th line only echo \u0026#34;$example\u0026#34; | sed -n \u0026#39;2,5 p\u0026#39; # Print from 3rd line until the end of the file echo \u0026#34;$example\u0026#34; | sed -n \u0026#39;2,$ p\u0026#39; # Delete lines thet contain \u0026#39;Lorem\u0026#39; echo \u0026#34;$example\u0026#34; | sed \u0026#39;/Lorem/ d\u0026#39; # Replace all \u0026#39;amet\u0026#39; with \u0026#39;tema\u0026#39; echo \u0026#34;$example\u0026#34; | sed \u0026#39;s/amet/tema/g\u0026#39; # Replace second \u0026#39;m\u0026#39; to \u0026#39;M\u0026#39; in each line echo \u0026#34;$example\u0026#34; | sed \u0026#39;s:m:M:2\u0026#39; # Put \u0026#39;ipsum\u0026#39; in square brackets echo \u0026#34;$example\u0026#34; | sed -E \u0026#39;s/(ipsum)/[\\1]/g\u0026#39; # Chain multiple commands together # replace the 2nd and third lines to numbers, then # print even numbers twice echo \u0026#34;$example\u0026#34; | sed \\ -e \u0026#39;2,3 s_^.*$_1234567890_\u0026#39; \\ -e \u0026#39;s/\\([02468]\\)/\u0026amp;\u0026amp;/g\u0026#39; AWK AWK is a record-based pattern-directed text processing language. It\u0026rsquo;s name comes from the last names of its creators.\nAn AWK script builds up from Pattern-Action pairs.\nAWK splits the input into records. Splits the records into fields.\nFrom start to end, match the defined patterns with the records, to determine whether it needs to perform the action of that pattern.\nIt allows you to write complex programs with it, I advise you to take some time to get familiar with the main functionality.\nNotable AWK flags -F define input field separator regexp -f load code from a file -v var=value set variables before staring up Patterns Empty pattern matches for every line.\nSpecial patterns BEGIN/END define action before the first input line is read, and after the last input is read respectively\nPatterns can be combined together:\nsimple regular-expression regular-expression is fenced by forward slashes boolean operators: AND: \u0026amp;\u0026amp;, OR: ||, NOT: ! expression matchop regular-expression matchop is one of the following ~ matches !~ does not match expression relop expression relational operator is one of the following == Equal to \u0026gt; Greater than \u0026lt; Less than != Not equal to \u0026gt;= Greater than or equal to \u0026lt;= Less than or equal to expression in array-name array-name (expr,expr,\u0026hellip;) in array-name if 2 patterns are defined separated by a comma, then the action will be performed from the first occurrance of the fist pattern until the first occurrance of the second pattern Actions Missing action means to print the whole line. Actions are surrounded by curly brackets. Commands are terminated by semicolons/newlines/right braces. Fields can be accessed as $NUMBER, where number is the index of the field starting from 1. $0 contains the whole line. AWK has associative arrays, meaning its indexes can be strings, or numbers You can define them in the following format: arrayname[index] = value AWK does not support multi-dimensional arrays, but you can emulate it by concatenating the dimension indixes as a string In expressions the variables need not use $ signes in their names. Strings are concatenated together by spaces We can write complex programs in our AWK actions to process the input fields.\nThe following lines come from the manual as-is. The parts between [] are optional, except when it refers to array indexing. Other characters are as-is.\nStatements if( expression ) statement [ else statement ] while( expression ) statement for( expression ; expression ; expression ) statement for( var in array ) statement do statement while( expression ) break continue { [ statement ... ] } expression commonly var = expression print [ expression-list ] [ \u0026gt; expression ] printf format [ , expression-list ] [ \u0026gt; expression ] return [ expression ] next skip remaining patterns on this input line nextfile skip rest of this file, open next, start at top delete array[ expression ] delete an array element delete array delete all elements of array exit [ expression ] exit immediately; status is expression Other functions mathematical functions: atan2, cos, exp, log, sin, and sqrt length the length of its argument taken as a string, number of elements in an array for an array argument, or length of $0 if no argument. rand random number on [0,1). srand sets seed for rand and returns the previous seed. int truncates to an integer value. substr(s, m [, n]): the n-character substring of s that begins at position m counted from 1. If no n, use the rest of the string. index(s, t): the position in s where the string t occurs, or 0 if it does not. match(s, r): the position in s where the regular expression r occurs, or 0 if it does not. The variables RSTART and RLENGTH are set to the position and length of the matched string. split(s, a [, fs]): splits the string s into array elements a[1], a[2], ..., a[n], and returns n. The separation is done with the regular expression fs or with the field separator FS if fs is not given. An empty string as field separator splits the string into one array element per character. sub(r, t [, s]): substitutes t for the first occurrence of the regular expression r in the string s. If s is not given, $0 is used. gsub(r, t [, s]): same as sub except that all occurrences of the regular expression are replaced; sub and gsub return the number of replacements. sprintf(fmt, expr, ...): the string resulting from formatting expr ... according to the printf(3) format fmt. system(cmd): executes cmd and returns its exit status. This will be -1 upon error, cmd\u0026rsquo;s exit status upon a normal exit, 256 + sig upon death-by-signal, where sig is the number of the murdering signal, or 512 + sig if there was a core dump. tolower(str): returns a copy of str with all upper-case characters translated to their corresponding lower-case equivalents. toupper(str): returns a copy of str with all lower-case characters translated to their corresponding upper-case equivalents. Special variables AWK provides information about the state of the processing and environment\nvariable name description RS Specifies the record separator. FS Specifies the field separator. FIELDWIDTHS Specifies the field width. OFS Specifies the Output separator. ORS Specifies the Output separator. NF Fields count of the line being processed. NR Retrieves total count of processed records. FNR The record which is processed. ARGC Retrieves the number of passed parameters. ARGV Retrieves the command line parameters. ENVIRON Array of the shell environment variables and corresponding values. AWK Examples # AWK examples from man page # Print lines longer than 72 characters. length($0) \u0026gt; 72 # Print first two fields in opposite order. { print $2, $1 } # Same, with input fields separated # by comma and/or spaces and tabs. BEGIN { FS = \u0026#34;,[ \\t]*|[ \\t]+\u0026#34; } { print $2, $1 } # Add up first column, print sum and average. { s += $1 } END { print \u0026#34;sum is\u0026#34;, s, \u0026#34; average is\u0026#34;, s/NR } # Print all lines between start/stop pairs. /start/, /stop/ # Simulate echo(1) BEGIN { for (i = 1; i \u0026lt; ARGC; i++) printf \u0026#34;%s \u0026#34;, ARGV[i] printf \u0026#34;\\n\u0026#34; exit } Learn more from this great tutorial Disclaimer I did not get anything from making this post,\nMy main goal was to host an evolving cheatsheet for myself when I forget all this, and need to apply it quickly.\nI hope you learned something from it as well.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/02/18/grep-sed-awk-filters/","summary":"I usually work with *nix systems, and I process text all the time. This consists of CLI tool output, config file modifications and log files scanning. These utilities make it easy to search and manipulate plaintext data. I think they\u0026rsquo;re an essential part of any developer\u0026rsquo;s toolbox.\n","title":"Grep Sed AWK Filters"},{"content":"I\u0026rsquo;m currently following the trends with my dev setup. I use dark theme in almost all of my tools. That make my Mission Control a monochrome mess. Most of my tools have theming options, so a few months ago I decided to light things up.\nThe Problem My general workflow in mac heavily relies on finding windows, and switching between them. At a given time I usuallly have 10+ windows open. With the embedded gestures, I can just swipe 3 fingers up and search for the appropriate window.\nFor 2 or 3 windows that I use often, I use fullscreen to access them quickly by swiping left/right with 3 fingers, but more windows make it slower to find the necessary place to continue the work.\nTo make things even harder, for some reason mac rearranges the windows after every switch.\nWith dark theme everywhere, it\u0026rsquo;s pretty hard to distingush between the different applications, you have to rely on small random features.\nIt\u0026rsquo;s not fun to switch between these windows.\nUnless you set themes!\nMy most crucial triad are: Iterm2, Slack and VSCode. Chrome is top 4, but I currerntly I like its default dark theme.\nIterm2 Tab Colors In iterm2 I use vertical tab arrangement. That way more tabs can fit in the screen. The tabs can have custom colors.\nIt might not help too much in the big picture, BUT at least tabs are found easily.\nSlack Themes My main motivation is to have a bright color that can be seen from a distance.\nSlack has an option to customize its theme colors.\nSince themes are defined as a concactenated list of colors, there are many sites that hoost combinations with custom names. You can definitely find one that suits your needs.\nI really like the default CMYK theme\n#20252C,#0E0B01,#6BC9FF,#0E0B01,#0E0B01,#FCEBF9,#FCE54D,#CD2553,#D53C9F,#0E0B01 VSCode Theme Customization VSCode is my main IDE, generally 4+ instances are open at a given time. I figured that theme customization let me distingush between them. By recoloring the sidebar, I was finally able to mark the projects I needed the most.\n{ \u0026#34;activityBar.background\u0026#34;: \u0026#34;#62bfda\u0026#34;, \u0026#34;activityBar.foreground\u0026#34;: \u0026#34;#15202b\u0026#34;, } Peacock Peacock helps to automatize this flow.\nI only want it to recolor the sidebar, luckily there are settings to disable recoloring the other parts. I added these settings globally.\n{ \u0026#34;peacock.affectAccentBorders\u0026#34;: false, \u0026#34;peacock.affectStatusBar\u0026#34;: false, \u0026#34;peacock.affectTitleBar\u0026#34;: false, } It\u0026rsquo;s pretty powerful tool, but my favorite part is that I can just ask it for a random harmonic colorset.\nIt writes to the settings file, and since it modifies the embedded theme settings, it can work for colleagues that do not have this extension.\nFinal thoughts There is a saying, that if you mark everything, it\u0026rsquo;s as efficient as not marking anything. But I think this is not the case. I like to think of these tweaks as multiple colorful bookmarks in a huge textbook.\nI achieved my goal, I significantly reduced the time I need to look for small details, I can spot the colors easily and navigate to the desired app.\n","permalink":"https://budavariam.github.io/posts/2021/01/27/light-up-my-mission-control/","summary":"I\u0026rsquo;m currently following the trends with my dev setup. I use dark theme in almost all of my tools. That make my Mission Control a monochrome mess. Most of my tools have theming options, so a few months ago I decided to light things up.\n","title":"Light Up My Mission Control"},{"content":"Have you ever typed ctrl-c instead of ctrl-v and had to recopy again? Have you ever needed to copy and paste multiple entries at once from a page causing you to switch back and forth? Have you ever needed to copy the output of a program running in the terminal? I did, and got fed up with them almost 5 years ago, I\u0026rsquo;ll show you how you can eliminate these problems.\nClipboard History Most of my clipboard-related frustration came from the fact, that default clipboards in the operating systems store only one entry at a time. If I were to access the clipboard history, most of my problems were gone. Luckily there are apps for that.\nOS Defaults The latest version of Windows 10 have a setting to make clipboard history available in the System settings under Clipboard history. It makes clipboard history available with win+V key. Not too configurable, but perfectly usable.\nOn Mac you can use a secondary clipboard with ctrl+k (copy) and ctrl+y (paste), alongside cmd+c (copy) and cmd+v (paste). You can still only have 2 separate entries at once.\nDitto I started to use Ditto to eliminate this problem. I loved that I could access my previous clips throughout the day. It had configurable shortcuts to access the last 10 entries separately. The only problem I had with it, that it only worked for windows.\nCopyQ When I started to use Ubuntu for my daily work I found CopyQ, a free open-source multiplatform clipboard manager. I use it daily ever since.\nI love that it has a configurable clipboard size, I can search through the entries, and it has a configurable shortcut to Show main window under mouse cursor that can speed up work.\nIn case I copy sensitive data, I can turn off clipboard monitoring all at once with a configurable shortcut: Toggle Clipboard Storing.\nMy only problem with it is that it sometimes tends to quit unexpectedly on mac. According to their github issues they\u0026rsquo;re working on it.\nClipboard in the command line In the command line you can take advantage of the operating system\u0026rsquo;s pipeline. Imagine copy as a utility that consumes text, and paste as one that produce text, and when you use them the clipboard changes accordingly.\nLet\u0026rsquo;s see what are the exact utilities that can be used for different systems.\nMac Mac has built-in utility commands to pbcopy and pbpaste to the clipboard.\n# copy text to clipboard by piping to `pbcopy` echo \u0026#34;Text to copy\u0026#34; | pbcopy # paste text from clipboard by piping from `pbpaste` pbpaste | less Linux On Linux that use X window manager you can use xclip. In case you switch between Mac and Linux often, you can use aliases to keep things consistent.\n# Install it with the available package manager. # Add to e.g: ~/.bash_profile to load on startup alias pbcopy=\u0026#39;xclip -selection clipboard\u0026#39; alias pbpaste=\u0026#39;xclip -selection clipboard -o\u0026#39; On linux servers that does not have window manager I did not yet see the point to investigate this further.\nWindows Windows has builtin clip.exe. Unfortunately, it can only copy TO the clipboard, can not read from it.\nIf you need access to the clipboard you need to use Get-Clipboard powershell module.\nREM copy to clipboard with clip.exe echo \u0026#34;Text to copy\u0026#34; | clip REM get data from clipboard powershell -command \u0026#34;Get-Clipboard\u0026#34; REM get data from clipboard into file powershell -command \u0026#34;Get-Clipboard\u0026#34; \u0026gt; file.txt Cygwin If for some reason you still use Cygwin, you\u0026rsquo;re in luck! It makes Windows clipboard available as /dev/clipboard.\n# copy text to clipboard by redirecting to `/dev/clipboard` echo \u0026#34;Text to copy\u0026#34; \u0026gt; /dev/clipboard # paste text from clipboard by reading from `/dev/clipboard` cat /dev/clipboard oh-my-zsh oh-my-zsh has a clever way to detect the OS capabilities. You can use its clipcopy and clippaste functions out of the box in most systems.\n# copy text to clipboard by piping to `clipcopy` echo \u0026#34;Text to copy\u0026#34; | clipcopy # paste text from clipboard by piping from `clippaste` clippaste | less Web Browsers In web browsers you can use the modern Clipboard API to interact with the clipboard. Previously you could use document.execCommand() but it\u0026rsquo;s obsolete, that means it might still work, but it\u0026rsquo;s discouraged.\nFor browser support see clipboard at caniuse.com.\nFor up to date and extensive examples see these pages sbove.\nChrome DevTools In Chrome developer Console you can use copy(object) builtin function to put an object to the clipboard.\nIt can be handy during debugging. Combined with $0 you can copy whole dom elements quickly.\ncopy($0) copy($0.value) copy(window.myGlobalObject) Closing Words I hope you\u0026rsquo;ve found it useful.\nCover Photo by Negative Space from Pexels\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2021/01/20/clipboard-goodies-for-productivity/","summary":"Have you ever typed ctrl-c instead of ctrl-v and had to recopy again? Have you ever needed to copy and paste multiple entries at once from a page causing you to switch back and forth? Have you ever needed to copy the output of a program running in the terminal? I did, and got fed up with them almost 5 years ago, I\u0026rsquo;ll show you how you can eliminate these problems.\n","title":"Clipboard Goodies For Productivity"},{"content":"From time to time I come across a rant on Twitter, that regular expressions are confusing and hard in general. I think if you know the basic building blocks of it, you\u0026rsquo;ll see how useful they are, and you can unleash its power in your daily coding life.\nYou do not have to know everything about them to be productive with them.\nWhat are regular expressions To put it simply, a regular expression (regex, regexp) is a sequence of characters that defines a pattern, that can be used on other strings to see whether they match the pattern or not.\nIt has roots in formal language theory.\nYou can imagine a regular expression as a machine, that checks whether the input string corresponds to its precoded rules or not.\nBase building blocks Char Description [characters] Matches any character in characters (can be an interval) [^characters] Negation: Matches any character that is not in characters | Matches any one element separated by the pipe (|) character. For example: a|b|c matches one of a, b or c. . Match any 1 character (except linebreaks) ? Matches the previous element zero or one time * Matches the previous element zero or more times (greedy, it matches as much as it possibly can) + Matches the previous element one or more times (greedy) () Creates a capture group, that can be extracted, or checked for repeating, assigns a number for it starting from 1 ^ Marks the start of the line $ Marks the end of the line \\character If you\u0026rsquo;d like to use any of the characters above in this list without their special meaning, (outside []-s), you\u0026rsquo;ll need to escape them. For example: \\. means a literal dot character. You can build many patterns out of these simple building blocks. Here are a few examples.\n[a-zA-Z]+ matches any word that consists of upper or lowercase letters of the English alphabet [0-9]+ matches any character string that constist of only numeric characters th[ae]n matches than OR then winter|spring|summer|autumn matches one of 4 seasons ^line$ matches a line that only contains the text line [^02-9][8-9][1-4][0-9] matches numbers between 1810-1849 OR 1910-1949 (key)?board matches keyboard OR board (https?|ftp):// matches http://, https://, ftp:// It\u0026rsquo;s not always reasonable to write down all possible matches, but it\u0026rsquo;s always a good idea to keep the possibilities in mind.\na+(bb|dd)*c?$ matches text that follows the pattern: at least 1 a followed by 0 or more occurrances of bb or dd and an optional c at the end Advice to read regexp In order to understand what can a certain regular expression match, you need to follow these simple rules:\nRead it from left to right Do not skip any characters If you encounter unknown syntax, read the appropriate docs, or use a tool like regex101 Tip: Syntax highlight and bracket matching usually helps to understand complex expressions.\nAdvice to write regexp Keep it simple Make sure it\u0026rsquo;s readable for others. I like to comment my intentions, in case the expression seems confusing Use . sparingly Try to keep greedy patterns to the minimum, for performance (see ReDoS) Some \u0026ldquo;advanced\u0026rdquo; concepts I like to use Word boundaries: \\b allows you to perform a \u0026ldquo;whole words only\u0026rdquo; search with e.g: \\bword\\b Shorthand character classes Whitespace: \\s Word: \\w stands for [A-Za-z0-9_] Digit: \\d stands for [0-9] Negated forms: \\S, \\W, \\D Backreference: match the same text as the marked capture group Non-capturing groups: (?:) do not store the result of the group (?:19)?(9[0-9]) matches numbers 1990-1999 OR 90-99, but captures only the second group Non-greedy matches (*?, +?) try to keep the match to the bare minimum so that the remaining part matches Exact number of matches {n}: Matches the previous element exactly n times {n,}: Matches the previous element at least n times {n, m}: Matches the previous element at least n times and at most m times Good to know about:\nLookahead/Lookbehind assertions Named groups Where can we use them Nowadays they can be used almost anywhere where there\u0026rsquo;s an option to process/match text.\nMost modern text editors have an opt-in option to use regular expressions in search. The best part is that they usually support replace patterns with regular expressions. That means that, you can use capturing groups in the replacement part.\nUNIX/Linux utilities like sed, (e)grep, find.\nProgramming languages generally support regular expressions.\nFor finding text in codebases via command line I often use ack-grep or its speed optimized competitor ag.\nDifferent programs can use different regular expression parsing engines, they can differ in what functionalities are available or what syntax do they use. It\u0026rsquo;s always reasonable to check the appropriate docs when writing complex expressions.\nSites I recommend In my opinion, the best way to understand and debug your regular expressions is regex101 regular-expressions.info is a comprehensive colorful tutorial on regular expressions Regexcrosswords is a mindboggling brainteaser, where you can practice your newfound knowledge Happy Coding!\n","permalink":"https://budavariam.github.io/posts/2021/01/18/regular-expressions-are-awesome/","summary":"From time to time I come across a rant on Twitter, that regular expressions are confusing and hard in general. I think if you know the basic building blocks of it, you\u0026rsquo;ll see how useful they are, and you can unleash its power in your daily coding life.\n","title":"Regular Expressions Are Awesome"},{"content":"I work with some projects that can be only used with specific versions of node/python and it\u0026rsquo;s not feasible to simply dockerize them. Every time I switch between these projects I\u0026rsquo;d need to reinstall different versions of node/python. That would be plain silly\u0026hellip; BUT there\u0026rsquo;s a better way.\nNode.js For Node, there\u0026rsquo;s an npm package called n.\nInstall any version of node Run npm install -g n Verify install: n --help Options I use the most:\nInstall specific version: n \u0026lt;version\u0026gt; e.g.: n 15.5.1 Select version from installed: n Install and use latest node version: n latest Clean up all versions except the current: n prune In case it does not work without sudo you can follow the advice in the docs:\nTo avoid requiring sudo for n and npm global installs, it is suggested you either install to your home directory using N_PREFIX, or take ownership of the system directories\nNote: It\u0026rsquo;s not supported on windows.\nPython For Python, there\u0026rsquo;s a community made package manager solution called pyenv. It uses shell scripts and builds the selected python environment from source.\nInstall any version of python Follow the instructions at its README Options I use the most:\nInstall specific python version: pyenv install \u0026lt;version\u0026gt; e.g: pyenv install 3.9.0 Use specific python version only for the current folder structure: pyenv local \u0026lt;version\u0026gt; I hope it\u0026rsquo;ll help you as much as it helped me.\nNote: It has a fork for windows.\nHappy Coding!\n","permalink":"https://budavariam.github.io/posts/2021/01/11/node/python-version-management/","summary":"I work with some projects that can be only used with specific versions of node/python and it\u0026rsquo;s not feasible to simply dockerize them. Every time I switch between these projects I\u0026rsquo;d need to reinstall different versions of node/python. That would be plain silly\u0026hellip; BUT there\u0026rsquo;s a better way.\n","title":"Node/Python Version Management"},{"content":"After experiencing the awesomeness of External Calls in Snowflake I decided to look into the possibilities of running external snippets from Postgres.\nI did not need to search too much to find out that it supports external calls to other languages beside SQL and C, called Procedural Languages.\nOut of the documented languages I choose Python to experiment with.\nCreate a docker image with Python and the extension You must install python3 and plpython3 explicitly. The rest is not mandatory, it would be inherited from the original image.\nFROM postgres:12 RUN apt-get update RUN apt-get -y install python3 python3-pip postgresql-plpython3-12 RUN apt-get clean \u0026amp;\u0026amp; \\ rm -rf /var/cache/apt/* /var/lib/apt/lists/* ENTRYPOINT [\u0026#34;/docker-entrypoint.sh\u0026#34;] EXPOSE 5432 CMD [\u0026#34;postgres\u0026#34;] Note about python3 version The postgres image is based on a slim debian image. In case you need a specfic version combination, or a shiny new python version you might have a hard time.\nIf the docker postgres image starts from a debian version that do not officially support the necessary python version, you need to figure out a suitable way to get it done.\nOne way is to build python from its source code, and to make sure that it is really used by plpython3u.\nAnother way would be to start from an os image (like a newer debian) and install postgres and python as well. And make sure that your code does all the things that the base postgres image would do, to achieve better compatibility.\nSome of the current latest version combnations:\npostgres:11 (stretch) installs python3.5.3 postfres:12 (buster) installs python3.7.3 postgres:13 (buster) installs python3.7.3 Create a stored procedure in Python Before you can start to work on your python code you need to enable the python language extension by running the following code once.\n-- need to call it once CREATE EXTENSION plpython3u; If the environment is ready you can create your python code wrapped in a stored procedure. Official docs.\n-- DROP FUNCTION hello_world; -- define incoming parameters with type CREATE FUNCTION hello_world (how text) RETURNS table ( -- return row definition index integer, greeting text ) AS $$ -- add any python code here for index, who in enumerate([ \u0026#34;World\u0026#34;, \u0026#34;PostgreSQL\u0026#34;, \u0026#34;PL/Python\u0026#34; ]): yield ( index, f\u0026#34;{how} {who}!\u0026#34; ) -- end of python code $$ LANGUAGE plpython3u; Use custom python libraries You can import python libraries in your code as well. In case you use it in an orchestrated environment e.g: kubernetes, you\u0026rsquo;ll need to make sure that the install directory is persisted.\nYou can install them manually inside the docker image (docker exec), or ship the docker image with the libs preinstalled (RUN pip3 install mylib). It depends on your constraints of what might be a better option.\nManual install The database does not need to be stopped, though the defined function won\u0026rsquo;t be available while you switch the two lib versions.\nIt might be the better choice while you need quick iterations, or you just like to get your hands dirty or you develop a custom lib just to use its code from postgres.\nShipped install You need to specify the lib version in the docker image, run pip install -r requirements.txt and ship a new version.\nIt might be the better choice if your database don\u0026rsquo;t have internet access, or you need to specifically keep track of the different version combinations.\nCall the stored procedure You can call the stored procedure in the from clause.\nselect * from hello_world(\u0026#39;Hello\u0026#39;); -- index | greeting -- -------+------------------- -- 0 | Hello World! -- 1 | Hello PostgreSQL! -- 2 | Hello PL/Python! select greeting from hello_world(\u0026#39;Goodbye\u0026#39;); -- greeting -- --------------------- -- Goodbye World! -- Goodbye PostgreSQL! -- Goodbye PL/Python! Access the database In case you need to get/set data in database you can connect to it from python code with the plpy module.\nCREATE FUNCTION try_adding_joe() RETURNS text AS $$ try: plpy.execute(\u0026#34;INSERT INTO users(username) VALUES (\u0026#39;joe\u0026#39;)\u0026#34;) except plpy.SPIError: return \u0026#34;something went wrong\u0026#34; else: return \u0026#34;Joe added\u0026#34; $$ LANGUAGE plpython3u; For more info see the official docs.\nBeware, it\u0026rsquo;s untrusted Before you rush to use it in your production app, I advise you, to evaluate the security risks it can add to your database.\nYou might\u0026rsquo;ve noticed the u at the end of plpython3u. Its meaning is defined in the official docs:\nPL/Python is only available as an \u0026ldquo;untrusted\u0026rdquo; language, meaning it does not offer any way of restricting what users can do in it and is therefore named plpythonu. \u0026hellip; The writer of a function in untrusted PL/Python must take care that the function cannot be used to do anything unwanted, since it will be able to do anything that could be done by a user logged in as the database administrator. Only superusers can create functions in untrusted languages such as plpythonu.\nHappy Coding!\n","permalink":"https://budavariam.github.io/posts/2021/01/05/postgres-external-python-call/","summary":"After experiencing the awesomeness of External Calls in Snowflake I decided to look into the possibilities of running external snippets from Postgres.\n","title":"Postgres External Python Call"},{"content":"A few months ago at work, I wrote a simple node.js snippet to calculate route distances in Mapbox. Now I\u0026rsquo;m proud, that it\u0026rsquo;s used to demonstrate how to use Mapbox calculations from Snowflake.\nTamas Foldi handled the infrastructure, and wrote a blog post to the official Snowflake blog on how to call an external lambda from SQL.\nThe source code is available on github.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2020/12/30/external-function-calls-from-snowflake/","summary":"A few months ago at work, I wrote a simple node.js snippet to calculate route distances in Mapbox. Now I\u0026rsquo;m proud, that it\u0026rsquo;s used to demonstrate how to use Mapbox calculations from Snowflake.\n","title":"External Function Calls From Snowflake"},{"content":"The 4th OITM has finished. OITM is an IT championship in Hungary sponsored by large tech companies.\nThe current championship had 22 categories, that had rounds every week. I participated in 7 categories. I learned from past years, that it\u0026rsquo;s harder to stick with completing all tests weekly if I\u0026rsquo;m not familiar with the topic at all.\nThis year I finally get to the end! I enjoyed participating. I could have prepared more, but I\u0026rsquo;m happy with the end result.\nI learned about the nuances of many fields. The questions helped me refresh my knowledge on topics I don\u0026rsquo;t use in my day-to-day work.\nResults Here are my results for this year ordered by Percentage:\nCategory name Percentage Exact Web development with traditional methods 11.81% 60. / 508 IT security 12.81% 61. / 476 Accessible websites 13.77% 46. / 334 Python 24.75% 102. / 412 DevOps 30.28% 116. / 383 Linux System Development and Operation 36.26% 132. / 364 Language-independent programming and Databases 38.65% 218. / 564 Looking forward to it next year!\n","permalink":"https://budavariam.github.io/posts/2020/12/18/oitm-2020/","summary":"The 4th OITM has finished. OITM is an IT championship in Hungary sponsored by large tech companies.\n","title":"OITM 2020"},{"content":"Ever since I wrote about VSCode Reveal, I wanted to have a command-line interface to generate the same output. I loved that well-configured behavior and did not want to start from scratch. Finally, I had the time to do it.\nGetting started The revealjs-cli npm package is available here.\nThe Github repo is available here.\nInstall\nnpm install revealjs-cli Create a markdown file for the slideshow.\nAccess info about the available features via --help flag.\nExport slides Run the tool with params to export\nrevealjs-cli \\ --build \\ --location ./slides-dist \\ --open ./path/to/markdown/slideshow.md NOTE: It removes the folder that the location is set to. It asks for permission before that happens. You can bypass it with --yes flag, for CI-friendly behavior.\nExport PDF You can create a pdf with the browser\u0026rsquo;s print feature.\nIt can be forced with ?print-pdf-now queryparam at the end of the url.\nServe Slides If you specify --serve flag, or a port to serve on with --port, then the server will not shut down, and it can be accessed from e.g. a browser.\nHappy sliding!\n","permalink":"https://budavariam.github.io/posts/2020/12/17/reveal.js-cli/","summary":"Ever since I wrote about VSCode Reveal, I wanted to have a command-line interface to generate the same output. I loved that well-configured behavior and did not want to start from scratch. Finally, I had the time to do it.\n","title":"Reveal.js CLI"},{"content":"Sometimes I work on similar projects that need so little customization I feel like I can just copy and paste it, and tweak some variables, then create a new repo for it, and start to generate the content. Here is where project templates come into play.\nCookiecutter is a python tool that lets you create an initial template that you can use for later projects. Just because it is written in python it does not mean it can only scaffold python projects.\nGetting started The theory is dead simple.\nYou create a folder for your templates. In each template mark the text substitution points in your file content, file names or directory names. with {{cookiecutter.CUSTOM_VARIABLE_NAME}}. Specify the variables that cookiecutter needs to look for in cookiecutter.json file for each project. Profit I recommend that you follow the official docs instructions, because my article can become outdated.\nThe awesome part is that you can even use a github repo to start out from.\nMy experience with it I first encountered with this tool when I worked on a custom plotly-dash react component.\nIn order to get started with that, I only needed to execute cookiecutter https://github.com/plotly/dash-component-boilerplate.git, answer a few questions about the projects and I was ready to go with a working personalized template. I was amazed by this simplicity.\nI usually present my advent of code solutions in the same style over the course of a year. This year I decided to create a project template for the solutions, and it works great.\nI use the python API interface to have some custom behavior and start it out from this python script.\nDisclaimer I was not asked to create this post, and did not get anything for it, I just wanted to share how simple it is to use and some of my experience with it.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2020/12/13/project-template-with-cookiecutter/","summary":"Sometimes I work on similar projects that need so little customization I feel like I can just copy and paste it, and tweak some variables, then create a new repo for it, and start to generate the content. Here is where project templates come into play.\n","title":"Project Template With Cookiecutter"},{"content":"It\u0026rsquo;s the time of the year when many people start to countdown with their advent calendars. For coders, there is a special kind of calendar that keeps us busy and help us prepare for the celebration.\nAdvent of Code presents a free challenge every day until December 25th. Each year there is a different back story. Usually, YOU are the coder hero and you need to save Christmas.\nYou do not have to have a CS background to participate, the challenges are solvable without extensive math/programming knowledge.\nHow it works The main goal is to collect 50 stars. You get stars by solving the daily challenges. The challenges are personalized, every registered user gets a unique generated input for the underlying problem. The problems are separated into two parts. The second part becomes available when you submit your successful solution.\nYou do not need to solve the problems in the actual day. On your personal stats page you can see how long after the opening did you solve the challenge for the actual day. The challenges open at midnight EST/UTC-5.\nThe two parts use the same input but require a different solution. From the site itself, you can not know in advance what will be the question to the second part. For this reason, it\u0026rsquo;s usually hard to give a solution to the first part, that can be simply reused in the second part, you usually need to do some restructuring.\nYou get a smaller input to test out your solution before submitting. And there is an explanation for that input to clear ambiguities.\nEach day has a hidden easter egg, some funny words or references, that are made visible at the end of the journey.\nCommunity They have a community forum on reddit at r/adventofcode. There you can ask for hints/help, post your solution to the solutions megathread, or post fun crafts that you made with the data or during the solution.\nMy experience with it It has been around since 2015, I first encountered it in university in the exam season, it helped me keep my mind sharp and let loose from the stress of the final exams. I did not have too much time to take it seriously, but it was a fun thing that I kept following every year since then.\nIt helped me strengthen my python knowledge and get to know it better. Helped me to practice Typescript when I first had to learn it for my work. Also, I used it to practice golang when I started with it.\nI post all my solutions into my advent_of_code github repo.\nDisclaimer I was not asked to create this post, and did not get anything for it, I just wanted to share how awesome it is and some of my experience with it.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2020/12/01/advent-of-code/","summary":"It\u0026rsquo;s the time of the year when many people start to countdown with their advent calendars. For coders, there is a special kind of calendar that keeps us busy and help us prepare for the celebration.\n","title":"Advent Of Code"},{"content":"A few days ago I read a question in twitter, what is the thing that you wish you had known when you started to code.\nI started to learn programming in high school, we tackled the basics of the field, by learning sql, networks, logic, binary calculations, imperative programming, but we did not really learn how these are going to work in real life.\nI collected some concepts that work for me now during my day-to-day coding, that I did not use much when I started out.\nInterpreters can help with quick calculations For scripting languages like python, bash, javascript, I find it beneficial to have a separate tab for a REPL environment.\nIt\u0026rsquo;s comforting to have a mini sandbox to try out small snippets on the go without the need to run/restart the complex app that I develop.\nSandboxes are great to investigate problems in isolation In order to solve problems it\u0026rsquo;s a good tactic to isolate the issue, and try to solve the actual problem.\nFor web projects I love online sandboxes, some of them have base templates and let me choose the frameworks that I want to include.\nI can share them with my colleagues and we can experiment in them together independently.\nCodePen CodeSandbox Repl.it Read as much code as you can Some of my university teachers told us, that it is good practice to read open-source library codes and try to familiarize ourselves with them.\nI occasionally need to use libraries for special cases that are not documented, this advice really come in handy. It empowered me to get my hands dirty and look into the source to figure out what happens under the hood.\nIn lucky cases they have tests for these issues, and can easily see how they should be used, if that\u0026rsquo;s not the case, the code still holds the truth of what they\u0026rsquo;re capable of.\nI like to read merge requests of my colleagues, and familiarize myself with the changes they made\nDebugger is usually easy to set up, and really useful For me it was scary at first, I did not get a tutorial on how these things work.\nIt\u0026rsquo;s pretty simple, mark the points where you\u0026rsquo;d like to stop code execution, start the code in debug mode, and make the code reach that point. From there you can inspect the variables, step forward, step into function calls, continue execution, and many more depending on the language and IDE.\nThe simple debugging tactic is to log every variable that needs to be inspected, but it can be hard to determine what variable do you actually need.\nUsually when I have to write vanilla javascript code, my main problem is that I can not always be sure what properties are available at a certain point for the available objects. Debugger makes it easy to see the possible options. Otherwise I\u0026rsquo;d need to guess what I need to log to the console, but this way I can just freeze time and look around.\nChrome devtools has a great intro article, if you want to learn more about debugging in Javascript\nLearning new programming languages comes easier with each new language Programming languages have the same basic principles based on their paradigm. If you need to learn a new object oriented language you don\u0026rsquo;t need to relearn the concept, just understand the differences in the syntax and the possibilities.\nWhen you learn a new language you don\u0026rsquo;t have to know everything about it at first, learn what\u0026rsquo;s enough and if you need to use advanced approaches you can find the answers to your questions later on. The important thing is to practice.\nI found it useful to have a script language that I know very well. If I can quickly solve simple problems with it, it can boost productivity in my daily coding routine.\nYou can write mini disposable code to achive a one-time simple task, that you\u0026rsquo;d otherwise have to type out. For example if you need to type the same pattern over and over, it\u0026rsquo;s frustrating to figure out in the middle, that the pattern should be different. Generated code can save you from this nightmare.\nProgramming challange sites helped me achive learning new languages better by presenting problems in an isolated state. They do not require you to handle all errors and write production ready code, but still great for practice. They make you able to focus on the way it has to be calculated.\nMy favourite programming challenge sites:\nCodeSignal HackerRank SPOJ Terminal can be simpler than GUI If an application comes with a terminal, or command interpreter, it\u0026rsquo;s worth it to learn to use what it\u0026rsquo;s capable of. Most of the time it involves less clicking and mouse movement to achieve the same thing, or even do many more options.\nMy favourite examples are Excel and AutoCAD.\nIn Excel you can select the commands from a form and add each parameter for a function. But when it comes to nesting those params, you\u0026rsquo;ll end up with juggling many windows. At least it was the case in version 2003, I haven\u0026rsquo;t really used new versions since then, but this experience stuck. You have the option to write a formula, that\u0026rsquo;s simpler, and the help menu and the next property hovers over the cursor anyways. The only thing you need to be aware of, not to make any syntax errors. I recall one time I needed a specific drawing command option, but it was not available as a button. TODO: look for it.\nMy favorite IDE is curretly VSCode, I always keep the terminal open in the bottom. I can pipe together operations that would be impossible to do in the GUI of the operating system.\nTyping is crucial I learned to code in Hungarian keyboard layout, and it\u0026rsquo;s not the most coding friendly layout. In mac it\u0026rsquo;s even worse, the special characters are spread across the keyboard with cryptic shortcuts, in order to have all accented keys easily reachable.\nIt might not be news for you, but I figured that English layout is much more convenient. It has all the special characters I need at most one SHIFT key away.\nI learned touch typing by myself, when I realized that my typing speed could be enhanced. There are some great sites and applications for that, there are even sites that let you practice writing code.\nThe best advice that helped for me is that you should not look at your hand when you\u0026rsquo;re typing.\nSome of my colleagues take it one step further, and do not really use their mouse at all. They edit code with modal editors like vim, or VSCode vim extension, and use tiling window managers.\nMy favourite learning materials were:\ngtypist: practice in the terminal offline Typing Study: helped me to learn the basics Typing Club: great stories Typing.io: practice typing code Write documentation what you\u0026rsquo;d like to read In my first few months of coding at a company was a totally new experience unlike anything. I had to familiarize myself with many things all at once. I found myself asking the same questions all over again. One day I saw a colleague taking notes in a Word document. I realized it can save me a lot of time, and I can process the new information while I write them down.\nI started out with simple txt files, later I changed to markdown, to get familiar with it.\nNowadays I find it useful to write README files for each project I\u0026rsquo;m working on, to make it easier for others to get started.\nMost importantly the docs I write help me get restarted, when I need to work on the projects again after a long time (more than 2 weeks).\nThe processes might seem logical at the time of writing, but a few projects and many new experiences/trends later it might not behave as what you\u0026rsquo;d expect them to be.\nIt takes effort to keep the docs up to date, but if you handle them as the main source of truth, it\u0026rsquo;s going to worth it.\nOther advices I find helpful It\u0026rsquo;s an underrated and invaluable skill to be able to search for the right terms about a problem you face, to find the documentation, discussions in the internet, articles about it, open or long closed github issues. Be curious, find the reasons, of why things misbehave, don\u0026rsquo;t be satisfied with quick patches that seem to fix the issues Instead of inline parameters use variables with a clear names about it\u0026rsquo;s intention Clean after yourself, leave the code cleaner than you found it, code will be read more than written. (Clean code, boy scout rule) Read through your changes before you submit a merge request, to avoid the mistakes that can be easily spotted Linters are good to keep a consistent style, and save you from common mistakes Pragmatic programmer principles DRY KISS 12 factor app UX rules Practice practice, practice \u0026hellip;\nHappz coding$\nCover Photo by Christina Morillo from Pexels\n","permalink":"https://budavariam.github.io/posts/2020/09/19/things-i-wish-i-had-known-as-a-junior/","summary":"A few days ago I read a question in twitter, what is the thing that you wish you had known when you started to code.\n","title":"Things I Wish I Had Known As a Junior"},{"content":"When I develop new web components I find it frustrating that I have to run the app, click it through until the point I find my new visual, just to see how it behaves in a real life situation. Unit tests are great to check whether my component does what I intended, but styling is a whole different story. I\u0026rsquo;ve been looking for a component preview library for React, that is not invasive and I do not need to change my code with extra markup to make it work, Storybook does exactly what I was looking for.\nWhat is this They summarized what their library is about in their introduction page.\nStorybook is a user interface development environment and playground for UI components. The tool enables developers to create components independently and showcase components interactively in an isolated development environment.\nStorybook runs outside of the main app so users can develop UI components in isolation without worrying about app specific dependencies and requirements.\nI heard about this library first in the Ladybug Podcast episode 13 Design systems. I did not look into it then, but when I needed to create a showcase of some of my components I decided to give it a try.\nNext time I had to create a totally new component, I enjoyed the benefits of the focused development, and not having to run the whole app.\nYou can get started easily for multiple frameworks.\nMy code organizing experience I do not want to get into how to get started they have many good tutorial paths depending on what you want to use it for.\nI got started with npx -p @storybook/cli sb init --type react_scripts, this boilerplate code uses number prefixed stories, and put everything into one stories folder.\nFor my use case I found it better to name the story files the same as the component and put it next to them.\nThis script adds the necessary dependencies, and adds storybook related code as devDependencies. It takes some time to get it all together, and I usually don\u0026rsquo;t need these in my CI pipelines, so I moved these to optionslDependencies, and call npm install with --no-optional flag.\nOne entrypoint rules them all I created a index.storybook.js file, to import all the necessary things that my stories need, so they can behave consistently. This file need to be imported into every .stories.js file, and it will take care of the common logic.\nIf I want to mimic the look and feel of my app I need to include the same styles that my app uses. To avoid any potential issues I prefer to import them in the same order, to avoid misbehaving style overrides due to ordering differences.\nAlso I need to include any other dependencies that my components might need, e.g i18n, so the components\u0026rsquo; behaviour can stay the same.\nIn order to showcase my components I provided some mock data to use throughout the components. These are not used anywhere in the real app. I do not want to repeat them many times, this entrypoint can contain them, or reexport them from their separate location.\nDecorators for repeated logic In react data for a component can come from props, context.\nFor a component that needs a provider to work, you need to return your component wrapped in that provider. If that provider is used by many of your components your stories will have many repeated wrapped code. This is where decorators come in handy\nSimple provider The decorator can wrap around the component and it won\u0026rsquo;t need to repeat this code.\nexport const modalProviderDecorator = (storyFn) =\u0026gt; \u0026lt;ModalProvider\u0026gt;{storyFn()}\u0026lt;/ModalProvider\u0026gt; The only thing is that the story declaration must add the necessary decorators for the component definition. Be aware that it applies them in the specified order.\nexport default { title: \u0026#34;CustomComponent\u0026#34;, component: CustomComponent, decorators: [ modalProviderDecorator, ], } React Router I did not yet needed to mock different routes, I only needed to make my components work that use location info. This small snippet made those work.\nimport { createMemoryHistory } from \u0026#34;history\u0026#34; import { Router, Route } from \u0026#34;react-router-dom\u0026#34; export const addRouter = (storyFn) =\u0026gt; ( \u0026lt;Router history={createMemoryHistory({ initialEntries: [\u0026#34;/\u0026#34;] })}\u0026gt; \u0026lt;Route path=\u0026#34;/\u0026#34; component={() =\u0026gt; storyFn()} /\u0026gt; \u0026lt;/Router\u0026gt; ) Custom data in Provider Your component might need to act differently if there\u0026rsquo;s something in one of its contexts. If you want to showcase this behaviour in different stories listed one by one this is a possible solution.\nThe intuitive solution would be to you create a function that creates the decorator, and call it with a parameter, but it will encapsulate that data into its clojure, and it won\u0026rsquo;t change if you rerun the code.\nBut if you simply add a global variable into the decorator you can change that variable in the given story and it will render the component with that data. This way you don\u0026rsquo;t need to repeat the context definition, you can still use the decorators.\nHere the privileges can be a global variable that changes depending on what story you render.\nconst prv = { EDIT: \u0026#34;EDIT\u0026#34;, VIEW: \u0026#34;VIEW\u0026#34; } let privileges = [] export const addPrivilegeContext = (storyFn) =\u0026gt; { return (\u0026lt;PrivilegeContext.Provider value={{ privileges }} \u0026gt;{storyFn()}\u0026lt;/PrivilegeContext.Provider \u0026gt;) } } export default { title: \u0026#39;CustomComponent\u0026#39;, component: CustomComponent, decorators: [ addPrivilegeContext, ], }; export const ComponentWithEditorPrivilege = () =\u0026gt; { privileges = [prv.EDIT] return \u0026lt;CustomComponent /\u0026gt;; } export const ComponentWithViewerPrivilege = () =\u0026gt; { privileges = [prv.VIEW] return \u0026lt;CustomComponent /\u0026gt;; } Note: Global variables are evil. I just want to point out that it is possible this way.\nNote that this will only work if you have already loaded the storybook, and clicking through different pages, if you arrive to this page then the default value will be used that is an empty aray in this case. If this is not okay for you, you can still extract the logic to a function, and wrap your component around it without using decorators.\nKnobs for interactivity You can make your stories controlled with knobs.\nBasicly you\u0026rsquo;ll have a tab in the bottom with controls, that can set the incoming props of your component. You can see how it reacts to change, and change its input without changing the underlying code.\nAll you need to do is add withKnobs as the first decorator from \u0026quot;@storybook/addon-knobs\u0026quot;, and define the possible values and settings for each story.\nYou can have many types, e.g. number, text, array, drowdown, multiselect, and they can really supercharge your components.\nI could create a blogpost just on knobs alone, I really enjoy this feature.\nThey are pretty amazing for example to filter mocked data only for those that you\u0026rsquo;re interested in in your current usecase.\nAn other exciting use-case is that you can define a dropdown with keys, add the property value combinations into an object, and when a selction is made, the values change all at once. This way you can showcase and examine different states of the component to others saving time by not having to click through many stories, and not having to type anything to get the different states.\nDisclaimer I was not asked to create this post, and did not get anything for it, I just wanted to share how simple it is to use and some of my experience with it.\n","permalink":"https://budavariam.github.io/posts/2020/07/04/storybook/","summary":"When I develop new web components I find it frustrating that I have to run the app, click it through until the point I find my new visual, just to see how it behaves in a real life situation. Unit tests are great to check whether my component does what I intended, but styling is a whole different story. I\u0026rsquo;ve been looking for a component preview library for React, that is not invasive and I do not need to change my code with extra markup to make it work, Storybook does exactly what I was looking for.\n","title":"Storybook"},{"content":"React Transition group is a great library for animations in react. I want to share my experience on how to have an appear animation on components that are mounted with an in={false} property.\nMy only constraint was hat I could not use unmountOnExit property.\nWhen the component mounted, it showed up immediately without the fade-in effect, then when it actually should have shown, then the animation started. I had to make sure that the component do not show up before the fade-in animation happens.\nAs stated in the docs, the in={false} setting prevents any classes applied to the component with CSSTransition.\nIf the transition component mounts with in={false}, no classes are applied yet. You might be expecting *-exit-done, but if you think about it, a component cannot finish exiting if it hasn\u0026rsquo;t entered yet.\nBummer.\nSo the first time we see the component, it won\u0026rsquo;t have any classes added to it. And later on it will only have classes that has a suffix like *.enter-done. Then how do we apply an effect to it?\nI came up with a simple solution. The classNames property can be any string, and the additional classes will be applied to the end of it. For example my-node will be transformed to my-node-enter on enter.\nI needed a way to know when the initial transition has happened.\nIf I set a string with a space in it, then technically it will apply 2 classes. It add a suffix to the last one only, and evidently the first untouched one will mark that CSSTransitionGroup has changed the classes, while giving us a class to easily check it.\n\u0026lt;CSSTransition in={falseAtFirst} key=\u0026#34;unique\u0026#34; timeout={200} classNames=\u0026#34;css-transition-applied hello-world-message\u0026#34; \u0026gt; \u0026lt;span className=\u0026#34;message\u0026#34;\u0026gt;Hello world\u0026lt;/span\u0026gt; \u0026lt;/CSSTransition\u0026gt; Then with this css I can assure that the component do not show up prematurely.\n.message:not(.css-transition-applied) { display: none; } Hope you won\u0026rsquo;t need this.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2020/06/18/react-csstransition-appear-animation-with-infalse-and-without-unmountonexit/","summary":"React Transition group is a great library for animations in react. I want to share my experience on how to have an appear animation on components that are mounted with an in={false} property.\n","title":"React CSSTransition appear animation with in=false and without unmountOnExit"},{"content":"My favourite place to deploy simple hobby and experimental web applications is heroku. It has a free plan, and it\u0026rsquo;s pretty easy to get started.\nHeroku can detect the type of your application, if it is in the root of your repository, but if you need some custom options, you can define a Procfile.\nIn the free plan as of today you can have 1000 hour of free hosting on spare instances. When your application is not used, it goes to sleep mode, and stays awake for a short period of time, or until it\u0026rsquo;s used. It means that the first reach of your application might take a bit longer, and if you don\u0026rsquo;t persist your application state it can be lost.\nGet started I usually use the heroku CLI to manage my applications.\nregister in heroku, create a git repo for the project, navigate to it heroku login - opens the browser and authenticates for the CLI session heroku create project-name - creates a new project, and sets a new remote called heroku for the it up for the current git repository magic happens here (create the app) git push heroku master - start the deployment heroku logs -t - shows the logs of the current heroku app Serve create-react-app application Sometimes I just write a simpe react web application without any backend, that I just want to host somewhere for a quick demonstration.\nI haven\u0026rsquo;t found a description how to host create-react-app for this simple use case in the docs.\nThe simplest way is to put the app in the root of the repository. If heroku finds package.json in the root, it assumes that the project is a node webapp. At deployment it will install both dependencies and devDependencies, build the application with npm run build, remove devDependencies, then start the application with npm start.\nAfter create-react-app prod build, it shows a way to serve the application with serve. I added it as the start script in package.json, and build the app with react-scripts build.\nFor local development I kept react-scripts start as npm run cra-start.\nSome gotchas Heroku needs a README.md in the root, otherwise it won\u0026rsquo;t deploy. In order to install the proper dependencies, package-lock.json or yarn.lock file must be pushed to the repo. The engines property can set the necessary npm and node versions. The port that the app needs to listen to is set in $PORT environment variable. Sample package.json { \u0026#34;name\u0026#34;: \u0026#34;create-react-app\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;react\u0026#34;: \u0026#34;^16.13.1\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^16.13.1\u0026#34;, \u0026#34;react-scripts\u0026#34;: \u0026#34;3.4.1\u0026#34;, \u0026#34;serve\u0026#34;: \u0026#34;^11.3.1\u0026#34; }, \u0026#34;engines\u0026#34;: { \u0026#34;npm\u0026#34;: \u0026#34;6.11.3\u0026#34;, \u0026#34;node\u0026#34;: \u0026#34;10.17.0\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;serve -s build\u0026#34;, \u0026#34;cra-start\u0026#34;: \u0026#34;react-scripts start\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;react-scripts build\u0026#34;, }, \u0026#34;eslintConfig\u0026#34;: { \u0026#34;extends\u0026#34;: \u0026#34;react-app\u0026#34; }, \u0026#34;browserslist\u0026#34;: { \u0026#34;production\u0026#34;: [ \u0026#34;\u0026gt;0.2%\u0026#34;, \u0026#34;not dead\u0026#34;, \u0026#34;not op_mini all\u0026#34; ], \u0026#34;development\u0026#34;: [ \u0026#34;last 1 chrome version\u0026#34;, \u0026#34;last 1 firefox version\u0026#34;, \u0026#34;last 1 safari version\u0026#34; ] } } Serve untracked non-generated files I had a quick and small project where I couldn\u0026rsquo;t generate the static pages with a script, but I did not want to host the generated files in the repository.\nI used a script to collect the data on every deploy, and push it to heroku. I wanted it to be simple, and reproducible in a new machine, without any manual steps.\nDeploy script I put the necessary files (package.json, package-lock.json, README.md) for heroku root into heroku-deploy folder.\nFor the sake of the example I collected the static files into untracked-files/export.\n#!/bin/bash echo \u0026#34;- Clean dist folder\u0026#34; # Make sure that dist-folder does not exist rm -rf ./dist-folder echo \u0026#34;- Create dist branch\u0026#34; git checkout --orphan dist git reset --hard git clean -fd -e untracked-files/export git commit --allow-empty -m \u0026#34;Create Empty Dist Branch\u0026#34; git checkout master echo \u0026#34;- Add files and push new version\u0026#34; git worktree add -f dist-folder dist cp -r ./untracked-files/export/* dist-folder/ cp -r ./heroku-deploy/* dist-folder/ cd dist-folder || exit 1 git add . git commit -m \u0026#39;Deploy to Heroku\u0026#39; git push --force heroku dist:master # force push is needed, because a # new local branch is created on every deploy. cd .. echo \u0026#34;- Cleanup\u0026#34; git worktree remove dist-folder git branch -D dist echo \u0026#34;- Done\u0026#34; Git commands to create a new empty parentless branch git checkout --orphan dist git reset --hard git clean -fd -e untracked-files/export git commit --allow-empty -m \u0026#34;Create Empty Dist Branch\u0026#34; git checkout master In order to create a new branch that does not have anything inside git checkout --orphan dist is a good start, it creates a new orphaned branch called dist.\nAfter this script runs, we are taken to this new branch, and every file in the work tree is in staged state.\nSome say that rm -rf . is a good next step, but for me it seems a bit dangerous.\nI sticked with git reset --hard; git clean -fd -e untracked-files/export. It unstages all the files, remove the modified files, then clean all untracked files, except the ones in the excluded (-e) directories.\nTo create a branch I added a new empty commit, and headed back to the main branch.\nGit worktree Git worktree is a way to manage multiple branches in the same repository.\nTo put it simple, it creates a folder, and when you step into that folder, git acts like you\u0026rsquo;ve checked out that branch.\ngit worktree add -f dist-folder dist cp -r anything/* dist-folder cd dist-folder # now git thinks we\u0026#39;ve checked out `dist` git add . git commit -m \u0026#39;Deploy to Heroku\u0026#39; git push --force heroku dist:master cd .. # back in master git worktree remove dist-folder For my usecase it\u0026rsquo;s perfect, I have an empty dist branch at this point,\nI check it out into a folder called dist-folder copy the necessary files step into the worktree, so it seems like I\u0026rsquo;ve checked out dist Stage the files, commit and deploy. step out, so git thinks I\u0026rsquo;m in master, and I can safely remove dist-folder. Since I create a new branch on every deploy, I overwrite the contents of master branch in heroku remote. Since pushes to that branch is only to trigger deployment, I never check it out, I don\u0026rsquo;t yet see a problem with this approach.\nDisclaimer I was not asked to create this post, and did not get anything for it, I just wanted to share how simple it is to use and some of my experience with it.\n","permalink":"https://budavariam.github.io/posts/2020/06/14/heroku/","summary":"My favourite place to deploy simple hobby and experimental web applications is heroku. It has a free plan, and it\u0026rsquo;s pretty easy to get started.\n","title":"Heroku"},{"content":"I\u0026rsquo;ve started to learn how to create Visualizations with Tableau for a few weeks now. Today I\u0026rsquo;ve submitted my solution to the recent MakeoverMonday challenge (2020 #23).\nAbout the challenge The organizers summarized it perfectly on data.world.\nEach week we post a link to a chart, and its data, and then you rework the chart. Maybe you retell the story more effectively, or find a new story in the data. We\u0026rsquo;re curious to see the different approaches you all take. Whether it‚Äôs a simple bar chart or an elaborate infographic, we encourage everyone of all skills to partake. Together we can have broader conversations about and with data.\nBefore / After Original chart My reworked chart I\u0026rsquo;ve published it on Tableau Public.\nExperience The main thing I wanted to emphasize in this chart is the time frequencies. In the original chart I did not see the clear distinction between the effort of consuming non-animal related products on a daily basis, and the full lack of this effort.\nOther than that I wanted to put a clear distinction between meat-eaters and the ones that follow a specific diet.\nAlso I wanted to use the colors, size and the ordering to show the differences between the effort that the different people put in. I set a color range from green to red. In my opinion red is a better color to show that someone Never consumes specifically meat-free/animal-free products, than the green color that the original chart uses.\nI think someone that do not think about this might eat more of these products than someone, who loves meat and wouldn\u0026rsquo;t change it for any other substitution, so I put the never label on top, making it the smallest.\nI did not like in the original image that the axis went over 100% without meaningful data. I let my bottom chart run to 100% to prevent unintentional axis changes.\nWhen I did this challenge, I set myself a max 1.5 hour timeframe, so I did not have time to polish it until perfection. There are some things I miss, like bigger font on the barcharts, clearer font colors, explanation of size.\nMy favourite part is that on hovering any of the top bars, a plain english sentence tells me what I need to see, and the chart on the bottom updates with the appropriate data.\nThe overall result is a bit redundant, the reason behind that is that I wanted to take some time to practice some Tableau features.\nAll in all it was a nice experience putting my newfound knowledge in use.\n","permalink":"https://budavariam.github.io/posts/2020/06/08/first-makeovermonday-submission/","summary":"I\u0026rsquo;ve started to learn how to create Visualizations with Tableau for a few weeks now. Today I\u0026rsquo;ve submitted my solution to the recent MakeoverMonday challenge (2020 #23).\n","title":"First MakeoverMonday submission"},{"content":"Today I\u0026rsquo;ve found an awesome library, called reveal.js, that lets me create slideshows in markdown format. It has a VSCode plugin, that is intuitive to use. My main purpose was to create a slideshow in plaintext format, and this lib exceeded my hopes.\nVSCode plugin The plugin adds a new item to the sidebar, that shows the outline of the opened document. In the top bar there are options to present or save the presentation.\nSave to HTML Save to PDF Open presentation in the browser Open presentation to the side The side presentation even syncs up with the cursor and shows only the current slide.\nBasics For a basic overview of the possibilities the VSCode plugin promotes a sample file, that is available here.\nThis is the first time I met this lib, and I haven\u0026rsquo;t yet got time to dive in the docs, here are the essential parts I needed:\nThe markdown file has to start with a front-matter like this:\n--- theme: \u0026#34;night\u0026#34; transition: \u0026#34;slide\u0026#34; highlightTheme: \u0026#34;monokai\u0026#34; logoImg: \u0026#34;logo.png\u0026#34; slideNumber: false title: \u0026#34;My first markdown slide\u0026#34; --- To scroll the slides to the right, separate the pages with ---, for bottom scroll use --.\nMarkdown syntax can be used. So I can insert an image with:\n![Alt text](./images/file-location.png) Tables can be embedded as well.\nI needed to get rid of image borders. I added customTheme: \u0026quot;overrides\u0026quot; to front-matter, and this css to overrides.css in the same folder as the presentation. There might be a more sophisticated way, but it was fine for me.\n.reveal section img { background: none; border: none; box-shadow: none; } To fragment a page I need to add {.fragment} at the end of the block I want to show later.\n### Trivia What is the answer to the Ultimate Question of Life, the Universe, and Everything? ... calculating {.fragment} ... still calculating {.fragment} 42 {.fragment} To make sure that an image is fit to the whole screen add {.stretch} class to it\n![Alt text](./images/file-location.png) {.stretch} Some useful shortcuts during runtime:\nTo pause the presentation press . To draw in the presentation press c To show all slides and navigate easily press ESC What I missed during this first day One thing I miss though is a simple way to build the presentation, to publish, but I\u0026rsquo;m sure I\u0026rsquo;ll figure something out when I\u0026rsquo;ll need it.\nStill it\u0026rsquo;s an amazing tool, I\u0026rsquo;m grateful for its creators.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2020/06/01/markdown-slideshow/","summary":"Today I\u0026rsquo;ve found an awesome library, called reveal.js, that lets me create slideshows in markdown format. It has a VSCode plugin, that is intuitive to use. My main purpose was to create a slideshow in plaintext format, and this lib exceeded my hopes.\n","title":"Markdown Slideshow"},{"content":"I need to set the zoom factor in an iframe. I knew exactly how much space should the embedded content fit into. And the scale needs to be adjustable. Here\u0026rsquo;s how I\u0026rsquo;d do it.\n\u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;iframe class=\u0026#34;scaled-iframe\u0026#34; src=\u0026#34;https://example.com\u0026#34; frameborder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; Container The iframe has to be wrapped into a container div element, that can have any size. I set a css custom property on it, that can be changed with javascript later on.\n.container { --scale-factor: 0.5; overflow: hidden; /* props below are not mandatory */ width: 50%; height: 500px; border: 1px solid black; } The container\u0026rsquo;s width and height can be any reasonable value, the --scale-factor should be a positive number around 1 (1 is 100%, zero does not make sense).\nSince I\u0026rsquo;ll fit the iframe content to the container, I don\u0026rsquo;t need to show any possible overflows.\nIframe The main trick is that in the iframe transform: scale can change its contents\u0026rsquo; size.\nIf I set width: 100%; height: 100%; on the iframe to keep it fit into its container, the scaling will change them as well. I need to adjust the width and height of the iframe element so that it fits in its container. I can calc the necessary adjustments based on the custom property this way: calc(1/var(--scale-factor) * 100%).\n.scaled-iframe { transform: scale(var(--scale-factor)); width: calc(1/var(--scale-factor) * 100%); height: calc(1/var(--scale-factor) * 100%); } In case I don\u0026rsquo;t want to fill the whole container, and I don\u0026rsquo;t like that it\u0026rsquo;s aligned to the middle, I need to set the transform-origin property to a different value. E.g: 0 0; will start to scale it up from the top left corner.\nBrowser support As of now css variables are not supported in IE11, JS can be used instead of it.\nOpera mini stays out of this game completely.\nFor up to date info check out caniuse.com:\ncalc transform css variables ","permalink":"https://budavariam.github.io/posts/2020/05/11/iframe-zoom/","summary":"I need to set the zoom factor in an iframe. I knew exactly how much space should the embedded content fit into. And the scale needs to be adjustable. Here\u0026rsquo;s how I\u0026rsquo;d do it.\n","title":"Iframe zoom"},{"content":"The commmand line can be your best friend during development, if you take some time to get to know its capabilities. But even if you know what it can help you with, you can still extend it. I\u0026rsquo;d like to introduce you some of my favourite tools, fzf, and oh-my-zsh. By the end of this post I hope you\u0026rsquo;ll see how well they can work together with you.\noh-my-zsh I\u0026rsquo;ve always enjoyed tweaking my command line configurations, but usually when I needed a functionality, I had to sit down and understand my code again to figure out where to put the new logic.\nLast year I\u0026rsquo;ve found oh-my-zsh, and I felt relieved. It makes it easy to create an easily managable config, nice themes and it is easily pluginable. It has a nice community that creates and shares their work.\nInstall git Install zsh Install oh-my-zsh My favourite feature in it, other than its simplicity, is that zsh makes tab completion navigatable, so you can use the arrow keys to select the appropriate value that you were searching for.\nAn other great built-in command is fc, that opens up my editor and lets me edit the previous command and run it after save.\nZsh comes embedded with plugins for commonly used commands like git, docker and kubernetes. It empowers them with aliases, command prompt information, also extends their tab completion by helping with available field names and lets you browse resources.\nNew plugins can be installed usually with 2 lines of code, one of which is a git clone, the other is editing the plugins list in .zshrc. Their configuration usually means to set some environmental variables.\nfzf fzf is a general purpose command line fuzzy finder.\nInstall guide. It makes it easy to filter data by typing any part of the line.\nYou can pipe data into it, or filter file content from your disk.\nI like the recommended settings, that way it stands out, from the other lines.\nexport FZF_DEFAULT_OPTS=\u0026#39;--height 40% --layout=reverse --border\u0026#39; Autocomplete Many shells come with command history navigation helper shortcut ctrl+R, but in the past it usually confused me more than what it helped.\nI often just ended up using history | less and search through lines with /.\nPlugins for the rescue!\nzsh-autosuggestions This plugin lets me see autosuggestions for my commands.\nInstall guide. It makes me feel super productive, when I often need to use the same set of commands in a project in order to run, build or test it.\nWhen I start to type the commands, I can accept the suggestion with a simple right arrow click.\nIf I need to search for a complex command there is a better way for that!\nfzf in zsh Fzf can be integrated with oh-my-zsh.\nNo further installation needed, only need to add fzf to the plugin array in .zshrc. It is super convenient to fuzzy search for previous commands with ctrl+R. It can find my previously typed command from just a few keystrokes.\nIt is also useful to insert file name from the current subtree with ctrl+T.\nEnhance zsh tab completion with fzf As I mentioned above, zsh comes with navigatable tab completion, but unfortunately the fzf plugin do not attach in every case. Not so long ago I\u0026rsquo;ve found a great plugin, fzf-tab that lets you use fzf in every situation.\nInstall guide. You have the option to toggle it temporarily with toggle-fzf-tab, because sometimes it might not be what you need, maybe there are too many options, or too slow in special cases.\nMy zsh config For reference my zsh config is available here. The interesting part is the plugins section. With only a few lines of code, the plugins come alive.\n# fzf configurations export FZF_DEFAULT_OPTS=\u0026#39;--height 40% --layout=reverse --border\u0026#39; # Uncomment the following line to disable fuzzy completion # export DISABLE_FZF_AUTO_COMPLETION=\u0026#34;true\u0026#34; # Uncomment the following line to disable key bindings (CTRL-T, CTRL-R, ALT-C) # export DISABLE_FZF_KEY_BINDINGS=\u0026#34;true\u0026#34; plugins=( fzf-tab # to turn it on and off: toggle-fzf-tab zsh-autosuggestions fzf ) In case it may be changed this is how it looks like at the time of writing.\nI\u0026rsquo;ve tried zsh-syntax-highlighting, but is did not really like long commands, or pasted code, so I turnded it off.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2020/04/27/supercharge-your-command-line/","summary":"The commmand line can be your best friend during development, if you take some time to get to know its capabilities. But even if you know what it can help you with, you can still extend it. I\u0026rsquo;d like to introduce you some of my favourite tools, fzf, and oh-my-zsh. By the end of this post I hope you\u0026rsquo;ll see how well they can work together with you.\n","title":"Supercharge your command line"},{"content":"In my opinion Emmet is an essential tool for web developers. You can code in abbreviations that you can translate into html layouts, css styles, or even xsl transformations. These handy shortcuts make development faster, if you know what you can use by heart.\nBasics You can find the detailed basics in the official docs.\nAlso I recommend you to check out the official cheat sheet.\nI\u0026rsquo;ve been coding in VSCode, and emmet has been integrated to it for a few years now. It is enabled by default for many file types e.g: html, jsx, xml, xsl, css, scss, sass etc.\nWhen you type in an emmet statement in those file types, you can expand it with ctrl+space helper, or with the Emmet: Expand Abbreviation command.\nI list the basic building blocks below, that you can combine in any way you\u0026rsquo;d like. Just because my examples are simple it does not mean that it can not create complex layouts. (In some examples I shorten the generated code with ... to save space).\nEmmet shines when it can make you type less. In my opinion it is better to keep it simple in general, so that you won\u0026rsquo;t waste more time to create the perfect snippet, than what it would\u0026rsquo;ve taken to type it in the first place.\nTags, properties and text Use . for class Use # for id Use [] for custom attributes Use {} to add cutom text Use lorem for lorem ipsum filler text. You can specify a number to limit the word count. e.g: lorem10. What Emmet Generated HTML class a.myClassName \u0026lt;a href=\u0026quot;\u0026quot; class=\u0026quot;myClassName\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; id p#myId \u0026lt;p id=\u0026quot;myId\u0026quot;\u0026gt;\u0026lt;/p\u0026gt; attributes td[title=\u0026quot;Hello world!\u0026quot; colspan=3] \u0026lt;td title=\u0026quot;Hello world!\u0026quot; colspan=\u0026quot;3\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; custom text div{Welcome} \u0026lt;div\u0026gt;Welcome\u0026lt;/div\u0026gt; filler text lorem5 Lorem ipsum dolor sit amet. Movements Use \u0026gt; to step into the previous item, and define its children. Use + to define a sibling of the previous item. Use ^ to climb up to parent. (It can be used multiple times). What Emmet Generated HTML move down ul\u0026gt;li\u0026gt;lorem4 \u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;Lorem ipsum dolor sit.\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt; add siblings div\u0026gt;span.a+span.b+span.c \u0026lt;div\u0026gt;\u0026lt;span class=\u0026quot;a\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;b\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;c\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/div\u0026gt; move up div\u0026gt;p\u0026gt;span+strong^^footer \u0026lt;div\u0026gt;\u0026lt;p\u0026gt;\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;strong\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;footer\u0026gt;\u0026lt;/footer\u0026gt; Control Use *n for multiplication, where n is a number that defines how many times an element should be outputted Use () for grouping (e.g. it is useful to combine with multiplication) Use $ to insert an increasing number. The number of preceding zeroes can be defined with the number of $s. You can reverse the number count direction to decrease with @-. (For me it does not seem to work now) You can change the start number with @n where n is the desired number. What Emmet Generated HTML Add counter ul\u0026gt;li.item$*5 \u0026lt;ul\u0026gt;\u0026lt;li class=\u0026quot;item1\u0026quot;\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li class=\u0026quot;item2\u0026quot;\u0026gt;\u0026lt;/li\u0026gt;...\u0026lt;/ul\u0026gt; Group mulltiplication (div\u0026gt;label+input[type=radio])*2 \u0026lt;div\u0026gt;\u0026lt;label for=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/label\u0026gt;\u0026lt;input type=\u0026quot;radio\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;div\u0026gt;\u0026lt;label for=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/label\u0026gt;\u0026lt;input type=\u0026quot;radio\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; Multiple zeros ul\u0026gt;li.item$$$2*5 \u0026lt;ul\u0026gt;\u0026lt;li class=\u0026quot;item001\u0026quot;\u0026gt;\u0026lt;/li\u0026gt;...\u0026lt;li class=\u0026quot;item005\u0026quot;\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt; Start from different base p#id$@34*4 \u0026lt;p id=\u0026quot;id34\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;...\u0026lt;p id=\u0026quot;id37\u0026quot;\u0026gt;\u0026lt;/p\u0026gt; Counter in text starting from 2 span{I have $@2 cats}*8 \u0026lt;span\u0026gt;I have 2 cats\u0026lt;/span\u0026gt;...\u0026lt;span\u0026gt;I have 9 cats\u0026lt;/span\u0026gt; Implicit tag names Emmet can assume some tagnames based on context. For example unordered lists can only contain li tags, table contains trs, and trs contain tds. Divs are commonly used, so if you don\u0026rsquo;t use any tag, and the context does not tell it otherwise then it can assume you meant to use divs.\nWhat Short Long div .wrap\u0026gt;.content div.wrap\u0026gt;div.content span em\u0026gt;.info em\u0026gt;span.info list ul\u0026gt;.item*3 ul\u0026gt;li.item*3 table table\u0026gt;#row$*4\u0026gt;[colspan=2] table\u0026gt;tr#row$*4\u0026gt;td[colspan=2] Things to be aware of Note that space is a stop symbol where Emmet stops abbreviation parsing, so do not use it outside {}. When you expand an emmet abbreviation the cursor has to be at the end of the statement. HTML, CSS, XSL There are many abbreviations to check out. I recommend the official cheat sheet for this purpose.\nEmmet in React Since last year I\u0026rsquo;ve been coding in React with .js files for frontend development. As you might have noticed .js is not in the default enabled list above, so I haven\u0026rsquo;t used my emmet knowledge for a while.\nA few days ago I looked around, and I\u0026rsquo;ve found a way to turn on emmet for react javascript files that do not have .jsx extension. I just needed to set this in VS Code\u0026rsquo;s settings.json.\n{ \u0026#34;emmet.includeLanguages\u0026#34;: { \u0026#34;javascript\u0026#34;: \u0026#34;javascriptreact\u0026#34; } } Finally I can use it again! This rediscovery inspired me to write about this tool, and share how much I love it. I hope I was able to prove how simple and powerful it is.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2020/04/12/emmet/","summary":"In my opinion Emmet is an essential tool for web developers. You can code in abbreviations that you can translate into html layouts, css styles, or even xsl transformations. These handy shortcuts make development faster, if you know what you can use by heart.\n","title":"Emmet"},{"content":"A few days ago I came across a tweet about Jetbrains Mono, the new free and open source font of Jetbrains. I have never used custom fonts for my developer environments, so I thought it would be a good start to give it a shot. Long story short, it was totally worth it.\nThis font is designed for developers, it is optimized to reduce eye strain that can occur when we scan quickly between multiple lines of code. It\u0026rsquo;s characters are of course monospace and easily distinguishable. Its lowercase characters have increased height. It has 138 code specific ligatures, some are merged characters, others are just whitespace balanced character pairs.\nI immediately fell for the difference between the curly brackets and parentheses. Differenciating between lowercase L, one and uppercase i can be difficult with other fonts, but this font makes them completely different. I turned on ligatures as well, my favourites are the arrows, comparisons lte, gte, and the double slash for comments.\nThis font is used in Jetbrains applications\u0026rsquo; latest versions (starting from v2019.3), currently I only use DataGrip from that repertoire. For my daily work I use the iTerm2 terminal and VSCode. It was quite simple to set them up.\nFrom this point there\u0026rsquo;s no turning back to default fonts.\n","permalink":"https://budavariam.github.io/posts/2020/02/08/developer-font/","summary":"A few days ago I came across a tweet about Jetbrains Mono, the new free and open source font of Jetbrains. I have never used custom fonts for my developer environments, so I thought it would be a good start to give it a shot. Long story short, it was totally worth it.\n","title":"Developer font"},{"content":"I have an application that logs a lot, and during development I got tired of looking through the command line for the error logs, that were hidden by other logs (that were also necessary). So I looked around what is the preferred way of handling logs nowadays.\nSome years ago I\u0026rsquo;ve worked on a project, where we used the ELK stack to provide configurable dashboards and realtime logs for monitoring. We used it, but I was not working with it directly. It seemed like a good idea to revisit how it actually works.\nI already knew that I only want to play around with it so I did not need to run a production ready server for it.\nFor my usecase a local virtualized install would do. I searched for existing configured stacks, and I\u0026rsquo;ve found exactly what I was looking for. Huge thanks for deviantony\u0026rsquo;s docker-elk repository. I forked it and started to explore.\nMy github repo is available here.\nWhat is ELK ELK is a stack that consists of 3 opensource tools Elasticsearch, Logstash and Kibana and lets you store logs and create visualizations based on those logs in realtime.\nLogstash collects the logs Elasticsearch stores them Kibana lets you visualize and explore them Simple as that.\nFilebeat What the starting stack was missing was a way to send logs to logstash. I read about different ways and decided to add a filebeat extension to read logs from the file system.\nBeats is the platform for single-purpose data shippers. They send data from hundreds or thousands of machines and systems to Logstash or Elasticsearch.\nsource\nElasticsearch provides docker image for these beats, so the configuration was pretty straightforward.\nARG ELK_VERSION FROM docker.elastic.co/beats/filebeat:${ELK_VERSION} I needed to provide a config, and a volume to /var/log/apps.\nIn my configuration I experimented with multiline configuration, to avoid sending multiple entries for a single log message.\nI check if the line matches with the ^(DEBUG|INFO|WARNING|ERROR|FATAL) regexp, if it does, then starts a new line, otherwise the line gets appended to the previous line.\nmultiline.pattern: \u0026#39;^(DEBUG|INFO|WARNING|ERROR|FATAL)\u0026#39; multiline.negate: true multiline.match: after Logstash I\u0026rsquo;ve played around with logstash configurations for a while, until I found a solution that I was happy with. I\u0026rsquo;ve found GROK debugger a useful tool, and it helped me to browse the basic types.\nWhile I was playing around it made me realize how important it is to provide consistent and easily parsable logs to make monitoring and error research easier to track bugs.\nSplit log message My golang code logs with a specific logger. Logstash gave me a hard time and docs/github issue browsing until I found that golang supports nanosecond precision while elasticsearch \u0026ldquo;only\u0026rdquo; uses microseconds precision, so I needed to trim the last 3 digits from the timestamp.\ngrok { match =\u0026gt; { \u0026#34;source\u0026#34; =\u0026gt; \u0026#34;%{GREEDYDATA}/%{GREEDYDATA:app}.log\u0026#34; \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{LOGLEVEL:loglevel}:\\s+(?\u0026lt;timestamp\u0026gt;%{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME})\\s+%{GREEDYDATA:logmsg}\u0026#34; } } ## golang has nanosecond precision, elasticsearch has microseconds precision, trim last 3 numbers mutate { gsub =\u0026gt; [\u0026#34;timestamp\u0026#34;,\u0026#34;\\d\\d\\d$\u0026#34;,\u0026#34;\u0026#34;] } Use log date as @timestamp The next challenge that I gave myself to use log date as the elasticsearch timestamp. In logstash it is straightforward, I need to use the date filter to convert my data to date, it needs the source with the timestamp format and the target field.\ndate { match =\u0026gt; [ \u0026#34;timestamp\u0026#34;, \u0026#34;YYYY/MM/dd HH:mm:ss.SSS\u0026#34; ] target =\u0026gt; \u0026#34;@timestamp\u0026#34; } Putting it all together I fired it all up with docker-compose -f docker-compose.yml -f extensions/filebeat-compose/filebeat-compose.yml up.\nI needed to add an index pattern to match logstash, and wait for micarle. When when the data finally started to flow and show up in kibana it was an amazing feeling, that was worth the few days of fiddling around.\nI managed to separate the data from the logs that I needed, and now I am able to save queries and dashboards based on specific cases.\nFinal thoughts I felt lucky that one version number is necessary, and it just works. I can imagine that it can be painful to manage configuration errors.\nI usually work in both frontend and backend side of the code, recently I got into managing CI/CD pipelines and deploying to different environments, but now I felt like I got a bit more taste of the devops world.\n","permalink":"https://budavariam.github.io/posts/2020/01/18/elk-adventures/","summary":"I have an application that logs a lot, and during development I got tired of looking through the command line for the error logs, that were hidden by other logs (that were also necessary). So I looked around what is the preferred way of handling logs nowadays.\n","title":"ELK adventures"},{"content":"Markdown makes it easy to write formatted text quickly. It\u0026rsquo;s a plain text format that uses basic notations to add semantics to the document. The format is widely adopted, it is a very simple and efficient tool in the hands of a developer.\nIt\u0026rsquo;s common to write the documentation in markdown format, then generate static websites/pages from it.\nMost developers like it because the modifications can be tracked in version control systems, and does not need a special editor.\nBasic syntax The markdown document translates to simple HTML.\nFor example, if the line starts with # Heading it will be converted to \u0026lt;h1\u0026gt;Heading\u0026lt;/h1\u0026gt; upon viewing.\nHere are the minimal syntax that every developer needs to know:\n\u0026lt;!-- Commented text --\u0026gt; \u0026lt;!-- Headings --\u0026gt; # h1 heading ## H2 heading ### H3 heading #### H4 heading ##### H5 heading \u0026lt;!-- Paragraphs --\u0026gt; One empty line creates a new paragraph. This line starts in a new line but still in the same paragraph. This is a separate paragraph \u0026lt;!-- Unordered List --\u0026gt; - item 1 - nested list - item 2 - item 3 \u0026lt;!-- Ordered List --\u0026gt; 1. item 1 1. nested list 1. item 2 1. item 3 \u0026lt;!-- Horizontal Divider Line --\u0026gt; --- \u0026lt;!-- Link --\u0026gt; [alt text](./anchor/href/url) \u0026lt;!-- Image --\u0026gt; ![embedded image alt text](./embedded/image/path) \u0026lt;!-- Text Format --\u0026gt; *italic* **bold** ~~strike through~~ \u0026lt;!-- Quote --\u0026gt; \u0026gt; multi line \u0026gt; quoted text \u0026lt;!-- Embedded code --\u0026gt; monospace code: `here` ```bash #!/bin/bash # this is a bash highlighter fenced code block pwd ``` \u0026lt;!-- Table --\u0026gt; table col 1 | table col 2 | table col 3 --- | --- | --- row 11 | row 12 | row 13 row 21 | row 22 | row 23 row 31 | row 31 | row 33 Converters Markdown is widely supported on the web:\nmany applications let you write formatted text in markdown. README.md files in the projects are converted and viewable on the site for example in github, gitlab and npm. some messaging apps let you format messages in markdown syntax static site generators create HTML pages from markdown documents Most of the time you don\u0026rsquo;t need to worry about converting them. However, you have the option to add markdown support to your website. You can also convert them to other formats, like pdf or latex.\nPandoc Pandoc is the swiss army knife of converting between markup formats.\nMy favorite part is that it can export my doc to pdf.\npandoc README.md --pdf-engine=xelatex -o documentation.pdf Markdown-it Markdown-it provides a simple way to render markdown text into a webpage in javascript.\nDifferent flavors When I started to learn markdown, the most confusing part for me was that the format has different implementations, and they come with different extensions. As I later found out the initial description of Markdown contained ambiguities and unanswered questions, so the implementations that appeared over the years have subtle differences and many come with syntax extensions.\nCommonMark comes to the rescue and provides a consistent way to write markdown. If the parser you use support it, you can be sure that it works as expected.\nGithub adds extra features on CommonMark, like emojis and marks for task completion.\nStyleguide The style and syntax are not enforced, if the document has an error, it will be converted anyway, only the result will most likely not look as intended.\nI recommend you to use a linter, like markdownlint to keep your markdown files consistent. Markdownlint has many rules, that points out errors and warns you about coding style best practices.\nHappy coding!\n","permalink":"https://budavariam.github.io/posts/2019/05/01/plaintext-docs-in-markdown/","summary":"Markdown makes it easy to write formatted text quickly. It\u0026rsquo;s a plain text format that uses basic notations to add semantics to the document. The format is widely adopted, it is a very simple and efficient tool in the hands of a developer.\n","title":"Plaintext Docs In Markdown"},{"content":"Imagine you want to submit a huge merge request (gitlab terminology), that has many changes from a bunch of commits. You realize that you don\u0026rsquo;t want to see some changes, but these changes are not in separate commits, so they can\u0026rsquo;t be easily reverted. There are a lot of small changes. You don\u0026rsquo;t want to type their reverse, or copy-paste for minutes. You want to keep the commits, not squash them together in the end. What would you do?\nI did not want to spend time to find the perfect solution, so I came up with a quick one.\nWhat I really wanted is to see all changes in one commit, that I saw in my merge request, and select the code I wanted to get rid of, then apply these changes to my original branch.\nIn order to achieve that, I got the latest master, created a sandbox branch, squashed my target branch inside it, selected what code I wanted to get rid of, reverted that commit, and cherry picked it to my target branch.\nSANDBOX_BRANCH=sandbox TARGET_BRANCH=target # 1. Get a clear sandbox with recent master git checkout master git pull git checkout -b $SANDBOX_BRANCH ## 2. Get all changes as one commit git merge $TARGET_BRANCH --squash # ... select only the unnecessary code, # ... that you want to revert git add . git commit -m \u0026#34;Unnecessary code\u0026#34; git revert HEAD HASH=`git rev-parse --short HEAD` ## 3. Apply the inverse changes, cleanup git checkout $TARGET_BRANCH git cherry-pick $HASH git commit --amend -v # rename commit git branch -D $SANDBOX_BRANCH Enjoy :)\nP.S: Let me know if you have a better idea.\n","permalink":"https://budavariam.github.io/posts/2019/04/25/groom-merge-request/","summary":"Imagine you want to submit a huge merge request (gitlab terminology), that has many changes from a bunch of commits. You realize that you don\u0026rsquo;t want to see some changes, but these changes are not in separate commits, so they can\u0026rsquo;t be easily reverted. There are a lot of small changes. You don\u0026rsquo;t want to type their reverse, or copy-paste for minutes. You want to keep the commits, not squash them together in the end. What would you do?\n","title":"Groom merge request"},{"content":"A few days ago I\u0026rsquo;ve been thinking whether there\u0026rsquo;s a more interactive way of learning flexbox, rather than this great guide.\nI know the basics, the concept, read this introduction many times, but I had to look up the parameters all the time.\nIn my not so comprehensive searching I\u0026rsquo;ve found 2 great interactive tutorials.\nWebflow tutorial feels like a way to introduce the flexbox possibilities in its user interface, but a great way to practice with real examples. It can be clicked through in a few hours.\nFlexbox zombies is a great way to keep the knowledge in your hands. You practice by writing code. The task difficulties increase slowly and gradually, first it holds your hand, then let you practice alone. It advices you to keep longer breaks between the sections to let your earned knowledge rest, and that way stay longer with you. I love the story, i love the artwork. Originally it is a course that you can get for $225, but currently it is open for enrollbent for free. It consists of 12 lessons, I keep a day between levels, so it is definitely not a quick tutorial.\n","permalink":"https://budavariam.github.io/posts/2018/05/06/flexbox-zombies/","summary":"A few days ago I\u0026rsquo;ve been thinking whether there\u0026rsquo;s a more interactive way of learning flexbox, rather than this great guide.\n","title":"Flexbox zombies"},{"content":"I just started my github pages site supported by Jekyll.\n","permalink":"https://budavariam.github.io/posts/2018/03/03/hello-world/","summary":"I just started my github pages site supported by Jekyll.\n","title":"Hello world"}]